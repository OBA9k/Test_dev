{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import skimage.external.tifffile as tiff\n",
    "\n",
    "from common import Statistics, dataset_source\n",
    "from resources.conv_learner import *\n",
    "from resources.plots import *\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets/Hirano3D/\"\n",
    "# data_path = Path(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_clss = {'NM17-002': 0,\n",
    "         'Ctrl-AK': 0,\n",
    "         'GUK1-D': 1, \n",
    "         'GUK1-R': 1,\n",
    "         'MFN2-1': 2,\n",
    "         'VCP-1': 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV generation via sklearn, Multilabel implementation by trent-b, or FastAi\n",
    "\n",
    "Both libraries seem to be completely useless... can just use native fastai function: get_cv_idxs().<br>\n",
    "However, get_cv_idxs() does NOT shuffle...!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def get_label_stratified_CV_idxs(csv_path):\n",
    "    \n",
    "    _all_labels = pd.read_csv(csv_path)\n",
    "    arr = _all_labels.values\n",
    "\n",
    "    X = arr[:,0]\n",
    "    y = arr[:,1:]\n",
    "    \n",
    "    ### sklearn.model_selection.StratifiedKFold\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "    \n",
    "    for train_index, val_index in sss.split(X, y):\n",
    "        trn_idxs = train_index\n",
    "        val_idxs = val_index\n",
    "    \n",
    "    print(f\"\"\"Train label-distribution:\\n\"\"\"\n",
    "          f\"\"\"{pd.Series(arr[:,1][trn_idxs]).value_counts()}\"\"\")\n",
    "    print(f\"\"\"Val label-distribution:\\n\"\"\"\n",
    "          f\"\"\"{pd.Series(arr[:,1][val_idxs]).value_counts()}\"\"\")\n",
    "    \n",
    "    return trn_idxs, val_idxs\n",
    "\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "def get_label_stratified_CV_idxs_multi(csv_path):\n",
    "    \n",
    "    # FastAi csv_source expects a folder-name string to be passed as first arg... -> 'dummy'\n",
    "    X, y, all_lbls = csv_source('dummy', csv_path)\n",
    "    \n",
    "    ### Iterative stratification library: https://github.com/trent-b/iterative-stratification\n",
    "    msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for train_index, val_index in msss.split(X, y):\n",
    "        trn_idxs = train_index\n",
    "        val_idxs = val_index\n",
    "    \n",
    "    trn_count = np.sum(y[trn_idxs], axis=0)\n",
    "    val_count = np.sum(y[val_idxs], axis=0)\n",
    "    \n",
    "    print(f\"\"\"Train label-distribution:\\n\"\"\"\n",
    "          f\"\"\"{trn_count}\"\"\")\n",
    "    print(f\"\"\"Val label-distribution:\\n\"\"\"\n",
    "          f\"\"\"{val_count}\"\"\")\n",
    "    \n",
    "    return trn_idxs, val_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label-distribution:\n",
      "0    216\n",
      "1    163\n",
      "2    161\n",
      "3    124\n",
      "dtype: int64\n",
      "Val label-distribution:\n",
      "0    54\n",
      "1    41\n",
      "2    40\n",
      "3    31\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### used atm...\n",
    "csv_path = path + '8bit_multi_folder_Hirano3D_v1.csv'\n",
    "trn_idxs, val_idxs = get_label_stratified_CV_idxs(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "idxs_dict = {'trn_idxs': trn_idxs, 'val_idxs': val_idxs}\n",
    "\n",
    "with open('datasets/Hirano3D/tmp/Hirano3D_dn121_local_8bit_idxs.pkl', 'wb') as handle:\n",
    "    pickle.dump(idxs_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('datasets/Hirano3D/tmp/Hirano3D_dn121_local_8bit_idxs.pkl', 'rb') as handle:\n",
    "    idxs_dict_load = pickle.load(handle)\n",
    "    \n",
    "val_idxs_loaded = idxs_dict_load['val_idxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# csv_path = path + 'multi_folder_Hirano3D_02.csv'\n",
    "# trn_idxs, val_idxs = get_label_stratified_CV_idxs(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setting up a list of a random 20% of images in train as the validation set\n",
    "\n",
    "# lbl_csv = path + 'multi_folder_Hirano3D_02.csv'\n",
    "# n = len(list(open(lbl_csv))) -1\n",
    "# val_idxs = get_cv_idxs(n, val_pct=0.2)\n",
    "\n",
    "\n",
    "# # Count labels\n",
    "# # _all_labels = pd.read_csv(PATH + 'multi_folder_Hirano3D_02.csv')\n",
    "# # print(_all_labels.Targets.value_counts())\n",
    "\n",
    "# _arr = _all_labels.values\n",
    "# _val_labels = pd.DataFrame(_arr[val_idxs], columns=['Id','Targets'])\n",
    "# print(_val_labels.Targets.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, lbl_csv, val_idxs, sz, bs, aug_tfms):\n",
    "\n",
    "    tfms = tfms_with_IntNorm(sz, aug_tfms=aug_tfms, crop_type=CropType.CENTER)\n",
    "    data = ImageClassifierData.from_csv(PATH, 'data', lbl_csv, \n",
    "                                        val_idxs = val_idxs,\n",
    "                                        test_name='data/8bit_Hirano3D_MaxP_GRFB_test_512', \n",
    "                                        tfms=tfms, bs=bs, suffix = '.tif', \n",
    "                                        balance=True, num_workers=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"datasets/Hirano3D\"\n",
    "# data_path = Path(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_crop is: 2\n",
      "Calculating weights...\n",
      "one-hot encoding single-labels...\n",
      "Weights calculated successfully!\n",
      "Using WeightedRandomSampler\n"
     ]
    }
   ],
   "source": [
    "# define augmentations\n",
    "augs = [RandomDihedral()]\n",
    "NUM_CLASSES = 4\n",
    "bs = 32\n",
    "sz = [4,224,224]\n",
    "lbl_csv = path + '8bit_multi_folder_Hirano3D_v1.csv'\n",
    "# initialize data object\n",
    "data = get_data(PATH, lbl_csv, val_idxs, sz, bs, aug_tfms = augs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inpsect data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.trn_dl.dataset.transform.tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 224, 224)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(data.trn_dl))\n",
    "im = to_np(x[0])\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(data.val_dl))\n",
    "# x_test, y_test = next(iter(data.test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print transformations\n",
    "# plt.style.use('seaborn-white')\n",
    "\n",
    "c = 0\n",
    "idx = 0\n",
    "fig, ax = plt.subplots(1,4, figsize=(16,10))\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    x, y = next(iter(data.aug_dl))\n",
    "    im = to_np(x)[idx]\n",
    "#     ax.imshow(np.sum(im, axis = 0))\n",
    "    ax.imshow(im[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_raw = tiff.imread('datasets\\\\Hirano3D\\\\test_out/fCMT2_02_e3_017.tif')\n",
    "im_scaled = (im_raw/255)\n",
    "\n",
    "im_sc_rot = np.moveaxis(im_scaled, 0,-1)\n",
    "\n",
    "m = np.array(np.mean(im_sc_rot, axis=(0,1)), dtype=np.float32)\n",
    "s = np.array(np.std(im_sc_rot, axis=(0,1)), dtype=np.float32)\n",
    "\n",
    "im_scaled_normed = (im_sc_rot - m) / s\n",
    "m_n = np.mean(im_scaled_normed[0])\n",
    "s_n = np.std(im_scaled_normed[0])\n",
    "\n",
    "print(np.mean(im_raw[0]))\n",
    "print(np.mean(im_scaled[0]))\n",
    "print(np.max(im_scaled_normed[0]))\n",
    "print(m)\n",
    "\n",
    "print(m_n, s_n)\n",
    "\n",
    "im_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff.imshow(im_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect images\n",
    "plt.style.use('seaborn-white')\n",
    "ch = 0\n",
    "idx = 0\n",
    "\n",
    "# im = to_np(x)[idx]\n",
    "im_rawHPA = tiff.imread('datasets\\\\Kaggle_HPA_2018\\\\HPAv18_BGR_test\\\\1183_51_A11_2.tiff')\n",
    "im_raw = tiff.imread('datasets\\\\Hirano3D\\\\test_out/fCMT2_02_e3_017.tif')\n",
    "# im_scaled = (im_raw/255)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(16,10))\n",
    "ax[0].imshow(im_rawHPA[0])\n",
    "ax[1].imshow(im_raw[ch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = 1\n",
    "\n",
    "print(np.max(im_raw[ch]))\n",
    "print(np.max(im_rawHPA[ch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(im_rawHPA[ch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(to_np(x)[5][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading epoch for manual inspection..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_epoch(dl = data.trn_dl):\n",
    "    \n",
    "    batch = iter(dl)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "#     for b in range(0,len(dl)):\n",
    "    for b in range(0,10):\n",
    "\n",
    "        x_, y_ = next(batch)\n",
    "        x_np, y_np = to_np(x_), to_np(y_)\n",
    "        xs.append(x_np)\n",
    "        ys.append(y_np)\n",
    "\n",
    "    return np.vstack(xs), np.concatenate(ys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inpsecting loaded images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_label(y):\n",
    "    ind = [i for i, p in enumerate(y) if y[i]==1]\n",
    "    return(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspect train images\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "idx = 2\n",
    "\n",
    "im = to_np(x)[idx]\n",
    "\n",
    "lbl = to_np(y)[idx]\n",
    "# lbl = to_label(to_np(y)[idx])\n",
    "print(lbl)\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize=(16,10))\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    ax.imshow(im[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspect test images\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "idx = 3\n",
    "\n",
    "im = to_np(x_test)[idx]\n",
    "\n",
    "# lbl = to_label(to_np(y)[idx])\n",
    "# print(lbl)\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize=(16,10))\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    ax.imshow(im[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base-model\n",
    "\n",
    "arch = dn121_c\n",
    "# arch = resnet50\n",
    "learn = ConvLearner.pretrained(arch, data, opt_fn=optim.Adam, ps=0, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional parameters\n",
    "\n",
    "wd=1e-8 # weight-decay/L2 regularization \n",
    "# learn.metrics = [accuracy, f1_micro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find2(1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a360cac16e614440807725d9e94e0180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 0                                                                                                                                                                                      \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      1.39219    1.580265   0.277108  \n",
      "EPOCH 1 ---------------------------------------- STEP 1                                                                                                                                                                                      \n",
      "    1      1.353507   2.277456   0.277108  \n",
      "EPOCH 2 ---------------------------------------- STEP 2                                                                                                                                                                                      \n",
      "    2      1.347699   2.236724   0.204819  \n",
      "EPOCH 3 ---------------------------------------- STEP 3                                                                                                                                                                                      \n",
      "    3      1.268945   1.605096   0.204819  \n",
      "EPOCH 4 ---------------------------------------- STEP 4                                                                                                                                                                                      \n",
      "    4      1.199048   1.586713   0.259036  \n",
      "EPOCH 5 ---------------------------------------- STEP 5                                                                                                                                                                                      \n",
      "    5      1.148325   1.254752   0.439759  \n",
      "EPOCH 6 ---------------------------------------- STEP 6                                                                                                                                                                                      \n",
      "    6      1.104404   1.466434   0.385542  \n",
      "EPOCH 7 ---------------------------------------- STEP 7                                                                                                                                                                                      \n",
      "    7      1.068369   1.529125   0.409639  \n",
      "EPOCH 8 ---------------------------------------- STEP 8                                                                                                                                                                                      \n",
      "    8      1.042316   1.087842   0.548193  \n",
      "EPOCH 9 ---------------------------------------- STEP 9                                                                                                                                                                                      \n",
      "    9      0.97865    1.135338   0.572289  \n",
      "EPOCH 10 ---------------------------------------- STEP 10                                                                                                                                                                                    \n",
      "    10     0.934184   1.263818   0.536145  \n",
      "EPOCH 11 ---------------------------------------- STEP 11                                                                                                                                                                                    \n",
      "    11     0.874787   1.272708   0.524096  \n",
      "EPOCH 12 ---------------------------------------- STEP 12                                                                                                                                                                                    \n",
      "    12     0.838554   1.105432   0.566265  \n",
      "EPOCH 13 ---------------------------------------- STEP 13                                                                                                                                                                                    \n",
      "    13     0.786301   1.223112   0.536145  \n",
      "EPOCH 14 ---------------------------------------- STEP 14                                                                                                                                                                                    \n",
      "    14     0.757848   1.204956   0.53012   \n",
      "EPOCH 15 ---------------------------------------- STEP 15                                                                                                                                                                                    \n",
      "    15     0.715089   1.24687    0.512048  \n",
      "EPOCH 16 ---------------------------------------- STEP 16                                                                                                                                                                                    \n",
      "    16     0.666389   1.523799   0.512048  \n",
      "EPOCH 17 ---------------------------------------- STEP 17                                                                                                                                                                                    \n",
      "    17     0.704868   2.837854   0.343373  \n",
      "EPOCH 18 ---------------------------------------- STEP 18                                                                                                                                                                                    \n",
      "    18     0.818193   1.937687   0.427711  \n",
      "EPOCH 19 ---------------------------------------- STEP 19                                                                                                                                                                                    \n",
      "    19     0.856404   1.307476   0.445783  \n",
      "EPOCH 20 ---------------------------------------- STEP 20                                                                                                                                                                                    \n",
      "    20     0.871406   1.433564   0.451807  \n",
      "EPOCH 21 ---------------------------------------- STEP 21                                                                                                                                                                                    \n",
      "    21     0.866389   1.361874   0.487952  \n",
      "EPOCH 22 ---------------------------------------- STEP 22                                                                                                                                                                                    \n",
      "    22     0.841461   1.240684   0.524096  \n",
      "EPOCH 23 ---------------------------------------- STEP 23                                                                                                                                                                                    \n",
      "    23     0.798012   1.170211   0.53012   \n",
      "EPOCH 24 ---------------------------------------- STEP 24                                                                                                                                                                                    \n",
      "    24     0.761189   1.39114    0.524096  \n",
      "EPOCH 25 ---------------------------------------- STEP 25                                                                                                                                                                                    \n",
      "    25     0.707955   1.169436   0.524096  \n",
      "EPOCH 26 ---------------------------------------- STEP 26                                                                                                                                                                                    \n",
      "    26     0.642885   1.422373   0.5       \n",
      "EPOCH 27 ---------------------------------------- STEP 27                                                                                                                                                                                    \n",
      "    27     0.602867   1.104535   0.572289  \n",
      "EPOCH 28 ---------------------------------------- STEP 28                                                                                                                                                                                    \n",
      "    28     0.556142   1.246684   0.578313  \n",
      "EPOCH 29 ---------------------------------------- STEP 29                                                                                                                                                                                    \n",
      "    29     0.497516   1.193941   0.584337  \n",
      "EPOCH 30 ---------------------------------------- STEP 30                                                                                                                                                                                    \n",
      "    30     0.452746   1.230463   0.548193  \n",
      "EPOCH 31 ---------------------------------------- STEP 31                                                                                                                                                                                    \n",
      "    31     0.415266   1.131623   0.60241   \n",
      "\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n",
      "Wall time: 12min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.13162]), 0.6024096378360886]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-3, 2, cycle_len=16, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85), best_save_name='Hirano3D_v1_dn121_8bit_bs32_sz224_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa6717f12e749d8be4dac7b537521ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 32                                                                                                                                                                                     \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.33739    1.329391   0.63253   \n",
      "EPOCH 1 ---------------------------------------- STEP 33                                                                                                                                                                                     \n",
      "    1      0.447565   1.642701   0.481928  \n",
      "EPOCH 2 ---------------------------------------- STEP 34                                                                                                                                                                                     \n",
      "    2      0.616699   1.485875   0.524096  \n",
      "EPOCH 3 ---------------------------------------- STEP 35                                                                                                                                                                                     \n",
      "    3      0.643013   1.258106   0.536145  \n",
      "EPOCH 4 ---------------------------------------- STEP 36                                                                                                                                                                                     \n",
      "    4      0.614086   1.339988   0.512048  \n",
      "EPOCH 5 ---------------------------------------- STEP 37                                                                                                                                                                                     \n",
      "    5      0.597984   1.317933   0.493976  \n",
      "EPOCH 6 ---------------------------------------- STEP 38                                                                                                                                                                                     \n",
      "    6      0.576937   1.625652   0.433735  \n",
      "EPOCH 7 ---------------------------------------- STEP 39                                                                                                                                                                                     \n",
      "    7      0.544682   1.238499   0.566265  \n",
      "EPOCH 8 ---------------------------------------- STEP 40                                                                                                                                                                                     \n",
      "    8      0.524118   1.339972   0.542169  \n",
      "EPOCH 9 ---------------------------------------- STEP 41                                                                                                                                                                                     \n",
      "    9      0.481549   1.19922    0.572289  \n",
      "EPOCH 10 ---------------------------------------- STEP 42                                                                                                                                                                                    \n",
      "    10     0.413493   1.316584   0.548193  \n",
      "EPOCH 11 ---------------------------------------- STEP 43                                                                                                                                                                                    \n",
      "    11     0.372104   1.334001   0.620482  \n",
      "EPOCH 12 ---------------------------------------- STEP 44                                                                                                                                                                                    \n",
      "    12     0.33867    1.272448   0.572289  \n",
      "EPOCH 13 ---------------------------------------- STEP 45                                                                                                                                                                                    \n",
      "    13     0.287788   1.235682   0.60241   \n",
      "EPOCH 14 ---------------------------------------- STEP 46                                                                                                                                                                                    \n",
      "    14     0.268085   1.228583   0.578313  \n",
      "EPOCH 15 ---------------------------------------- STEP 47                                                                                                                                                                                    \n",
      "    15     0.236308   1.206959   0.614458  \n",
      "\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n",
      "Wall time: 6min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.20696]), 0.614457830607173]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(6e-4, 1, cycle_len=16, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85), best_save_name='Hirano3D_v1_dn121_8bit_bs32_sz224_v2_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e12da9204c4d319671e6fc82a79606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 48                                                                                                                                                                                     \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.322217   1.600793   0.53012   \n",
      "EPOCH 1 ---------------------------------------- STEP 49                                                                                                                                                                                     \n",
      "    1      0.584379   1.557682   0.506024  \n",
      "EPOCH 2 ---------------------------------------- STEP 50                                                                                                                                                                                     \n",
      "    2      0.636146   1.718524   0.427711  \n",
      "EPOCH 3 ---------------------------------------- STEP 51                                                                                                                                                                                     \n",
      "    3      0.587801   1.273903   0.548193  \n",
      "EPOCH 4 ---------------------------------------- STEP 52                                                                                                                                                                                     \n",
      "    4      0.524972   1.457618   0.548193  \n",
      "EPOCH 5 ---------------------------------------- STEP 53                                                                                                                                                                                     \n",
      "    5      0.458298   1.389638   0.554217  \n",
      "EPOCH 6 ---------------------------------------- STEP 54                                                                                                                                                                                     \n",
      "    6      0.408945   1.429465   0.560241  \n",
      "EPOCH 7 ---------------------------------------- STEP 55                                                                                                                                                                                     \n",
      "    7      0.352281   1.327002   0.542169  \n",
      "EPOCH 8 ---------------------------------------- STEP 56                                                                                                                                                                                     \n",
      "    8      0.319314   1.660274   0.542169  \n",
      "EPOCH 9 ---------------------------------------- STEP 57                                                                                                                                                                                     \n",
      "    9      0.400234   1.879908   0.451807  \n",
      "EPOCH 10 ---------------------------------------- STEP 58                                                                                                                                                                                    \n",
      "    10     0.454552   1.575835   0.475904  \n",
      "EPOCH 11 ---------------------------------------- STEP 59                                                                                                                                                                                    \n",
      "    11     0.456448   1.326167   0.536145  \n",
      "EPOCH 12 ---------------------------------------- STEP 60                                                                                                                                                                                    \n",
      "    12     0.440024   1.243955   0.578313  \n",
      "EPOCH 13 ---------------------------------------- STEP 61                                                                                                                                                                                    \n",
      "    13     0.39902    1.257615   0.590361  \n",
      "EPOCH 14 ---------------------------------------- STEP 62                                                                                                                                                                                    \n",
      "    14     0.344164   1.247034   0.620482  \n",
      "EPOCH 15 ---------------------------------------- STEP 63                                                                                                                                                                                    \n",
      "    15     0.304149   1.256709   0.638554  \n",
      "EPOCH 16 ---------------------------------------- STEP 64                                                                                                                                                                                    \n",
      "    16     0.270347   1.378364   0.60241   \n",
      "EPOCH 17 ---------------------------------------- STEP 65                                                                                                                                                                                    \n",
      "    17     0.330661   2.501663   0.493976  \n",
      "EPOCH 18 ---------------------------------------- STEP 66                                                                                                                                                                                    \n",
      "    18     0.402492   1.965492   0.409639  \n",
      "EPOCH 19 ---------------------------------------- STEP 67                                                                                                                                                                                    \n",
      "    19     0.439274   1.486438   0.53012   \n",
      "EPOCH 20 ---------------------------------------- STEP 68                                                                                                                                                                                    \n",
      "    20     0.423987   1.20269    0.620482  \n",
      "EPOCH 21 ---------------------------------------- STEP 69                                                                                                                                                                                    \n",
      "    21     0.369499   1.276584   0.596386  \n",
      "EPOCH 22 ---------------------------------------- STEP 70                                                                                                                                                                                    \n",
      "    22     0.323669   1.212382   0.608434  \n",
      "EPOCH 23 ---------------------------------------- STEP 71                                                                                                                                                                                    \n",
      "    23     0.267395   1.254086   0.638554  \n",
      "EPOCH 24 ---------------------------------------- STEP 72                                                                                                                                                                                    \n",
      "    24     0.240025   1.499359   0.542169  \n",
      "EPOCH 25 ---------------------------------------- STEP 73                                                                                                                                                                                    \n",
      "    25     0.289356   1.623812   0.542169  \n",
      "EPOCH 26 ---------------------------------------- STEP 74                                                                                                                                                                                    \n",
      "    26     0.353383   1.599319   0.560241  \n",
      "EPOCH 27 ---------------------------------------- STEP 75                                                                                                                                                                                    \n",
      "    27     0.362734   1.451652   0.644578  \n",
      "EPOCH 28 ---------------------------------------- STEP 76                                                                                                                                                                                    \n",
      "    28     0.350103   1.366721   0.566265  \n",
      "EPOCH 29 ---------------------------------------- STEP 77                                                                                                                                                                                    \n",
      "    29     0.322714   1.349335   0.536145  \n",
      "EPOCH 30 ---------------------------------------- STEP 78                                                                                                                                                                                    \n",
      "    30     0.278569   1.315423   0.60241   \n",
      "EPOCH 31 ---------------------------------------- STEP 79                                                                                                                                                                                    \n",
      "    31     0.240325   1.26215    0.626506  \n",
      "\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n",
      "Wall time: 14min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.26215]), 0.6265060248145138]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(8e-4, 4, cycle_len=8, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85), best_save_name='Hirano3D_v1_dn121_8bit_bs32_sz224_v2_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4724357af73e42aba2ae67c1f5e3da13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 80                                                                                                                                                                                     \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.14351    1.222646   0.626506  \n",
      "EPOCH 1 ---------------------------------------- STEP 81                                                                                                                                                                                     \n",
      "    1      0.126164   1.403043   0.614458  \n",
      "EPOCH 2 ---------------------------------------- STEP 82                                                                                                                                                                                     \n",
      "    2      0.126797   1.38206    0.626506  \n",
      "EPOCH 3 ---------------------------------------- STEP 83                                                                                                                                                                                     \n",
      "    3      0.120005   1.277625   0.644578  \n",
      "EPOCH 4 ---------------------------------------- STEP 84                                                                                                                                                                                     \n",
      "    4      0.11382    1.253274   0.638554  \n",
      "EPOCH 5 ---------------------------------------- STEP 85                                                                                                                                                                                     \n",
      "    5      0.101975   1.275      0.626506  \n",
      "EPOCH 6 ---------------------------------------- STEP 86                                                                                                                                                                                     \n",
      "    6      0.091271   1.270312   0.644578  \n",
      "EPOCH 7 ---------------------------------------- STEP 87                                                                                                                                                                                     \n",
      "    7      0.08542    1.274526   0.644578  \n",
      "EPOCH 8 ---------------------------------------- STEP 88                                                                                                                                                                                     \n",
      "    8      0.082132   1.287732   0.63253   \n",
      "EPOCH 9 ---------------------------------------- STEP 89                                                                                                                                                                                     \n",
      "    9      0.081089   1.298767   0.662651  \n",
      "EPOCH 10 ---------------------------------------- STEP 90                                                                                                                                                                                    \n",
      "    10     0.07118    1.308656   0.644578  \n",
      "EPOCH 11 ---------------------------------------- STEP 91                                                                                                                                                                                    \n",
      "    11     0.067837   1.33193    0.650602  \n",
      "EPOCH 12 ---------------------------------------- STEP 92                                                                                                                                                                                    \n",
      "    12     0.069038   1.33948    0.650602  \n",
      "EPOCH 13 ---------------------------------------- STEP 93                                                                                                                                                                                    \n",
      "    13     0.062945   1.381467   0.644578  \n",
      "EPOCH 14 ---------------------------------------- STEP 94                                                                                                                                                                                    \n",
      "    14     0.057008   1.374946   0.638554  \n",
      "EPOCH 15 ---------------------------------------- STEP 95                                                                                                                                                                                    \n",
      "    15     0.054448   1.377766   0.656627  \n",
      "EPOCH 16 ---------------------------------------- STEP 96                                                                                                                                                                                    \n",
      "    16     0.052203   1.438348   0.626506  \n",
      "EPOCH 17 ---------------------------------------- STEP 97                                                                                                                                                                                    \n",
      "    17     0.050268   1.415011   0.620482  \n",
      "EPOCH 18 ---------------------------------------- STEP 98                                                                                                                                                                                    \n",
      "    18     0.049458   1.396263   0.620482  \n",
      "EPOCH 19 ---------------------------------------- STEP 99                                                                                                                                                                                    \n",
      "    19     0.053003   1.442832   0.608434  \n",
      "EPOCH 20 ---------------------------------------- STEP 100                                                                                                                                                                                   \n",
      "    20     0.048972   1.460537   0.60241   \n",
      "EPOCH 21 ---------------------------------------- STEP 101                                                                                                                                                                                   \n",
      "    21     0.046749   1.432825   0.584337  \n",
      "EPOCH 22 ---------------------------------------- STEP 102                                                                                                                                                                                   \n",
      "    22     0.044468   1.38797    0.608434  \n",
      "EPOCH 23 ---------------------------------------- STEP 103                                                                                                                                                                                   \n",
      "    23     0.041188   1.393653   0.596386  \n",
      "EPOCH 24 ---------------------------------------- STEP 104                                                                                                                                                                                   \n",
      "    24     0.037083   1.363554   0.63253   \n",
      "EPOCH 25 ---------------------------------------- STEP 105                                                                                                                                                                                   \n",
      "    25     0.037476   1.394412   0.620482  \n",
      "EPOCH 26 ---------------------------------------- STEP 106                                                                                                                                                                                   \n",
      "    26     0.037608   1.423182   0.644578  \n",
      "EPOCH 27 ---------------------------------------- STEP 107                                                                                                                                                                                   \n",
      "    27     0.034699   1.449731   0.644578  \n",
      "EPOCH 28 ---------------------------------------- STEP 108                                                                                                                                                                                   \n",
      "    28     0.033695   1.404181   0.650602  \n",
      "EPOCH 29 ---------------------------------------- STEP 109                                                                                                                                                                                   \n",
      "    29     0.030439   1.396138   0.638554  \n",
      "EPOCH 30 ---------------------------------------- STEP 110                                                                                                                                                                                   \n",
      "    30     0.031401   1.414485   0.644578  \n",
      "EPOCH 31 ---------------------------------------- STEP 111                                                                                                                                                                                   \n",
      "    31     0.029222   1.393354   0.662651  \n",
      "\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n",
      "Wall time: 13min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.39335]), 0.6626506031277668]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-4, 4, cycle_len=8, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85), best_save_name='Hirano3D_v1_dn121_8bit_bs32_sz224_v2_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fc1be3478242bbbb182d061a625eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 112                                                                                                                                                                                    \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.031391   1.463439   0.644578  \n",
      "EPOCH 1 ---------------------------------------- STEP 113                                                                                                                                                                                    \n",
      "    1      0.030422   1.452      0.662651  \n",
      "EPOCH 2 ---------------------------------------- STEP 114                                                                                                                                                                                    \n",
      "    2      0.025333   1.463051   0.63253   \n",
      "EPOCH 3 ---------------------------------------- STEP 115                                                                                                                                                                                    \n",
      "    3      0.033577   1.438728   0.662651  \n",
      "EPOCH 4 ---------------------------------------- STEP 116                                                                                                                                                                                    \n",
      "    4      0.034229   1.423751   0.656627  \n",
      "EPOCH 5 ---------------------------------------- STEP 117                                                                                                                                                                                    \n",
      "    5      0.029219   1.381927   0.674699  \n",
      "EPOCH 6 ---------------------------------------- STEP 118                                                                                                                                                                                    \n",
      "    6      0.027344   1.403442   0.638554  \n",
      "EPOCH 7 ---------------------------------------- STEP 119                                                                                                                                                                                    \n",
      "    7      0.029142   1.434419   0.638554  \n",
      "EPOCH 8 ---------------------------------------- STEP 120                                                                                                                                                                                    \n",
      "    8      0.024983   1.431436   0.638554  \n",
      "EPOCH 9 ---------------------------------------- STEP 121                                                                                                                                                                                    \n",
      "    9      0.022068   1.474119   0.626506  \n",
      "EPOCH 10 ---------------------------------------- STEP 122                                                                                                                                                                                   \n",
      "    10     0.020814   1.474065   0.626506  \n",
      "EPOCH 11 ---------------------------------------- STEP 123                                                                                                                                                                                   \n",
      "    11     0.020678   1.438406   0.63253   \n",
      "EPOCH 12 ---------------------------------------- STEP 124                                                                                                                                                                                   \n",
      "    12     0.023108   1.444731   0.620482  \n",
      "EPOCH 13 ---------------------------------------- STEP 125                                                                                                                                                                                   \n",
      "    13     0.021416   1.487357   0.620482  \n",
      "EPOCH 14 ---------------------------------------- STEP 126                                                                                                                                                                                   \n",
      "    14     0.018698   1.451188   0.638554  \n",
      "EPOCH 15 ---------------------------------------- STEP 127                                                                                                                                                                                   \n",
      "    15     0.020846   1.495268   0.608434  \n",
      "EPOCH 16 ---------------------------------------- STEP 128                                                                                                                                                                                   \n",
      "    16     0.021926   1.471675   0.63253   \n",
      "EPOCH 17 ---------------------------------------- STEP 129                                                                                                                                                                                   \n",
      "    17     0.021894   1.503955   0.644578  \n",
      "EPOCH 18 ---------------------------------------- STEP 130                                                                                                                                                                                   \n",
      "    18     0.023119   1.467087   0.626506  \n",
      "EPOCH 19 ---------------------------------------- STEP 131                                                                                                                                                                                   \n",
      "    19     0.020323   1.479508   0.638554  \n",
      "EPOCH 20 ---------------------------------------- STEP 132                                                                                                                                                                                   \n",
      "    20     0.017686   1.517707   0.626506  \n",
      "EPOCH 21 ---------------------------------------- STEP 133                                                                                                                                                                                   \n",
      "    21     0.017031   1.549383   0.63253   \n",
      "EPOCH 22 ---------------------------------------- STEP 134                                                                                                                                                                                   \n",
      "    22     0.019827   1.494752   0.638554  \n",
      "EPOCH 23 ---------------------------------------- STEP 135                                                                                                                                                                                   \n",
      "    23     0.018927   1.517919   0.650602  \n",
      "EPOCH 24 ---------------------------------------- STEP 136                                                                                                                                                                                   \n",
      "    24     0.02029    1.528405   0.626506  \n",
      "EPOCH 25 ---------------------------------------- STEP 137                                                                                                                                                                                   \n",
      "    25     0.021738   1.439846   0.650602  \n",
      "EPOCH 26 ---------------------------------------- STEP 138                                                                                                                                                                                   \n",
      "    26     0.019862   1.545299   0.650602  \n",
      "EPOCH 27 ---------------------------------------- STEP 139                                                                                                                                                                                   \n",
      "    27     0.020244   1.568948   0.644578  \n",
      "EPOCH 28 ---------------------------------------- STEP 140                                                                                                                                                                                   \n",
      "    28     0.018252   1.507957   0.650602  \n",
      "EPOCH 29 ---------------------------------------- STEP 141                                                                                                                                                                                   \n",
      "    29     0.01562    1.494476   0.644578  \n",
      "EPOCH 30 ---------------------------------------- STEP 142                                                                                                                                                                                   \n",
      "    30     0.015767   1.504309   0.638554  \n",
      "EPOCH 31 ---------------------------------------- STEP 143                                                                                                                                                                                   \n",
      "    31     0.016884   1.526849   0.644578  \n",
      "\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n",
      "Wall time: 13min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.52685]), 0.6445783139711403]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(5e-5, 4, cycle_len=8, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85), best_save_name='Hirano3D_v1_dn121_8bit_bs32_sz224_v2_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f376ad0e057a42729eac68eba3100fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 144                                                                                                                                                                                    \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.026007   1.542364   0.650602  \n",
      "EPOCH 1 ---------------------------------------- STEP 145                                                                                                                                                                                    \n",
      "    1      0.019589   1.562376   0.644578  \n",
      "EPOCH 2 ---------------------------------------- STEP 146                                                                                                                                                                                    \n",
      "    2      0.019904   1.573586   0.63253   \n",
      "EPOCH 3 ---------------------------------------- STEP 147                                                                                                                                                                                    \n",
      "    3      0.01647    1.539182   0.656627  \n",
      "EPOCH 4 ---------------------------------------- STEP 148                                                                                                                                                                                    \n",
      "    4      0.0142     1.531706   0.644578  \n",
      "EPOCH 5 ---------------------------------------- STEP 149                                                                                                                                                                                    \n",
      "    5      0.014535   1.47262    0.662651  \n",
      "EPOCH 6 ---------------------------------------- STEP 150                                                                                                                                                                                    \n",
      "    6      0.015209   1.502142   0.644578  \n",
      "EPOCH 7 ---------------------------------------- STEP 151                                                                                                                                                                                    \n",
      "    7      0.020224   1.539182   0.638554  \n",
      "EPOCH 8 ---------------------------------------- STEP 152                                                                                                                                                                                    \n",
      "    8      0.01913    1.492718   0.644578  \n",
      "EPOCH 9 ---------------------------------------- STEP 153                                                                                                                                                                                    \n",
      "    9      0.016918   1.491396   0.650602  \n",
      "EPOCH 10 ---------------------------------------- STEP 154                                                                                                                                                                                   \n",
      "    10     0.014369   1.525694   0.650602  \n",
      "EPOCH 11 ---------------------------------------- STEP 155                                                                                                                                                                                   \n",
      "    11     0.015583   1.532812   0.662651  \n",
      "EPOCH 12 ---------------------------------------- STEP 156                                                                                                                                                                                   \n",
      "    12     0.012939   1.522629   0.650602  \n",
      "EPOCH 13 ---------------------------------------- STEP 157                                                                                                                                                                                   \n",
      "    13     0.011378   1.530263   0.638554  \n",
      "EPOCH 14 ---------------------------------------- STEP 158                                                                                                                                                                                   \n",
      "    14     0.011199   1.493426   0.662651  \n",
      "EPOCH 15 ---------------------------------------- STEP 159                                                                                                                                                                                   \n",
      "    15     0.012461   1.494609   0.644578  \n",
      "EPOCH 16 ---------------------------------------- STEP 160                                                                                                                                                                                   \n",
      "    16     0.011725   1.522897   0.638554  \n",
      "EPOCH 17 ---------------------------------------- STEP 161                                                                                                                                                                                   \n",
      "    17     0.010921   1.527339   0.626506  \n",
      "EPOCH 18 ---------------------------------------- STEP 162                                                                                                                                                                                   \n",
      "    18     0.010557   1.51268    0.644578  \n",
      "EPOCH 19 ---------------------------------------- STEP 163                                                                                                                                                                                   \n",
      "    19     0.010479   1.546814   0.656627  \n",
      "EPOCH 20 ---------------------------------------- STEP 164                                                                                                                                                                                   \n",
      "    20     0.01249    1.536716   0.656627  \n",
      "EPOCH 21 ---------------------------------------- STEP 165                                                                                                                                                                                   \n",
      "    21     0.014199   1.521626   0.650602  \n",
      "EPOCH 22 ---------------------------------------- STEP 166                                                                                                                                                                                   \n",
      "    22     0.013483   1.55384    0.638554  \n",
      "EPOCH 23 ---------------------------------------- STEP 167                                                                                                                                                                                   \n",
      "    23     0.014847   1.534217   0.620482  \n",
      "EPOCH 24 ---------------------------------------- STEP 168                                                                                                                                                                                   \n",
      "    24     0.014255   1.566986   0.626506  \n",
      "EPOCH 25 ---------------------------------------- STEP 169                                                                                                                                                                                   \n",
      "    25     0.01258    1.556585   0.638554  \n",
      "EPOCH 26 ---------------------------------------- STEP 170                                                                                                                                                                                   \n",
      "    26     0.011959   1.545557   0.662651  \n",
      "EPOCH 27 ---------------------------------------- STEP 171                                                                                                                                                                                   \n",
      "    27     0.011493   1.505259   0.650602  \n",
      "EPOCH 28 ---------------------------------------- STEP 172                                                                                                                                                                                   \n",
      "    28     0.012854   1.571918   0.638554  \n",
      "EPOCH 29 ---------------------------------------- STEP 173                                                                                                                                                                                   \n",
      "    29     0.01096    1.539723   0.63253   \n",
      "EPOCH 30 ---------------------------------------- STEP 174                                                                                                                                                                                   \n",
      "    30     0.011069   1.53293    0.656627  \n",
      "EPOCH 31 ---------------------------------------- STEP 175                                                                                                                                                                                   \n",
      "    31     0.010922   1.500591   0.638554  \n",
      "\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n",
      "Wall time: 12min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.50059]), 0.6385542175855982]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-5, 4, cycle_len=8, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85), best_save_name='Hirano3D_v1_dn121_8bit_bs32_sz224_v2_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2112d0816af45448f8072880edea7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 176                                                                                                                                                                                    \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.011268   1.535957   0.662651  \n",
      "EPOCH 1 ---------------------------------------- STEP 177                                                                                                                                                                                    \n",
      "    1      0.012036   1.481114   0.656627  \n",
      "EPOCH 2 ---------------------------------------- STEP 178                                                                                                                                                                                    \n",
      "    2      0.010604   1.524911   0.644578  \n",
      "EPOCH 3 ---------------------------------------- STEP 179                                                                                                                                                                                    \n",
      "    3      0.009953   1.524801   0.638554  \n",
      "EPOCH 4 ---------------------------------------- STEP 180                                                                                                                                                                                    \n",
      "    4      0.010125   1.540579   0.638554  \n",
      "EPOCH 5 ---------------------------------------- STEP 181                                                                                                                                                                                    \n",
      "    5      0.010809   1.550329   0.668675  \n",
      "EPOCH 6 ---------------------------------------- STEP 182                                                                                                                                                                                    \n",
      "    6      0.012468   1.550932   0.644578  \n",
      "EPOCH 7 ---------------------------------------- STEP 183                                                                                                                                                                                    \n",
      "    7      0.012047   1.534303   0.662651  \n",
      "EPOCH 8 ---------------------------------------- STEP 184                                                                                                                                                                                    \n",
      "    8      0.011378   1.573331   0.668675  \n",
      "EPOCH 9 ---------------------------------------- STEP 185                                                                                                                                                                                    \n",
      "    9      0.011927   1.495101   0.656627  \n",
      "EPOCH 10 ---------------------------------------- STEP 186                                                                                                                                                                                   \n",
      "    10     0.010416   1.543531   0.644578  \n",
      "EPOCH 11 ---------------------------------------- STEP 187                                                                                                                                                                                   \n",
      "    11     0.010282   1.55693    0.668675  \n",
      "EPOCH 12 ---------------------------------------- STEP 188                                                                                                                                                                                   \n",
      "    12     0.010384   1.567105   0.650602  \n",
      "EPOCH 13 ---------------------------------------- STEP 189                                                                                                                                                                                   \n",
      "    13     0.009663   1.539425   0.644578  \n",
      "EPOCH 14 ---------------------------------------- STEP 190                                                                                                                                                                                   \n",
      "    14     0.008921   1.559439   0.638554  \n",
      "EPOCH 15 ---------------------------------------- STEP 191                                                                                                                                                                                   \n",
      "    15     0.008929   1.578817   0.626506  \n",
      "EPOCH 16 ---------------------------------------- STEP 192                                                                                                                                                                                   \n",
      "    16     0.010128   1.548074   0.626506  \n",
      "EPOCH 17 ---------------------------------------- STEP 193                                                                                                                                                                                   \n",
      "    17     0.010518   1.549719   0.644578  \n",
      "EPOCH 18 ---------------------------------------- STEP 194                                                                                                                                                                                   \n",
      "    18     0.012092   1.509832   0.668675  \n",
      "EPOCH 19 ---------------------------------------- STEP 195                                                                                                                                                                                   \n",
      "    19     0.01537    1.531072   0.662651  \n",
      "EPOCH 20 ---------------------------------------- STEP 196                                                                                                                                                                                   \n",
      "    20     0.01571    1.559058   0.668675  \n",
      "EPOCH 21 ---------------------------------------- STEP 197                                                                                                                                                                                   \n",
      "    21     0.013208   1.506438   0.650602  \n",
      "EPOCH 22 ---------------------------------------- STEP 198                                                                                                                                                                                   \n",
      "    22     0.01199    1.509008   0.662651  \n",
      "EPOCH 23 ---------------------------------------- STEP 199                                                                                                                                                                                   \n",
      "    23     0.012044   1.54214    0.644578  \n",
      "EPOCH 24 ---------------------------------------- STEP 200                                                                                                                                                                                   \n",
      "    24     0.014179   1.507624   0.650602  \n",
      "EPOCH 25 ---------------------------------------- STEP 201                                                                                                                                                                                   \n",
      "    25     0.012094   1.49565    0.656627  \n",
      "EPOCH 26 ---------------------------------------- STEP 202                                                                                                                                                                                   \n",
      "    26     0.011574   1.532616   0.650602  \n",
      "EPOCH 27 ---------------------------------------- STEP 203                                                                                                                                                                                   \n",
      "    27     0.011492   1.565867   0.650602  \n",
      "EPOCH 28 ---------------------------------------- STEP 204                                                                                                                                                                                   \n",
      "    28     0.010936   1.567048   0.644578  \n",
      "EPOCH 29 ---------------------------------------- STEP 205                                                                                                                                                                                   \n",
      "    29     0.011268   1.556188   0.638554  \n",
      "EPOCH 30 ---------------------------------------- STEP 206                                                                                                                                                                                   \n",
      "    30     0.011204   1.509924   0.662651  \n",
      "EPOCH 31 ---------------------------------------- STEP 207                                                                                                                                                                                   \n",
      "    31     0.010119   1.555196   0.656627  \n",
      "\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n",
      "Wall time: 12min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.5552]), 0.6566265067422247]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(5e-6, 4, cycle_len=8, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85), best_save_name='Hirano3D_v1_dn121_8bit_bs32_sz224_v2_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(1e-5, 4, cycle_len=8, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85), best_save_name='Hirano3D_v1_dn121_8bit_bs32_sz224_v2_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(1e-4, 2, cycle_len=16, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85), best_save_name='Hirano3D_v1_dn121_8bit_bs32_sz224_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time learn.fit(1e-3, 2, cycle_len=16, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time learn.fit(6e-4, 2, cycle_len=16, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-10\n",
    "%time learn.fit(6e-4, 2, cycle_len=16, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define augmentations\n",
    "augs = [RandomDihedral()]\n",
    "NUM_CLASSES = 4\n",
    "bs = 64\n",
    "sz = [4,256,256]\n",
    "lbl_csv = path + '8bit_multi_folder_Hirano3D_v1.csv'\n",
    "# initialize data object\n",
    "data_64_256 = get_data(PATH, lbl_csv, val_idxs, sz, bs, aug_tfms = augs)\n",
    "learn.set_data(data_64_256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(1e-3, 1, cycle_len=4, wds=wd, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time learn.fit(1e-3, 1, cycle_len=24, wds=wd, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(1e-2, 5, wds=wd, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(8e-3, 6, wds=wd, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time learn.fit(1e-3, 2, cycle_len=8, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time learn.fit(8e-4, 1, cycle_len=16, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time learn.fit(3e-4, 1, cycle_len=16, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(1e-4, 1, cycle_len=16, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('Hirano3D_v1_dn121_bs128_128_1_42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define augmentations\n",
    "augs = [RandomDihedral()]\n",
    "NUM_CLASSES = 4\n",
    "bs = 64\n",
    "sz = [4,128,128]\n",
    "\n",
    "lbl_csv = path + '8bit_multi_folder_Hirano3D_v1.csv'\n",
    "# initialize data object\n",
    "data_64_128 = get_data(PATH, lbl_csv, val_idxs, sz, bs, aug_tfms = augs)\n",
    "learn.set_data(data_64_128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find2()\n",
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_per_iter = [[i, learn.sched.losses[idx], learn.sched.lrs[idx]] for idx, i in enumerate(learn.sched.iterations)]\n",
    "_per_iter = pd.DataFrame(per_iter, columns=['Iteration', 'trn_loss', 'lr'])\n",
    "per_iter_df.append(_per_iter)\n",
    "\n",
    "if learn.sched.glob_step: \n",
    "    per_iter_df = _per_iter\n",
    "    print('created')\n",
    "else: \n",
    "    per_iter_df.append(_per_iter)\n",
    "    print('appended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(1e-2, 2, cycle_len=1, wds=wd, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.Glob_lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(1e-4, 8, cycle_len=1, wds=wd, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time learn.fit(1e-5, 4, cycle_len=8, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(1e-4, 2, cycle_len=16, cycle_mult=2, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time learn.fit(2e-5, 1, cycle_len=8, cycle_mult=2, wds=wd, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = (5e-4, 1e-3, 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = [4,516, 516]\n",
    "learn.set_data(get_data(PATH, lbl_csv, val_idxs, sz, bs, aug_tfms = augs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time learn.fit(1e-3, 1, cycle_len=8, cycle_mult=2, wds=wd, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(1e-3, 2, cycle_len=8, wds=wd, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('Hirano3D_v1_ResNet18_512_72')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test-predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('Hirano3D_v1_dn121_8bit_bs32_sz224_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb7d29f49dd47318723c9bfe0d1d404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 208                                                                                                                                                                                    \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.245818   1.127193   0.572289  \n",
      "\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/Hirano3D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.12719]), 0.5722891559083778]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.warm_up(1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.predict_with_targs()\n",
    "preds = np.argmax(log_preds, axis=1)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                             \r"
     ]
    }
   ],
   "source": [
    "log_preds, y =  learn.TTA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  4  7  6]\n",
      " [ 2 24  6  4]\n",
      " [11  2 29  6]\n",
      " [ 8  4  4 18]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix \n",
    "plt.style.use('seaborn-white')\n",
    "log_preds_mean = np.mean(log_preds, axis=0)\n",
    "preds = np.argmax(log_preds_mean, axis=1)\n",
    "cm = confusion_matrix(preds,y)\n",
    "plot_confusion_matrix(cm, data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y =  learn.TTA(is_test=True)\n",
    "log_preds_mean = np.mean(log_preds, axis=0)\n",
    "preds = np.argmax(log_preds_mean, axis=1)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0', Sequential(\n",
       "                (conv0): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "                (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "                (relu0): ReLU(inplace)\n",
       "                (pool0): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
       "                (denseblock1): _DenseBlock(\n",
       "                  (denselayer1): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer2): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer3): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer4): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer5): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer6): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (transition1): _Transition(\n",
       "                  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "                  (relu): ReLU(inplace)\n",
       "                  (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "                )\n",
       "                (denseblock2): _DenseBlock(\n",
       "                  (denselayer1): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer2): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer3): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer4): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer5): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer6): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer7): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer8): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer9): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer10): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer11): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer12): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (transition2): _Transition(\n",
       "                  (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "                  (relu): ReLU(inplace)\n",
       "                  (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "                )\n",
       "                (denseblock3): _DenseBlock(\n",
       "                  (denselayer1): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer2): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer3): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer4): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer5): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer6): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer7): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer8): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer9): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer10): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer11): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer12): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer13): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer14): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer15): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer16): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer17): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer18): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer19): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer20): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer21): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer22): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer23): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer24): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (transition3): _Transition(\n",
       "                  (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "                  (relu): ReLU(inplace)\n",
       "                  (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "                )\n",
       "                (denseblock4): _DenseBlock(\n",
       "                  (denselayer1): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer2): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer3): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer4): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer5): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer6): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer7): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer8): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer9): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer10): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer11): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer12): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer13): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer14): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer15): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                  (denselayer16): _DenseLayer(\n",
       "                    (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu1): ReLU(inplace)\n",
       "                    (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "                    (relu2): ReLU(inplace)\n",
       "                    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "              )), ('1', AdaptiveConcatPool2d(\n",
       "                (ap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "                (mp): AdaptiveMaxPool2d(output_size=(1, 1))\n",
       "              )), ('2', Flatten(\n",
       "              )), ('3',\n",
       "              BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True)), ('4',\n",
       "              Linear(in_features=2048, out_features=512, bias=True)), ('5',\n",
       "              ReLU()), ('6',\n",
       "              BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)), ('7',\n",
       "              Linear(in_features=512, out_features=4, bias=True)), ('8',\n",
       "              LogSoftmax())])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.models.model._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to be called by register_forward_hook\n",
    "\n",
    "def get_embeddings(layer_name):\n",
    "    def register_hook(layer_name):\n",
    "        def get_embedding(layer, inp, outp):\n",
    "            tmp = inp[0]\n",
    "            embedding.append(tmp)\n",
    "\n",
    "        hook = layer.register_forward_hook(get_embedding) \n",
    "        \n",
    "        for i in ['trn', 'val', 'test']:\n",
    "            embedding = []\n",
    "            preds, y = learn.predict_with_targs(i)\n",
    "            \n",
    "            # populating dict, consiting of [0]: preds, [1]: y, [2]: activations[layer]\n",
    "            embeddings[i] = [preds, y, np.vstack(to_np(embedding))]\n",
    "            \n",
    "        hook.remove()\n",
    "        \n",
    "    embeddings = {}    \n",
    "    layer = learn.models.model._modules.get(layer_name)\n",
    "    register_hook(layer)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embeddings('7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(664, 512)\n",
      "(166, 512)\n",
      "(60, 512)\n",
      "(664,)\n",
      "(166,)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "# unpacking embeddings\n",
    "\n",
    "embs_trn = embeddings['trn'][2]\n",
    "y_trn = embeddings['trn'][1]\n",
    "\n",
    "embs_val = embeddings['val'][2]\n",
    "y_val = embeddings['val'][1]\n",
    "\n",
    "embs_test = embeddings['test'][2]\n",
    "y_test = embeddings['test'][1]\n",
    "\n",
    "print(embs_trn.shape)\n",
    "print(embs_val.shape)\n",
    "print(embs_test.shape)\n",
    "\n",
    "print(y_trn.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMAP_trn_embedding = umap.UMAP(n_neighbors=10,\n",
    "                      min_dist=0.3,\n",
    "                      metric='correlation').fit(embs_trn)\n",
    "\n",
    "UMAP_trn = UMAP_trn_embedding.embedding_\n",
    "UMAP_val = UMAP_trn_embedding.transform(embs_val)\n",
    "UMAP_test = UMAP_trn_embedding.transform(embs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.test_ds.fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.zeros(60)\n",
    "y_test[:30] = y_test[:30] +1 \n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e14eb3254ea9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# plotting PCA vs TSNE results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcompA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# plotting PCA vs TSNE results\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "compA = 0\n",
    "compB = 1\n",
    "\n",
    "for i in range(4):\n",
    "    trn_UMAP_cls = UMAP_trn[y_trn == i]\n",
    "\n",
    "    axarr[0].scatter(trn_UMAP_cls[:,compA], trn_UMAP_cls[:,compB], label = data.classes[i], s = 5)\n",
    "    axarr[0].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "#     if i == 0:\n",
    "#         axarr[1].scatter(trn_UMAP_cls[:,compA], trn_UMAP_cls[:,compB], label = data.classes[i], s = 5)\n",
    "\n",
    "#     axarr[0].set_xlim(-10,5)\n",
    "#     axarr[0].set_ylim(-5,8)\n",
    "    \n",
    "for i in range(4):\n",
    "    test_UMAP_cls = UMAP_val[y_val == i]\n",
    "    \n",
    "    axarr[1].scatter(test_UMAP_cls[:,compA], test_UMAP_cls[:,compB], s = 5)\n",
    "    axarr[1].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#     axarr[1].set_xlim(-10,5)\n",
    "#     axarr[1].set_ylim(-5,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_th(preds, targs, start=0.2, end=0.6, step=0.05):\n",
    "    ths = np.arange(start,end,step)\n",
    "    res = [f1_macro(preds, targs, thresh=th, kind='macro') for th in ths]\n",
    "    idx = np.argmax(res)\n",
    "    return ths[idx], res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train predictions\n",
    "\n",
    "preds_trn, targs_trn =  learn.predict_with_targs('trn')\n",
    "\n",
    "preds_trn_torch = torch.from_numpy(preds_trn)\n",
    "targs_trn_torch = torch.from_numpy(targs_trn)\n",
    "\n",
    "opt_th(preds_trn_torch, targs_trn_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds_val_torch[0])\n",
    "print(preds_trn_torch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get val predictions\n",
    "\n",
    "preds_val, targs_val =  learn.predict_with_targs('val')\n",
    "\n",
    "preds_val_torch = torch.from_numpy(preds_val)\n",
    "targs_val_torch = torch.from_numpy(targs_val)\n",
    "\n",
    "opt_th(preds_val_torch, targs_val_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test predictions\n",
    "\n",
    "preds_test, targs_test =  learn.predict_with_targs('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targs_test[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_epoch(dl = data.trn_dl):\n",
    "    \n",
    "    batch = iter(dl)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "#     for b in range(0,len(dl)):\n",
    "    for b in range(0,10):\n",
    "\n",
    "        x_, y_ = next(batch)\n",
    "        x_np, y_np = to_np(x_), to_np(y_)\n",
    "        xs.append(x_np)\n",
    "        ys.append(y_np)\n",
    "\n",
    "    return np.vstack(xs), np.concatenate(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_dl.sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = data.test_ds.fnames\n",
    "test_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(preds_file, output_name, th = 0.3, TTA=False):\n",
    "    \n",
    "    # creating submission file\n",
    "    \n",
    "    if TTA:\n",
    "        preds = preds_file.mean(axis=0)\n",
    "        print('TTA:',preds.shape)\n",
    "    else: preds = preds_file\n",
    "    \n",
    "    clss = np.arange(0, len(data.classes)) # get class indeces\n",
    "    res = np.array([' '.join(np.char.mod('%d', clss[np.where(p > th)])) for p in preds]) # generating output\n",
    "\n",
    "    # ensure that there are no empty cells: in case no value > thresh, fill in with argmax()\n",
    "    for i in range(res.shape[0]):\n",
    "        if res[i] == '':\n",
    "            res[i] = preds[i].argmax()\n",
    "\n",
    "    # getting image Ids\n",
    "    fnames = np.array([os.path.basename(im).split('.')[0] for im in data.test_ds.fnames])\n",
    "\n",
    "    # creating submission file\n",
    "    sub_df = pd.DataFrame(res, index=fnames, columns=['Predicted'])\n",
    "    sub_df.to_csv(output_name, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = PATH + 'submissions/Res18_pre_0.42_t-03.csv'\n",
    "\n",
    "create_submission(log_preds, submission_name, th=0.3, TTA=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of label identities:\n",
    "\n",
    "cell_location_label = {\n",
    "0:  'Nucleoplasm',\n",
    "1:  'Nuclear membrane',\n",
    "2:  'Nucleoli',   \n",
    "3:  'Nucleoli fibrillar center',\n",
    "4:  'Nuclear speckles',\n",
    "5:  'Nuclear bodies',\n",
    "6:  'Endoplasmic reticulum',   \n",
    "7:  'Golgi apparatus',\n",
    "8:  'Peroxisomes',\n",
    "9:  'Endosomes',\n",
    "10:  'Lysosomes',\n",
    "11:  'Intermediate filaments',\n",
    "12:  'Actin filaments',\n",
    "13:  'Focal adhesion sites',   \n",
    "14:  'Microtubules',\n",
    "15:  'Microtubule ends',  \n",
    "16:  'Cytokinetic bridge',   \n",
    "17:  'Mitotic spindle',\n",
    "18:  'Microtubule organizing center',  \n",
    "19:  'Centrosome',\n",
    "20:  'Lipid droplets',\n",
    "21:  'Plasma membrane',   \n",
    "22:  'Cell junctions', \n",
    "23:  'Mitochondria',\n",
    "24:  'Aggresome',\n",
    "25:  'Cytosol',\n",
    "26:  'Cytoplasmic bodies',   \n",
    "27:  'Rods & rings' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# thresholds = np.linspace(0, 1, 1000)\n",
    "# score = 0.0\n",
    "# test_threshold=0.5*np.ones(28)\n",
    "# best_threshold=np.zeros(28)\n",
    "# best_val = np.zeros(28)\n",
    "# for i in range(28):\n",
    "#     for threshold in thresholds:\n",
    "#         test_threshold[i] = threshold\n",
    "#         max_val = np.max(preds_y)\n",
    "#         val_predict = (preds_y > test_threshold)\n",
    "#         score = f1_score(valid_y > 0.5, val_predict, average='macro')\n",
    "#         if score > best_val[i]:\n",
    "#             best_threshold[i] = threshold\n",
    "#             best_val[i] = score\n",
    "#     print(\"Threshold[%d] %0.6f, F1: %0.6f\" % (i,best_threshold[i],best_val[i]))\n",
    "#     test_threshold[i] = best_threshold[i]\n",
    "# print(\"Best threshold: \")\n",
    "# print(best_threshold)\n",
    "# print(\"Best f1:\")\n",
    "# print(best_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
