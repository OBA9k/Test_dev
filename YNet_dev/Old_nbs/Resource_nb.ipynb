{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-prep: shuffle images and generate train, test and optionally val datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from __future__ import division\n",
    "\n",
    "\n",
    "np.random.seed(1) #reproducible randomness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to unzip more data\n",
    "\n",
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('Yeast_ML_EXP1/Zip_files/Mfb1KO_175.zip', 'r')\n",
    "zip_ref.extractall('Yeast_ML_EXP1/train/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350,)\n",
      "175\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import glob\n",
    "\n",
    "shuffle_data = True  # shuffle the addresses before saving\n",
    "hdf5_path = 'Yeast_ML_EXP1/dataset.hdf5'  # address to where you want to save the hdf5 file\n",
    "WT_v_Mfb1KO_train_path = 'Yeast_ML_EXP1/train/*.tif'\n",
    "\n",
    "# read addresses and labels from the 'train' folder\n",
    "addrs = glob.glob(WT_v_Mfb1KO_train_path)\n",
    "labels = [0 if 'WT' in addr else 1 for addr in addrs]  # 0 = WT, 1 = Mfb1KO\n",
    "\n",
    "# to shuffle data\n",
    "if shuffle_data:\n",
    "    c = list(zip(addrs, labels))\n",
    "    shuffle(c)\n",
    "    addrs, labels = zip(*c)\n",
    "    \n",
    "# Divide the hata into 60% train, 20% validation, and 20% test\n",
    "train_addrs = addrs[0:int(0.6*len(addrs))]\n",
    "train_labels = labels[0:int(0.6*len(labels))]\n",
    "val_addrs = addrs[int(0.6*len(addrs)):int(0.8*len(addrs))]\n",
    "val_labels = labels[int(0.6*len(addrs)):int(0.8*len(addrs))]\n",
    "test_addrs = addrs[int(0.8*len(addrs)):]\n",
    "test_labels = labels[int(0.8*len(labels)):]\n",
    "\n",
    "labels_check = np.array(labels)\n",
    "print (labels_check.shape) #correct size?\n",
    "print (np.sum(labels_check)) #correct number of 1 and 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/test_labels (Array(70,)) ''\n",
       "  atom := Int64Atom(shape=(), dflt=0)\n",
       "  maindim := 0\n",
       "  flavor := 'python'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating HDF5 file\n",
    "\n",
    "import tables\n",
    "\n",
    "data_order = 'tf'  # 'th' for Theano, 'tf' for Tensorflow\n",
    "img_dtype = tables.UInt16Atom()  # dtype in which the images will be saved\n",
    "\n",
    "# check the order of data and chose proper data shape to save images\n",
    "if data_order == 'th':\n",
    "    data_shape = (0, 2, 200, 200)\n",
    "elif data_order == 'tf':\n",
    "    data_shape = (0, 200, 200, 2)\n",
    "    \n",
    "# open a hdf5 file and create earrays\n",
    "hdf5_file = tables.open_file(hdf5_path, mode='w')\n",
    "train_storage = hdf5_file.create_earray(hdf5_file.root, 'train_img', img_dtype, shape=data_shape)\n",
    "val_storage = hdf5_file.create_earray(hdf5_file.root, 'val_img', img_dtype, shape=data_shape)\n",
    "test_storage = hdf5_file.create_earray(hdf5_file.root, 'test_img', img_dtype, shape=data_shape)\n",
    "mean_storage = hdf5_file.create_earray(hdf5_file.root, 'train_mean', img_dtype, shape=data_shape)\n",
    "\n",
    "# create the label arrays and copy the labels data in them\n",
    "hdf5_file.create_array(hdf5_file.root, 'train_labels', train_labels)\n",
    "hdf5_file.create_array(hdf5_file.root, 'val_labels', val_labels)\n",
    "hdf5_file.create_array(hdf5_file.root, 'test_labels', test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n"
     ]
    }
   ],
   "source": [
    "#closing the dataset.hdf5 file in case you want to recreate\n",
    "#hdf5_file.close()\n",
    "#print (data_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 100/210\n",
      "Train data: 200/210\n"
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "from skimage import transform\n",
    "\n",
    "# a numpy array to save the mean of the images\n",
    "mean = np.zeros(data_shape[1:], np.float32)\n",
    "\n",
    "# loop over train addresses\n",
    "for i in range(len(train_addrs)):\n",
    "    \n",
    "    # print how many images are saved every 100 images\n",
    "    if i % 100 == 0 and i > 1:\n",
    "        print 'Train data: {}/{}'.format(i, len(train_addrs))\n",
    "        \n",
    "    # read an image and resize to (2,64, 64)\n",
    "    addr = train_addrs[i]\n",
    "    img = io.imread(addr)\n",
    "    #img = transform.resize(img, (2,64,64))\n",
    "    \n",
    "    # add any image pre-processing here\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    if data_order == 'tf':\n",
    "        img = np.moveaxis(img, 0,-1) #Check the reorder condition - it has nothing to do with tensorflow or theano atm. \n",
    "        \n",
    "    # save the image and calculate the mean so far\n",
    "    train_storage.append(img[None])\n",
    "    mean += img / float(len(train_labels))\n",
    "    \n",
    "# loop over validation addresses\n",
    "for i in range(len(val_addrs)):\n",
    "    \n",
    "    # print how many images are saved every 100 images\n",
    "    if i % 100 == 0 and i > 1:\n",
    "        print 'Validation data: {}/{}'.format(i, len(val_addrs))\n",
    "        \n",
    "    # read an image and resize to (2,64,64)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = val_addrs[i]\n",
    "    img = io.imread(addr)\n",
    "    #img = transform.resize(img, (2,64, 64))\n",
    "    \n",
    "    # add any image pre-processing here\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    if data_order == 'tf':\n",
    "        img = np.moveaxis(img, 0,-1)\n",
    "        \n",
    "    # save the image\n",
    "    val_storage.append(img[None])\n",
    "    \n",
    "# loop over test addresses\n",
    "for i in range(len(test_addrs)):\n",
    "    \n",
    "    # print how many images are saved every 100 images\n",
    "    if i % 100 == 0 and i > 1:\n",
    "        print 'Test data: {}/{}'.format(i, len(test_addrs))\n",
    "        \n",
    "    # read an image and resize to (2,64,64)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    addr = test_addrs[i]\n",
    "    img = io.imread(addr)\n",
    "    #img = transform.resize(img, (2,64,64))\n",
    "    \n",
    "    # add any image pre-processing here\n",
    "    # if the data order is Theano, axis orders should change\n",
    "    if data_order == 'tf':\n",
    "        img = np.moveaxis(img, 0,-1)\n",
    "        \n",
    "    # save the image\n",
    "    test_storage.append(img[None])\n",
    "    \n",
    "# save the mean and close the hdf5 file\n",
    "mean_storage.append(mean[None])\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from skimage import io\n",
    "#from skimage import transform\n",
    "#im = io.imread('WT_WP_E1_S0_F1_I2_C1_A0.tif')\n",
    "#imresize = transform.resize(im,(2,64,64))\n",
    "#print (im.shape)\n",
    "\n",
    "#img = np.moveaxis(imresize, 0,-1)\n",
    "#print (img.shape)\n",
    "#plt.imshow(img[:,:,0])\n",
    "\n",
    "#addr = train_addrs[0]\n",
    "#imga = io.imread(addr)\n",
    "#imgb = transform.resize(imga, (2,64, 64))\n",
    "\n",
    "#imgc = np.moveaxis(imga, 0,-1)\n",
    "\n",
    "#print (imga.shape)\n",
    "#print (imgc.shape)\n",
    "\n",
    "#print (imga[0,0,:])\n",
    "#print (sum(imgc[0,:,1]))\n",
    "\n",
    "#plt.imshow(imga[1,:,:])\n",
    "#plt.imshow(imgc[:,:,1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#train_storage_test = [0,0,0]\n",
    "#train_storage_test.append(imgc[None])\n",
    "#print (train_storage_test)\n",
    "\n",
    "#hdf5_path = 'Yeast_ML_EXP1/dataset.hdf5'\n",
    "#hdf5_file = tables.open_file(hdf5_path, mode='r')\n",
    "\n",
    "#data_num = np.array(hdf5_file.root.train_img)\n",
    "#print (data_num.shape)\n",
    "#print (data_num[0,0,0,:])\n",
    "#plt.imshow(data_num[0,:,:,1])\n",
    "\n",
    "\n",
    "\n",
    "#hdf5_file.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
