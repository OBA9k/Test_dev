{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import skimage.external.tifffile as tiff\n",
    "\n",
    "from resources.conv_learner import * # important because our ResNet name needs to override theirs\n",
    "from resources.plots import *\n",
    "from common import Statistics, dataset_source\n",
    "from models import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../datasets/yeast_v4.1\"\n",
    "data_path = Path(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ('WT', 'mfb1KO', 'mfb1KO_mmr1KO', 'mmr1KO', )\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "BATCH_SIZE = 64\n",
    "SIZE = 200\n",
    "SEED = 5\n",
    "# set the seeds for experimentation\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on: Cit1_MC_WT\n",
      "working on: Cit1_MC_WT\n",
      "working on: Cit1_MC_mfb1KO_mmr1KO\n",
      "working on: Cit1_MC_mfb1KO_mmr1KO\n",
      "working on: Cit1_MC_mfb1KO\n",
      "working on: Cit1_MC_mfb1KO\n",
      "working on: Cit1_MC_mmr1KO\n",
      "working on: Cit1_MC_mmr1KO\n"
     ]
    }
   ],
   "source": [
    "stats_name = \"yeast_v5_per_class.dict\"\n",
    "classes = Statistics.source_class(data_path)\n",
    "stats_dict = Statistics.per_class(zip(classes['train'],classes['val']),save_name=stats_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path: str, sz, bs, stats):\n",
    "    create, lbl2index = ImageClassifierData.prepare_from_path(path, val_name='val', bs=bs)\n",
    "    stats_dict = {lbl2index[key]: val for key, val in stats.items()}\n",
    "    tfms = tfms_from_stats(stats_dict, sz, aug_tfms=[RandomDihedral()], pad=sz//8) #even without transformations and padding -> failure\n",
    "    print('\\n class to index mapping:\\n',lbl2index)\n",
    "    return create(tfms)\n",
    "\n",
    "### the eventual sub-function of ImageClassifierData (read_dirs) expects subdirectories for each class: \n",
    "### e.g. all \"test/cat.png\" images should be in a \"cat\" folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " class to index mapping:\n",
      " {'Cit1_MC_WT': 0, 'Cit1_MC_mfb1KO': 1, 'Cit1_MC_mfb1KO_mmr1KO': 2, 'Cit1_MC_mmr1KO': 3}\n"
     ]
    }
   ],
   "source": [
    "data = get_data(PATH,SIZE, BATCH_SIZE,stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/torch/cuda/__init__.py:97: UserWarning: \n",
      "    Found GPU0 GeForce GTX 960M which is of cuda capability 5.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(data.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/matplotlib/axes/_base.py:3124: UserWarning: Attempting to set identical left==right results\n",
      "in singular transformations; automatically expanding.\n",
      "left=0, right=0\n",
      "  'left=%s, right=%s') % (left, right))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 988.8x604.8 with 3 Axes>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x7fd14ec69208>,\n",
       " <matplotlib.image.AxesImage at 0x7fd14ebdd6d8>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 60\n",
    "trn_xs ,trn_ys = next(iter(data.trn_dl))\n",
    "trn_x = trn_xs[idx].cpu().numpy().copy()\n",
    "trn_y = trn_ys[idx]\n",
    "tiff.imshow(trn_x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(layers[i], layers[i + 1]) for i in range(len(layers) - 1)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        for l in self.layers:\n",
    "            l_x = l(x)\n",
    "            x = F.relu(l_x)\n",
    "        return F.log_softmax(l_x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(SimpleNet([200*200*2, 40, NUM_CLASSES]), data) #(!) change channel-number & classes accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn, [o.numel() for o in learn.model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(lr, 200, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(layers[i], layers[i + 1], kernel_size=5, stride=1, padding=(2,2))\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for l in self.layers: x = F.relu(l(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(ConvNet([2, 20, 40, 80], 6), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.summary() ### learner.summary is hardcording the number of channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(lr, 10, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet_with_Batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BnLayer(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=2, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni, nf, kernel_size=kernel_size, stride=stride,\n",
    "                              bias=False, padding=1)\n",
    "        self.a = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.m = nn.Parameter(torch.ones(nf,1,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x_chan = x.transpose(0,1).contiguous().view(x.size(1), -1)\n",
    "        if self.training:\n",
    "            self.means = x_chan.mean(1)[:,None,None]\n",
    "            self.stds  = x_chan.std (1)[:,None,None]\n",
    "        return (x-self.means) / self.stds *self.m + self.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetLayer(BnLayer):\n",
    "    def forward(self, x): return x + super().forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 10, kernel_size=5, stride=1, padding=2)\n",
    "        self.layers = nn.ModuleList([BnLayer(layers[i], layers[i+1])\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.layers2 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i + 1], 1)\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.layers3 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i + 1], 1)\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        for l,l2,l3 in zip(self.layers, self.layers2, self.layers3):\n",
    "            x = l3(l2(l(x)))\n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_hc = ConvLearner.from_model_data(Resnet([10, 20, 40, 80, 160], 6), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4714c2d5404448368c2a411c399ecd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 64.29%\n",
      "[2]:  0.0%\n",
      "[3]: 31.43%\n",
      "[4]: 100.0%\n",
      "[5]:  0.0%\n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      14.576533  25.149098  0.253968  \n",
      "EPOCH 1 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 42.86%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 50.0%\n",
      "[5]:  0.0%\n",
      "    1      7.969271   8.674541   0.257143  \n",
      "EPOCH 2 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 44.29%\n",
      "[2]:  0.0%\n",
      "[3]: 17.14%\n",
      "[4]: 50.0%\n",
      "[5]:  0.0%\n",
      "    2      4.889876   7.796872   0.247619  \n",
      "EPOCH 3 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 42.86%\n",
      "[2]:  0.0%\n",
      "[3]: 40.0%\n",
      "[4]: 58.57%\n",
      "[5]:  0.0%\n",
      "    3      3.534072   7.327427   0.260317  \n",
      "EPOCH 4 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 41.43%\n",
      "[2]:  0.0%\n",
      "[3]: 20.0%\n",
      "[4]: 62.86%\n",
      "[5]:  0.0%\n",
      "    4      2.878396   6.814866   0.279365  \n",
      "EPOCH 5 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 21.43%\n",
      "[1]: 37.14%\n",
      "[2]:  0.0%\n",
      "[3]: 22.86%\n",
      "[4]: 50.0%\n",
      "[5]:  0.0%\n",
      "    5      2.354189   5.769508   0.292063  \n",
      "EPOCH 6 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 75.71%\n",
      "[5]:  0.0%\n",
      "    6      1.927141   6.504669   0.346032  \n",
      "EPOCH 7 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 18.57%\n",
      "[1]: 20.0%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 77.14%\n",
      "[5]:  0.0%\n",
      "    7      1.655245   5.881834   0.298413  \n",
      "EPOCH 8 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 47.14%\n",
      "[1]: 2.857%\n",
      "[2]:  0.0%\n",
      "[3]: 8.571%\n",
      "[4]: 72.86%\n",
      "[5]: 28.57%\n",
      "    8      1.649219   3.49819    0.320635  \n",
      "EPOCH 9 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 44.29%\n",
      "[5]: 5.714%\n",
      "    9      1.567297   3.837852   0.339683  \n",
      "EPOCH 10 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 45.71%\n",
      "[2]:  0.0%\n",
      "[3]: 54.29%\n",
      "[4]: 41.43%\n",
      "[5]: 2.857%\n",
      "    10     1.414879   4.163393   0.346032  \n",
      "EPOCH 11 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 42.86%\n",
      "[1]: 14.29%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 40.0%\n",
      "[5]: 2.857%\n",
      "    11     1.265483   3.858004   0.301587  \n",
      "EPOCH 12 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 7.143%\n",
      "[1]: 67.14%\n",
      "[2]:  0.0%\n",
      "[3]: 25.71%\n",
      "[4]: 37.14%\n",
      "[5]: 5.714%\n",
      "    12     1.241508   4.148765   0.320635  \n",
      "EPOCH 13 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 52.86%\n",
      "[1]: 45.71%\n",
      "[2]:  0.0%\n",
      "[3]: 54.29%\n",
      "[4]: 48.57%\n",
      "[5]: 2.857%\n",
      "    13     1.257006   4.712028   0.387302  \n",
      "EPOCH 14 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 42.86%\n",
      "[1]: 17.14%\n",
      "[2]:  0.0%\n",
      "[3]: 54.29%\n",
      "[4]: 51.43%\n",
      "[5]: 8.571%\n",
      "    14     1.178745   4.662463   0.333333  \n",
      "EPOCH 15 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 50.0%\n",
      "[1]: 22.86%\n",
      "[2]:  0.0%\n",
      "[3]: 54.29%\n",
      "[4]: 41.43%\n",
      "[5]: 11.43%\n",
      "    15     1.061096   4.383353   0.32381   \n",
      "EPOCH 16 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 74.29%\n",
      "[1]: 7.143%\n",
      "[2]:  0.0%\n",
      "[3]: 57.14%\n",
      "[4]: 24.29%\n",
      "[5]: 2.857%\n",
      "    16     1.087308   6.001146   0.28254   \n",
      "EPOCH 17 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 8.571%\n",
      "[2]:  0.0%\n",
      "[3]: 25.71%\n",
      "[4]: 45.71%\n",
      "[5]: 34.29%\n",
      "    17     1.19739    4.091606   0.346032  \n",
      "EPOCH 18 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 20.0%\n",
      "[2]:  0.0%\n",
      "[3]: 60.0%\n",
      "[4]: 37.14%\n",
      "[5]: 2.857%\n",
      "    18     1.142277   4.424249   0.304762  \n",
      "EPOCH 26 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 47.14%\n",
      "[1]: 40.0%\n",
      "[2]:  0.0%\n",
      "[3]: 54.29%\n",
      "[4]: 40.0%\n",
      "[5]: 31.43%\n",
      "    26     0.89211    3.297466   0.396825  \n",
      "EPOCH 27 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 41.43%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 68.57%\n",
      "[4]: 40.0%\n",
      "[5]: 28.57%\n",
      "    27     0.84702    3.32718    0.463492  \n",
      "EPOCH 28 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 52.86%\n",
      "[1]: 8.571%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 28.57%\n",
      "[5]: 2.857%\n",
      "    28     0.84495    3.350056   0.428571  \n",
      "EPOCH 29 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 67.14%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 25.71%\n",
      "[5]: 2.857%\n",
      "    29     0.861717   4.074118   0.380952  \n",
      "EPOCH 30 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 42.86%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 30.0%\n",
      "[5]: 14.29%\n",
      "    30     0.836801   3.456692   0.44127   \n",
      "EPOCH 31 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 42.86%\n",
      "[1]: 48.57%\n",
      "[2]:  0.0%\n",
      "[3]: 62.86%\n",
      "[4]: 41.43%\n",
      "[5]: 14.29%\n",
      "    31     0.789244   3.577213   0.466667  \n",
      "\n",
      "CPU times: user 7min 37s, sys: 2min 53s, total: 10min 31s\n",
      "Wall time: 7min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.57721]), 0.46666666742355106]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn_hc.fit(1e-2, 8, cycle_len=4, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ebd273081d04f0c85fa3359fc64f21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 21.43%\n",
      "[2]:  0.0%\n",
      "[3]: 100.0%\n",
      "[4]: 27.14%\n",
      "[5]:  0.0%\n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      19.546573  27.691325  0.333333  \n",
      "EPOCH 1 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 60.0%\n",
      "[5]:  0.0%\n",
      "    1      11.318616  16.038361  0.285714  \n",
      "EPOCH 2 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 77.14%\n",
      "[2]:  0.0%\n",
      "[3]: 17.14%\n",
      "[4]: 55.71%\n",
      "[5]:  0.0%\n",
      "    2      6.811897   12.35904   0.288889  \n",
      "EPOCH 3 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 72.86%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 54.29%\n",
      "[5]:  0.0%\n",
      "    3      4.661259   12.267664  0.295238  \n",
      "EPOCH 4 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 41.43%\n",
      "[1]: 32.86%\n",
      "[2]:  0.0%\n",
      "[3]: 20.0%\n",
      "[4]: 35.71%\n",
      "[5]:  0.0%\n",
      "    4      3.729897   10.973367  0.330159  \n",
      "EPOCH 5 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 32.86%\n",
      "[2]:  0.0%\n",
      "[3]: 88.57%\n",
      "[4]: 45.71%\n",
      "[5]:  0.0%\n",
      "    5      3.103569   11.596262  0.330159  \n",
      "EPOCH 6 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 24.29%\n",
      "[1]: 31.43%\n",
      "[2]:  0.0%\n",
      "[3]: 62.86%\n",
      "[4]: 37.14%\n",
      "[5]:  0.0%\n",
      "    6      2.571463   9.836786   0.330159  \n",
      "EPOCH 7 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 58.57%\n",
      "[2]:  0.0%\n",
      "[3]: 74.29%\n",
      "[4]: 37.14%\n",
      "[5]:  0.0%\n",
      "    7      2.13735    9.986167   0.330159  \n",
      "EPOCH 8 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 77.14%\n",
      "[4]: 32.86%\n",
      "[5]:  0.0%\n",
      "    8      2.115642   9.373093   0.333333  \n",
      "EPOCH 9 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 5.714%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 74.29%\n",
      "[4]: 2.857%\n",
      "[5]:  0.0%\n",
      "    9      1.998348   7.816414   0.330159  \n",
      "EPOCH 10 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 8.571%\n",
      "[2]:  0.0%\n",
      "[3]: 82.86%\n",
      "[4]: 15.71%\n",
      "[5]:  0.0%\n",
      "    10     1.844165   8.589991   0.371429  \n",
      "EPOCH 11 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 37.14%\n",
      "[1]: 8.571%\n",
      "[2]:  0.0%\n",
      "[3]: 62.86%\n",
      "[4]: 37.14%\n",
      "[5]:  0.0%\n",
      "    11     1.607148   7.334993   0.371429  \n",
      "EPOCH 12 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 44.29%\n",
      "[1]:  0.0%\n",
      "[2]:  0.0%\n",
      "[3]: 94.29%\n",
      "[4]: 30.0%\n",
      "[5]:  0.0%\n",
      "    12     1.682802   8.101856   0.336508  \n",
      "EPOCH 13 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 42.86%\n",
      "[1]:  0.0%\n",
      "[2]:  0.0%\n",
      "[3]: 57.14%\n",
      "[4]: 24.29%\n",
      "[5]:  0.0%\n",
      "    13     1.684568   8.291547   0.333333  \n",
      "EPOCH 14 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 58.57%\n",
      "[1]:  0.0%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 48.57%\n",
      "[5]: 11.43%\n",
      "    14     1.673467   7.068686   0.346032  \n",
      "EPOCH 15 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 54.29%\n",
      "[1]: 5.714%\n",
      "[2]:  0.0%\n",
      "[3]: 74.29%\n",
      "[4]: 30.0%\n",
      "[5]: 2.857%\n",
      "    15     1.471853   7.917884   0.336508  \n",
      "EPOCH 16 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 55.71%\n",
      "[1]:  0.0%\n",
      "[2]:  0.0%\n",
      "[3]: 60.0%\n",
      "[4]: 34.29%\n",
      "[5]: 2.857%\n",
      "    16     1.603034   7.552263   0.336508  \n",
      "EPOCH 17 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 52.86%\n",
      "[1]:  0.0%\n",
      "[2]:  0.0%\n",
      "[3]: 31.43%\n",
      "[4]: 31.43%\n",
      "[5]: 57.14%\n",
      "    17     1.487995   5.611178   0.393651  \n",
      "EPOCH 18 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 41.43%\n",
      "[1]: 2.857%\n",
      "[2]:  0.0%\n",
      "[3]: 57.14%\n",
      "[4]: 32.86%\n",
      "[5]: 28.57%\n",
      "    18     1.404314   5.87525    0.361905  \n",
      "EPOCH 19 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 40.0%\n",
      "[1]: 4.286%\n",
      "[2]:  0.0%\n",
      "[3]: 80.0%\n",
      "[4]: 42.86%\n",
      "[5]: 11.43%\n",
      "    19     1.294108   6.163056   0.342857  \n",
      "EPOCH 20 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 51.43%\n",
      "[1]: 5.714%\n",
      "[2]:  0.0%\n",
      "[3]: 94.29%\n",
      "[4]: 40.0%\n",
      "[5]:  0.0%\n",
      "    20     1.349914   6.75491    0.333333  \n",
      "EPOCH 21 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 55.71%\n",
      "[1]:  0.0%\n",
      "[2]:  0.0%\n",
      "[3]: 71.43%\n",
      "[4]: 22.86%\n",
      "[5]: 25.71%\n",
      "    21     1.237111   6.370494   0.361905  \n",
      "EPOCH 22 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 61.43%\n",
      "[1]:  0.0%\n",
      "[2]:  0.0%\n",
      "[3]: 80.0%\n",
      "[4]: 24.29%\n",
      "[5]: 14.29%\n",
      "    22     1.131749   6.309366   0.346032  \n",
      "EPOCH 23 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 60.0%\n",
      "[1]: 1.429%\n",
      "[2]:  0.0%\n",
      "[3]: 71.43%\n",
      "[4]: 31.43%\n",
      "[5]: 22.86%\n",
      "    23     1.05871    5.849553   0.355556  \n",
      "EPOCH 24 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 62.86%\n",
      "[1]:  0.0%\n",
      "[2]:  0.0%\n",
      "[3]: 91.43%\n",
      "[4]: 17.14%\n",
      "[5]:  0.0%\n",
      "    24     1.144225   6.466179   0.333333  \n",
      "EPOCH 25 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 45.71%\n",
      "[1]: 11.43%\n",
      "[2]:  0.0%\n",
      "[3]: 65.71%\n",
      "[4]: 44.29%\n",
      "[5]: 34.29%\n",
      "    25     1.201106   5.946113   0.374603  \n",
      "EPOCH 26 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 50.0%\n",
      "[1]: 4.286%\n",
      "[2]:  0.0%\n",
      "[3]: 77.14%\n",
      "[4]: 38.57%\n",
      "[5]: 22.86%\n",
      "    26     1.114693   5.896331   0.35873   \n",
      "EPOCH 27 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 51.43%\n",
      "[1]: 4.286%\n",
      "[2]:  0.0%\n",
      "[3]: 74.29%\n",
      "[4]: 27.14%\n",
      "[5]: 22.86%\n",
      "    27     1.02313    5.925196   0.355556  \n",
      "EPOCH 28 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 47.14%\n",
      "[1]: 8.571%\n",
      "[2]:  0.0%\n",
      "[3]: 80.0%\n",
      "[4]: 55.71%\n",
      "[5]: 2.857%\n",
      "    28     0.982449   4.559798   0.361905  \n",
      "EPOCH 29 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 55.71%\n",
      "[1]:  0.0%\n",
      "[2]:  0.0%\n",
      "[3]: 85.71%\n",
      "[4]: 22.86%\n",
      "[5]: 11.43%\n",
      "    29     0.987851   5.614793   0.346032  \n",
      "EPOCH 30 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 50.0%\n",
      "[1]: 5.714%\n",
      "[2]:  0.0%\n",
      "[3]: 82.86%\n",
      "[4]: 31.43%\n",
      "[5]: 14.29%\n",
      "    30     0.924971   5.028294   0.349206  \n",
      "EPOCH 31 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 57.14%\n",
      "[1]: 1.429%\n",
      "[2]:  0.0%\n",
      "[3]: 65.71%\n",
      "[4]: 30.0%\n",
      "[5]: 31.43%\n",
      "    31     0.883551   4.931801   0.365079  \n",
      "\n",
      "CPU times: user 7min 34s, sys: 2min 52s, total: 10min 26s\n",
      "Wall time: 6min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([4.9318]), 0.36507936479553343]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = ResNet([10, 20, 40, 80, 160], 6, obj_name=\"EXP\",tb_log=False)\n",
    "learn_exp1 = ConvLearner.from_model_data(model1, data)\n",
    "%time learn_exp1.fit(1e-2, 8, cycle_len=4, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76697851d77411197eb395d95466263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 48.57%\n",
      "[2]:  0.0%\n",
      "[3]: 22.86%\n",
      "[4]: 50.0%\n",
      "[5]: 2.857%\n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      15.712452  11.548308  0.228571  \n",
      "f1 weighted average score: [0.1569]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 80.0%\n",
      "[1]:  0.0%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 50.0%\n",
      "[5]:  0.0%\n",
      "    1      8.42825    6.840355   0.231746  \n",
      "f1 weighted average score: [0.1689]\n",
      "EPOCH 2 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 14.29%\n",
      "[1]: 32.86%\n",
      "[2]:  0.0%\n",
      "[3]: 40.0%\n",
      "[4]: 65.71%\n",
      "[5]:  0.0%\n",
      "    2      5.07913    7.207547   0.247619  \n",
      "f1 weighted average score: [0.1868]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 41.43%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 51.43%\n",
      "[5]:  0.0%\n",
      "    3      3.388255   6.681377   0.244444  \n",
      "f1 weighted average score: [0.1889]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 51.43%\n",
      "[1]: 5.714%\n",
      "[2]:  0.0%\n",
      "[3]: 40.0%\n",
      "[4]: 50.0%\n",
      "[5]:  0.0%\n",
      "    4      2.740393   6.048422   0.257143  \n",
      "f1 weighted average score: [0.2043]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 12.86%\n",
      "[1]: 8.571%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 37.14%\n",
      "[5]: 2.857%\n",
      "    5      2.205514   4.863347   0.346032  \n",
      "f1 weighted average score: [0.325]\n",
      "EPOCH 6 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 15.71%\n",
      "[2]:  0.0%\n",
      "[3]: 40.0%\n",
      "[4]: 41.43%\n",
      "[5]:  0.0%\n",
      "    6      1.793773   4.397145   0.250794  \n",
      "f1 weighted average score: [0.1909]\n",
      "EPOCH 7 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 14.29%\n",
      "[1]: 38.57%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 55.71%\n",
      "[5]:  0.0%\n",
      "    7      1.505336   4.351654   0.247619  \n",
      "f1 weighted average score: [0.1928]\n",
      "EPOCH 8 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 7.143%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 34.29%\n",
      "[4]: 24.29%\n",
      "[5]: 22.86%\n",
      "    8      1.637196   4.850899   0.266667  \n",
      "f1 weighted average score: [0.1735]\n",
      "EPOCH 9 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 21.43%\n",
      "[1]: 7.143%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 58.57%\n",
      "[5]: 20.0%\n",
      "    9      1.609998   4.725433   0.266667  \n",
      "f1 weighted average score: [0.218]\n",
      "EPOCH 10 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 11.43%\n",
      "[1]: 32.86%\n",
      "[2]:  0.0%\n",
      "[3]: 25.71%\n",
      "[4]: 55.71%\n",
      "[5]: 17.14%\n",
      "    10     1.418963   4.77206    0.260317  \n",
      "f1 weighted average score: [0.2074]\n",
      "EPOCH 11 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 10.0%\n",
      "[1]: 14.29%\n",
      "[2]:  0.0%\n",
      "[3]: 25.71%\n",
      "[4]: 58.57%\n",
      "[5]: 17.14%\n",
      "    11     1.225049   4.647921   0.260317  \n",
      "f1 weighted average score: [0.2077]\n",
      "EPOCH 12 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 14.29%\n",
      "[2]:  0.0%\n",
      "[3]: 31.43%\n",
      "[4]: 91.43%\n",
      "[5]: 11.43%\n",
      "    12     1.127978   3.780862   0.311111  \n",
      "f1 weighted average score: [0.2364]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 13 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 1.429%\n",
      "[1]: 58.57%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 48.57%\n",
      "[5]: 20.0%\n",
      "    13     1.098733   3.349653   0.35873   \n",
      "f1 weighted average score: [0.3556]\n",
      "EPOCH 14 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 8.571%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 31.43%\n",
      "[4]: 18.57%\n",
      "[5]: 14.29%\n",
      "    14     0.99091    3.636735   0.273016  \n",
      "f1 weighted average score: [0.182]\n",
      "EPOCH 15 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]:  0.0%\n",
      "[1]: 45.71%\n",
      "[2]:  0.0%\n",
      "[3]: 31.43%\n",
      "[4]: 47.14%\n",
      "[5]: 14.29%\n",
      "    15     0.905331   3.823841   0.295238  \n",
      "f1 weighted average score: [0.2565]\n",
      "EPOCH 16 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 7.143%\n",
      "[1]: 11.43%\n",
      "[2]:  0.0%\n",
      "[3]: 31.43%\n",
      "[4]: 71.43%\n",
      "[5]: 42.86%\n",
      "    16     1.153238   2.344879   0.434921  \n",
      "f1 weighted average score: [0.4032]\n",
      "EPOCH 17 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 2.857%\n",
      "[1]: 27.14%\n",
      "[2]:  0.0%\n",
      "[3]: 25.71%\n",
      "[4]: 38.57%\n",
      "[5]: 85.71%\n",
      "    17     1.252103   2.10379    0.438095  \n",
      "f1 weighted average score: [0.3879]\n",
      "EPOCH 18 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 2.857%\n",
      "[1]: 25.71%\n",
      "[2]:  0.0%\n",
      "[3]: 34.29%\n",
      "[4]: 40.0%\n",
      "[5]: 62.86%\n",
      "    18     1.120783   1.327315   0.526984  \n",
      "f1 weighted average score: [0.5101]\n",
      "EPOCH 19 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 4.286%\n",
      "[1]: 30.0%\n",
      "[2]:  0.0%\n",
      "[3]: 31.43%\n",
      "[4]: 44.29%\n",
      "[5]: 74.29%\n",
      "    19     0.968927   1.420835   0.466667  \n",
      "f1 weighted average score: [0.4432]\n",
      "EPOCH 20 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 15.71%\n",
      "[1]: 41.43%\n",
      "[2]:  0.0%\n",
      "[3]: 25.71%\n",
      "[4]: 38.57%\n",
      "[5]: 42.86%\n",
      "    20     0.922601   2.411753   0.479365  \n",
      "f1 weighted average score: [0.4928]\n",
      "EPOCH 21 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 1.429%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 31.43%\n",
      "[4]: 24.29%\n",
      "[5]: 65.71%\n",
      "    21     0.936976   1.908937   0.374603  \n",
      "f1 weighted average score: [0.2633]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 22 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 1.429%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 34.29%\n",
      "[4]: 21.43%\n",
      "[5]: 68.57%\n",
      "    22     0.85826    2.02734    0.374603  \n",
      "f1 weighted average score: [0.2741]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 23 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 1.429%\n",
      "[1]: 38.57%\n",
      "[2]:  0.0%\n",
      "[3]: 31.43%\n",
      "[4]: 47.14%\n",
      "[5]: 68.57%\n",
      "    23     0.764573   1.783445   0.473016  \n",
      "f1 weighted average score: [0.4327]\n",
      "EPOCH 24 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 8.571%\n",
      "[1]: 22.86%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 60.0%\n",
      "[5]: 62.86%\n",
      "    24     0.92814    4.071473   0.47619   \n",
      "f1 weighted average score: [0.485]\n",
      "EPOCH 25 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 2.857%\n",
      "[1]: 15.71%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 50.0%\n",
      "[5]: 51.43%\n",
      "    25     0.996341   2.031806   0.479365  \n",
      "f1 weighted average score: [0.463]\n",
      "EPOCH 26 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 4.286%\n",
      "[1]: 17.14%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 48.57%\n",
      "[5]: 60.0%\n",
      "    26     0.887166   2.160646   0.415873  \n",
      "f1 weighted average score: [0.3824]\n",
      "EPOCH 27 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 2.857%\n",
      "[1]: 31.43%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 34.29%\n",
      "[5]: 57.14%\n",
      "    27     0.775214   2.269123   0.406349  \n",
      "f1 weighted average score: [0.3436]\n",
      "EPOCH 28 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 15.71%\n",
      "[1]: 28.57%\n",
      "[2]:  0.0%\n",
      "[3]: 40.0%\n",
      "[4]: 40.0%\n",
      "[5]: 77.14%\n",
      "    28     0.794902   1.484913   0.511111  \n",
      "f1 weighted average score: [0.5033]\n",
      "EPOCH 29 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 4.286%\n",
      "[1]: 45.71%\n",
      "[2]:  0.0%\n",
      "[3]: 40.0%\n",
      "[4]: 27.14%\n",
      "[5]: 71.43%\n",
      "    29     0.777817   2.230797   0.403175  \n",
      "f1 weighted average score: [0.3179]\n",
      "EPOCH 30 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 7.143%\n",
      "[1]: 48.57%\n",
      "[2]:  0.0%\n",
      "[3]: 40.0%\n",
      "[4]: 30.0%\n",
      "[5]: 77.14%\n",
      "    30     0.716561   1.732278   0.412698  \n",
      "f1 weighted average score: [0.3185]\n",
      "EPOCH 31 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 10.0%\n",
      "[1]: 38.57%\n",
      "[2]:  0.0%\n",
      "[3]: 40.0%\n",
      "[4]: 34.29%\n",
      "[5]: 77.14%\n",
      "    31     0.648006   1.520685   0.485714  \n",
      "f1 weighted average score: [0.4386]\n",
      "\n",
      "CPU times: user 8min 19s, sys: 3min 18s, total: 11min 37s\n",
      "Wall time: 7min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.52068]), 0.4857142879849389]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet([10, 20, 40, 80, 160], 6, obj_name=\"EXP\", tb_log=True)\n",
    "learn_exp2 = ConvLearner.from_model_data(model, data)\n",
    "%time learn_exp2.fit(1e-2, 8, cycle_len=4, wds=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn_exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Objective_A_Resnet_per_class_1.h5',\n",
       " 'Objective_A_Resnet_per_class_balanced_fromstart_1.h5',\n",
       " 'Objective_A_Resnet_per_class_balanced_fromstart_2.h5',\n",
       " 'Objective_C_Resnet_per_class_3.h5',\n",
       " 'Objective_C_Resnet_per_class_balanced_1.h5',\n",
       " 'Objective_C_Resnet_per_dataset_2.h5',\n",
       " 'Objective_C_Resnet_per_dataset_3.h5',\n",
       " 'ResNet5_default_07-24_23-18.h5',\n",
       " 'ResNet5_v5_batch_adj_07-24_16-46.h5',\n",
       " 'ResNet5_v5_batch_adj_07-24_18-32.h5',\n",
       " 'ResNet5_v5_batch_adj_07-24_18-55.h5',\n",
       " 'ResNet5_v5_batch_adj_07-24_19-11.h5',\n",
       " 'ResNet5_v5_batch_adj_07-24_19-32.h5',\n",
       " 'ResNet5_v5_batch_adj_07-24_19-55.h5',\n",
       " 'ResNet5_v5_batch_adj_07-24_19-59.h5',\n",
       " 'ResNet5_v5_batch_adj_07-24_20-27.h5']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir('../datasets/yeast_v5/models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d373f90bfcc438fbe851ea12bc7c688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=80), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 8.571%\n",
      "[1]: 70.0%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 2.857%\n",
      "[5]: 68.57%\n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.638168   2.327813   0.473016  \n",
      "f1 weighted average score: [0.397]\n",
      "EPOCH 1 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 1.429%\n",
      "[1]: 34.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 54.29%\n",
      "[5]: 60.0%\n",
      "    1      0.707171   2.138245   0.492063  \n",
      "f1 weighted average score: [0.4817]\n",
      "EPOCH 2 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 37.14%\n",
      "[1]: 8.571%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 25.71%\n",
      "[5]: 51.43%\n",
      "    2      0.715854   1.715517   0.479365  \n",
      "f1 weighted average score: [0.4443]\n",
      "EPOCH 3 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 40.0%\n",
      "[1]: 37.14%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 31.43%\n",
      "[5]: 71.43%\n",
      "    3      0.722359   1.7311     0.511111  \n",
      "f1 weighted average score: [0.4553]\n",
      "EPOCH 4 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 8.571%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 40.0%\n",
      "[5]: 62.86%\n",
      "    4      0.681785   1.595537   0.552381  \n",
      "f1 weighted average score: [0.5398]\n",
      "EPOCH 5 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 25.71%\n",
      "[1]: 21.43%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 54.29%\n",
      "[5]: 60.0%\n",
      "    5      0.656132   1.211531   0.657143  \n",
      "f1 weighted average score: [0.6622]\n",
      "EPOCH 6 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 44.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 47.14%\n",
      "[5]: 77.14%\n",
      "    6      0.631966   1.568718   0.612698  \n",
      "f1 weighted average score: [0.5934]\n",
      "EPOCH 7 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 14.29%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 20.0%\n",
      "[5]: 57.14%\n",
      "    7      0.609698   2.448703   0.479365  \n",
      "f1 weighted average score: [0.4325]\n",
      "EPOCH 8 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 15.71%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 34.29%\n",
      "[5]: 77.14%\n",
      "    8      0.576347   1.857375   0.415873  \n",
      "f1 weighted average score: [0.3424]\n",
      "EPOCH 9 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 15.71%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 34.29%\n",
      "[5]: 74.29%\n",
      "    9      0.551659   1.881654   0.48254   \n",
      "f1 weighted average score: [0.4423]\n",
      "EPOCH 10 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 5.714%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 32.86%\n",
      "[5]: 68.57%\n",
      "    10     0.531339   2.173362   0.463492  \n",
      "f1 weighted average score: [0.4214]\n",
      "EPOCH 11 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 14.29%\n",
      "[1]: 28.57%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 58.57%\n",
      "[5]: 82.86%\n",
      "    11     0.524098   1.304149   0.644444  \n",
      "f1 weighted average score: [0.6298]\n",
      "EPOCH 12 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 8.571%\n",
      "[1]: 67.14%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 47.14%\n",
      "[5]: 80.0%\n",
      "    12     0.550707   1.612509   0.495238  \n",
      "f1 weighted average score: [0.4325]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 13 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 15.71%\n",
      "[5]: 71.43%\n",
      "    13     0.570694   1.817978   0.549206  \n",
      "f1 weighted average score: [0.497]\n",
      "EPOCH 14 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 20.0%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 41.43%\n",
      "[5]: 85.71%\n",
      "    14     0.5915     1.411549   0.501587  \n",
      "f1 weighted average score: [0.4449]\n",
      "EPOCH 15 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 10.0%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 37.14%\n",
      "[5]: 82.86%\n",
      "    15     0.582649   1.576363   0.552381  \n",
      "f1 weighted average score: [0.533]\n",
      "EPOCH 16 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 7.143%\n",
      "[1]: 64.29%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 38.57%\n",
      "[5]: 77.14%\n",
      "    16     0.555907   1.354455   0.546032  \n",
      "f1 weighted average score: [0.5221]\n",
      "EPOCH 17 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 4.286%\n",
      "[1]: 48.57%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 71.43%\n",
      "[5]: 77.14%\n",
      "    17     0.531549   1.459399   0.580952  \n",
      "f1 weighted average score: [0.568]\n",
      "EPOCH 18 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 8.571%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 21.43%\n",
      "[5]: 77.14%\n",
      "    18     0.507196   1.657138   0.520635  \n",
      "f1 weighted average score: [0.4815]\n",
      "EPOCH 19 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 10.0%\n",
      "[1]: 68.57%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 21.43%\n",
      "[5]: 74.29%\n",
      "    19     0.494475   1.629231   0.498413  \n",
      "f1 weighted average score: [0.4528]\n",
      "EPOCH 20 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 14.29%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 40.0%\n",
      "[4]: 24.29%\n",
      "[5]: 68.57%\n",
      "    20     0.512745   1.941393   0.539683  \n",
      "f1 weighted average score: [0.4997]\n",
      "EPOCH 21 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 8.571%\n",
      "[1]: 45.71%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 51.43%\n",
      "[5]: 80.0%\n",
      "    21     0.528204   1.049844   0.647619  \n",
      "f1 weighted average score: [0.6498]\n",
      "EPOCH 22 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 37.14%\n",
      "[1]: 30.0%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 44.29%\n",
      "[5]: 77.14%\n",
      "    22     0.5489     1.512096   0.612698  \n",
      "f1 weighted average score: [0.5926]\n",
      "EPOCH 23 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 11.43%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 47.14%\n",
      "[5]: 71.43%\n",
      "    23     0.569548   1.658302   0.653968  \n",
      "f1 weighted average score: [0.647]\n",
      "EPOCH 24 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 11.43%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 51.43%\n",
      "[5]: 65.71%\n",
      "    24     0.529839   1.631098   0.612698  \n",
      "f1 weighted average score: [0.6098]\n",
      "EPOCH 25 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 12.86%\n",
      "[1]: 60.0%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 38.57%\n",
      "[5]: 80.0%\n",
      "    25     0.496985   1.510578   0.565079  \n",
      "f1 weighted average score: [0.5434]\n",
      "EPOCH 26 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 24.29%\n",
      "[1]: 48.57%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 45.71%\n",
      "[5]: 77.14%\n",
      "    26     0.484029   1.185201   0.647619  \n",
      "f1 weighted average score: [0.6481]\n",
      "EPOCH 27 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 21.43%\n",
      "[1]: 60.0%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 37.14%\n",
      "[5]: 74.29%\n",
      "    27     0.451963   1.381535   0.590476  \n",
      "f1 weighted average score: [0.573]\n",
      "EPOCH 28 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 18.57%\n",
      "[1]: 60.0%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 40.0%\n",
      "[5]: 74.29%\n",
      "    28     0.450584   1.499816   0.546032  \n",
      "f1 weighted average score: [0.5074]\n",
      "EPOCH 29 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 17.14%\n",
      "[1]: 60.0%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 40.0%\n",
      "[5]: 77.14%\n",
      "    29     0.43708    1.510724   0.526984  \n",
      "f1 weighted average score: [0.485]\n",
      "EPOCH 30 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 20.0%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 41.43%\n",
      "[5]: 74.29%\n",
      "    30     0.429024   1.430108   0.549206  \n",
      "f1 weighted average score: [0.5302]\n",
      "EPOCH 31 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 14.29%\n",
      "[1]: 65.71%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 38.57%\n",
      "[5]: 80.0%\n",
      "    31     0.438962   1.816236   0.438095  \n",
      "f1 weighted average score: [0.3621]\n",
      "EPOCH 32 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 18.57%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 45.71%\n",
      "[5]: 71.43%\n",
      "    32     0.467935   1.614553   0.593651  \n",
      "f1 weighted average score: [0.5818]\n",
      "EPOCH 33 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 17.14%\n",
      "[1]: 65.71%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 35.71%\n",
      "[5]: 77.14%\n",
      "    33     0.472385   1.448765   0.561905  \n",
      "f1 weighted average score: [0.5343]\n",
      "EPOCH 34 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 44.29%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 25.71%\n",
      "[5]: 82.86%\n",
      "    34     0.49387    1.038769   0.647619  \n",
      "f1 weighted average score: [0.6219]\n",
      "EPOCH 35 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 12.86%\n",
      "[1]: 47.14%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 44.29%\n",
      "[5]: 80.0%\n",
      "    35     0.480999   1.406956   0.612698  \n",
      "f1 weighted average score: [0.6009]\n",
      "EPOCH 36 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 22.86%\n",
      "[1]: 67.14%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 35.71%\n",
      "[5]: 85.71%\n",
      "    36     0.476219   1.173586   0.657143  \n",
      "f1 weighted average score: [0.6352]\n",
      "EPOCH 37 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 20.0%\n",
      "[1]: 71.43%\n",
      "[2]:  0.0%\n",
      "[3]: 40.0%\n",
      "[4]: 22.86%\n",
      "[5]: 82.86%\n",
      "    37     0.451452   1.684085   0.526984  \n",
      "f1 weighted average score: [0.4768]\n",
      "EPOCH 38 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 18.57%\n",
      "[1]: 64.29%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 42.86%\n",
      "[5]: 80.0%\n",
      "    38     0.448731   1.169484   0.622222  \n",
      "f1 weighted average score: [0.6105]\n",
      "EPOCH 39 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 12.86%\n",
      "[1]: 48.57%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 55.71%\n",
      "[5]: 82.86%\n",
      "    39     0.418331   1.028801   0.638095  \n",
      "f1 weighted average score: [0.6282]\n",
      "EPOCH 40 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 12.86%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 48.57%\n",
      "[5]: 80.0%\n",
      "    40     0.399697   1.173297   0.644444  \n",
      "f1 weighted average score: [0.638]\n",
      "EPOCH 41 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 5.714%\n",
      "[1]: 62.86%\n",
      "[2]:  0.0%\n",
      "[3]: 40.0%\n",
      "[4]: 34.29%\n",
      "[5]: 82.86%\n",
      "    41     0.39429    1.74738    0.565079  \n",
      "f1 weighted average score: [0.531]\n",
      "EPOCH 42 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 61.43%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 32.86%\n",
      "[5]: 82.86%\n",
      "    42     0.3992     1.130071   0.653968  \n",
      "f1 weighted average score: [0.6378]\n",
      "EPOCH 43 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 14.29%\n",
      "[1]: 31.43%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 64.29%\n",
      "[5]: 74.29%\n",
      "    43     0.422269   0.879711   0.768254  \n",
      "f1 weighted average score: [0.7734]\n",
      "EPOCH 44 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 10.0%\n",
      "[1]: 60.0%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 40.0%\n",
      "[5]: 82.86%\n",
      "    44     0.407796   1.364271   0.501587  \n",
      "f1 weighted average score: [0.437]\n",
      "EPOCH 45 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: 17.14%\n",
      "[1]: 32.86%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 61.43%\n",
      "[5]: 74.29%\n",
      "    45     0.409378   1.160529   0.638095  \n",
      "f1 weighted average score: [0.6496]\n",
      "EPOCH 46 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 17.14%\n",
      "[1]: 38.57%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 57.14%\n",
      "[5]: 77.14%\n",
      "    46     0.413742   0.867401   0.752381  \n",
      "f1 weighted average score: [0.753]\n",
      "EPOCH 47 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 18.57%\n",
      "[1]: 64.29%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 35.71%\n",
      "[5]: 74.29%\n",
      "    47     0.415166   1.505638   0.590476  \n",
      "f1 weighted average score: [0.5566]\n",
      "EPOCH 48 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 38.57%\n",
      "[5]: 85.71%\n",
      "    48     0.388437   1.017486   0.657143  \n",
      "f1 weighted average score: [0.6492]\n",
      "EPOCH 49 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 14.29%\n",
      "[1]: 58.57%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 44.29%\n",
      "[5]: 85.71%\n",
      "    49     0.375864   1.235464   0.622222  \n",
      "f1 weighted average score: [0.6028]\n",
      "EPOCH 50 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 5.714%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 60.0%\n",
      "[5]: 74.29%\n",
      "    50     0.379142   1.328333   0.619048  \n",
      "f1 weighted average score: [0.6004]\n",
      "EPOCH 51 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 12.86%\n",
      "[1]: 32.86%\n",
      "[2]:  0.0%\n",
      "[3]: 37.14%\n",
      "[4]: 60.0%\n",
      "[5]: 74.29%\n",
      "    51     0.391181   0.965309   0.698413  \n",
      "f1 weighted average score: [0.699]\n",
      "EPOCH 52 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 17.14%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 44.29%\n",
      "[5]: 68.57%\n",
      "    52     0.403469   1.291112   0.549206  \n",
      "f1 weighted average score: [0.5021]\n",
      "EPOCH 53 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 37.14%\n",
      "[5]: 80.0%\n",
      "    53     0.474945   1.361333   0.650794  \n",
      "f1 weighted average score: [0.6334]\n",
      "EPOCH 54 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 2.857%\n",
      "[1]: 38.57%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 64.29%\n",
      "[5]: 80.0%\n",
      "    54     0.51154    1.085067   0.603175  \n",
      "f1 weighted average score: [0.5784]\n",
      "EPOCH 55 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 24.29%\n",
      "[1]: 40.0%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 38.57%\n",
      "[5]: 65.71%\n",
      "    55     0.468434   1.415937   0.549206  \n",
      "f1 weighted average score: [0.5058]\n",
      "EPOCH 56 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 44.29%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 50.0%\n",
      "[5]: 85.71%\n",
      "    56     0.425784   0.89732    0.673016  \n",
      "f1 weighted average score: [0.6599]\n",
      "EPOCH 57 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 20.0%\n",
      "[1]: 40.0%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 51.43%\n",
      "[5]: 77.14%\n",
      "    57     0.406109   1.005146   0.666667  \n",
      "f1 weighted average score: [0.6534]\n",
      "EPOCH 58 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 11.43%\n",
      "[1]: 44.29%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 51.43%\n",
      "[5]: 74.29%\n",
      "    58     0.381009   0.885781   0.755556  \n",
      "f1 weighted average score: [0.7553]\n",
      "EPOCH 59 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 17.14%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 51.43%\n",
      "[5]: 80.0%\n",
      "    59     0.371878   1.154049   0.606349  \n",
      "f1 weighted average score: [0.5908]\n",
      "EPOCH 60 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 25.71%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 47.14%\n",
      "[5]: 71.43%\n",
      "    60     0.38777    1.396094   0.526984  \n",
      "f1 weighted average score: [0.5055]\n",
      "EPOCH 61 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 27.14%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 60.0%\n",
      "[5]: 74.29%\n",
      "    61     0.446498   0.848086   0.660317  \n",
      "f1 weighted average score: [0.6641]\n",
      "EPOCH 62 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 22.86%\n",
      "[1]: 34.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 60.0%\n",
      "[5]: 74.29%\n",
      "    62     0.458121   0.973696   0.711111  \n",
      "f1 weighted average score: [0.7135]\n",
      "EPOCH 63 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 2.857%\n",
      "[1]: 47.14%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 57.14%\n",
      "[5]: 68.57%\n",
      "    63     0.461107   1.305047   0.67619   \n",
      "f1 weighted average score: [0.6777]\n",
      "EPOCH 64 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 34.29%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 40.0%\n",
      "[5]: 74.29%\n",
      "    64     0.43249    0.923534   0.726984  \n",
      "f1 weighted average score: [0.7062]\n",
      "EPOCH 65 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 20.0%\n",
      "[1]: 38.57%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 54.29%\n",
      "[5]: 74.29%\n",
      "    65     0.423639   1.019762   0.692063  \n",
      "f1 weighted average score: [0.6941]\n",
      "EPOCH 66 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 42.86%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 50.0%\n",
      "[5]: 88.57%\n",
      "    66     0.394034   0.855545   0.752381  \n",
      "f1 weighted average score: [0.7504]\n",
      "EPOCH 67 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 18.57%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 41.43%\n",
      "[5]: 65.71%\n",
      "    67     0.378591   1.044605   0.615873  \n",
      "f1 weighted average score: [0.5966]\n",
      "EPOCH 68 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 45.71%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 51.43%\n",
      "[5]: 77.14%\n",
      "    68     0.351964   0.753358   0.787302  \n",
      "f1 weighted average score: [0.7884]\n",
      "EPOCH 69 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 22.86%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 51.43%\n",
      "[5]: 88.57%\n",
      "    69     0.336476   0.941018   0.701587  \n",
      "f1 weighted average score: [0.7017]\n",
      "EPOCH 70 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 17.14%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 42.86%\n",
      "[5]: 71.43%\n",
      "    70     0.324069   1.272713   0.657143  \n",
      "f1 weighted average score: [0.6507]\n",
      "EPOCH 71 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 12.86%\n",
      "[1]: 31.43%\n",
      "[2]:  0.0%\n",
      "[3]: 40.0%\n",
      "[4]: 61.43%\n",
      "[5]: 80.0%\n",
      "    71     0.348396   1.322846   0.704762  \n",
      "f1 weighted average score: [0.7035]\n",
      "EPOCH 72 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 40.0%\n",
      "[1]: 60.0%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 54.29%\n",
      "[5]: 77.14%\n",
      "    72     0.420162   1.00811    0.695238  \n",
      "f1 weighted average score: [0.6902]\n",
      "EPOCH 73 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 47.14%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 40.0%\n",
      "[5]: 88.57%\n",
      "    73     0.421192   1.10237    0.67619   \n",
      "f1 weighted average score: [0.6677]\n",
      "EPOCH 74 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 21.43%\n",
      "[1]: 45.71%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 54.29%\n",
      "[5]: 88.57%\n",
      "    74     0.410316   0.945266   0.679365  \n",
      "f1 weighted average score: [0.6779]\n",
      "EPOCH 75 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 8.571%\n",
      "[1]: 31.43%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 87.14%\n",
      "[5]: 65.71%\n",
      "    75     0.392176   0.912679   0.695238  \n",
      "f1 weighted average score: [0.6642]\n",
      "EPOCH 76 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 14.29%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 40.0%\n",
      "[4]: 52.86%\n",
      "[5]: 77.14%\n",
      "    76     0.375824   1.101925   0.666667  \n",
      "f1 weighted average score: [0.6646]\n",
      "EPOCH 77 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 60.0%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 37.14%\n",
      "[5]: 82.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    77     0.355387   1.130597   0.619048  \n",
      "f1 weighted average score: [0.6023]\n",
      "EPOCH 78 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 25.71%\n",
      "[1]: 58.57%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 42.86%\n",
      "[5]: 71.43%\n",
      "    78     0.337332   1.154519   0.650794  \n",
      "f1 weighted average score: [0.6436]\n",
      "EPOCH 79 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 22.86%\n",
      "[1]: 44.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 54.29%\n",
      "[5]: 74.29%\n",
      "    79     0.32731    0.933642   0.730159  \n",
      "f1 weighted average score: [0.733]\n",
      "\n",
      "CPU times: user 20min 34s, sys: 8min 20s, total: 28min 55s\n",
      "Wall time: 19min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.93364]), 0.7301587261850871]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# at very little overfitting we have 43% accuracy\n",
    "%time learn.fit(1e-2, 8, wds=wd, cycle_len=10, use_clr=(20,8, 0.95, 0.85), best_save_name=learn.model.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b878b8f06f22449cbdebdfc46cdde941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=160), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 22.86%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 35.71%\n",
      "[5]: 74.29%\n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.29158    1.029396   0.666667  \n",
      "f1 weighted average score: [0.6622]\n",
      "EPOCH 1 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 42.86%\n",
      "[5]: 80.0%\n",
      "    1      0.299866   0.903718   0.746032  \n",
      "f1 weighted average score: [0.7429]\n",
      "EPOCH 2 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 22.86%\n",
      "[1]: 45.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 48.57%\n",
      "[5]: 82.86%\n",
      "    2      0.311934   0.878561   0.746032  \n",
      "f1 weighted average score: [0.7485]\n",
      "EPOCH 3 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 22.86%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 41.43%\n",
      "[5]: 80.0%\n",
      "    3      0.303084   0.976591   0.688889  \n",
      "f1 weighted average score: [0.6873]\n",
      "EPOCH 4 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 34.29%\n",
      "[5]: 80.0%\n",
      "    4      0.305019   1.041197   0.650794  \n",
      "f1 weighted average score: [0.6362]\n",
      "EPOCH 5 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 25.71%\n",
      "[1]: 45.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 51.43%\n",
      "[5]: 82.86%\n",
      "    5      0.302964   0.821151   0.780952  \n",
      "f1 weighted average score: [0.7837]\n",
      "EPOCH 6 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 24.29%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 55.71%\n",
      "[5]: 80.0%\n",
      "    6      0.306143   0.896158   0.730159  \n",
      "f1 weighted average score: [0.7349]\n",
      "EPOCH 7 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 24.29%\n",
      "[1]: 48.57%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 52.86%\n",
      "[5]: 80.0%\n",
      "    7      0.281529   0.854942   0.765079  \n",
      "f1 weighted average score: [0.7672]\n",
      "EPOCH 8 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 48.57%\n",
      "[5]: 82.86%\n",
      "    8      0.278807   0.846338   0.761905  \n",
      "f1 weighted average score: [0.761]\n",
      "EPOCH 9 ---------------                                    \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 25.71%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 41.43%\n",
      "[5]: 80.0%\n",
      "    9      0.270618   0.883912   0.736508  \n",
      "f1 weighted average score: [0.734]\n",
      "EPOCH 10 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 25.71%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 50.0%\n",
      "[5]: 77.14%\n",
      "    10     0.263871   0.858893   0.761905  \n",
      "f1 weighted average score: [0.7608]\n",
      "EPOCH 11 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 25.71%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 57.14%\n",
      "[5]: 80.0%\n",
      "    11     0.257957   0.831039   0.777778  \n",
      "f1 weighted average score: [0.7795]\n",
      "EPOCH 12 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 25.71%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 42.86%\n",
      "[5]: 77.14%\n",
      "    12     0.264448   0.889312   0.739683  \n",
      "f1 weighted average score: [0.7345]\n",
      "EPOCH 13 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 47.14%\n",
      "[5]: 77.14%\n",
      "    13     0.266464   0.850343   0.761905  \n",
      "f1 weighted average score: [0.759]\n",
      "EPOCH 14 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 48.57%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 48.57%\n",
      "[5]: 80.0%\n",
      "    14     0.258157   0.846171   0.768254  \n",
      "f1 weighted average score: [0.7678]\n",
      "EPOCH 15 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 45.71%\n",
      "[5]: 80.0%\n",
      "    15     0.251956   0.875634   0.746032  \n",
      "f1 weighted average score: [0.7433]\n",
      "EPOCH 16 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 25.71%\n",
      "[1]: 48.57%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 50.0%\n",
      "[5]: 80.0%\n",
      "    16     0.257684   0.847694   0.765079  \n",
      "f1 weighted average score: [0.764]\n",
      "EPOCH 17 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 44.29%\n",
      "[5]: 80.0%\n",
      "    17     0.25255    0.881105   0.752381  \n",
      "f1 weighted average score: [0.7491]\n",
      "EPOCH 18 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 47.14%\n",
      "[5]: 80.0%\n",
      "    18     0.247966   0.851588   0.75873   \n",
      "f1 weighted average score: [0.7556]\n",
      "EPOCH 19 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 25.71%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 54.29%\n",
      "[5]: 80.0%\n",
      "    19     0.271987   0.82345    0.771429  \n",
      "f1 weighted average score: [0.7714]\n",
      "EPOCH 20 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 51.43%\n",
      "[5]: 80.0%\n",
      "    20     0.265547   0.824078   0.771429  \n",
      "f1 weighted average score: [0.771]\n",
      "EPOCH 21 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 41.43%\n",
      "[5]: 80.0%\n",
      "    21     0.258868   0.85816    0.749206  \n",
      "f1 weighted average score: [0.7457]\n",
      "EPOCH 22 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 55.71%\n",
      "[5]: 80.0%\n",
      "    22     0.264113   0.787275   0.784127  \n",
      "f1 weighted average score: [0.7848]\n",
      "EPOCH 23 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 48.57%\n",
      "[5]: 80.0%\n",
      "    23     0.260606   0.810174   0.771429  \n",
      "f1 weighted average score: [0.7692]\n",
      "EPOCH 24 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 50.0%\n",
      "[5]: 82.86%\n",
      "    24     0.264312   0.801421   0.771429  \n",
      "f1 weighted average score: [0.7703]\n",
      "EPOCH 25 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 24.29%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 55.71%\n",
      "[5]: 80.0%\n",
      "    25     0.273614   0.804227   0.774603  \n",
      "f1 weighted average score: [0.7718]\n",
      "EPOCH 26 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 47.14%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 61.43%\n",
      "[5]: 80.0%\n",
      "    26     0.284143   0.769831   0.803175  \n",
      "f1 weighted average score: [0.8036]\n",
      "EPOCH 27 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 25.71%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 51.43%\n",
      "[5]: 82.86%\n",
      "    27     0.281406   0.800837   0.774603  \n",
      "f1 weighted average score: [0.7732]\n",
      "EPOCH 28 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 24.29%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 61.43%\n",
      "[5]: 80.0%\n",
      "    28     0.270494   0.789294   0.765079  \n",
      "f1 weighted average score: [0.7632]\n",
      "EPOCH 29 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 25.71%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 44.29%\n",
      "[5]: 80.0%\n",
      "    29     0.273028   0.812088   0.765079  \n",
      "f1 weighted average score: [0.7612]\n",
      "EPOCH 30 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 58.57%\n",
      "[5]: 77.14%\n",
      "    30     0.276602   0.779768   0.790476  \n",
      "f1 weighted average score: [0.7908]\n",
      "EPOCH 31 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 45.71%\n",
      "[5]: 80.0%\n",
      "    31     0.273041   0.800376   0.771429  \n",
      "f1 weighted average score: [0.7682]\n",
      "EPOCH 32 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 54.29%\n",
      "[5]: 80.0%\n",
      "    32     0.273298   0.788554   0.780952  \n",
      "f1 weighted average score: [0.78]\n",
      "EPOCH 33 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 47.14%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 55.71%\n",
      "[5]: 80.0%\n",
      "    33     0.275427   0.757846   0.803175  \n",
      "f1 weighted average score: [0.8031]\n",
      "EPOCH 34 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 55.71%\n",
      "[5]: 82.86%\n",
      "    34     0.265665   0.776908   0.777778  \n",
      "f1 weighted average score: [0.7771]\n",
      "EPOCH 35 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 25.71%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 57.14%\n",
      "[5]: 82.86%\n",
      "    35     0.269755   0.7681     0.784127  \n",
      "f1 weighted average score: [0.784]\n",
      "EPOCH 36 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 61.43%\n",
      "[5]: 82.86%\n",
      "    36     0.296152   0.729987   0.809524  \n",
      "f1 weighted average score: [0.8104]\n",
      "EPOCH 37 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 58.57%\n",
      "[5]: 82.86%\n",
      "    37     0.279147   0.740259   0.790476  \n",
      "f1 weighted average score: [0.7905]\n",
      "EPOCH 38 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 60.0%\n",
      "[5]: 82.86%\n",
      "    38     0.279727   0.739699   0.806349  \n",
      "f1 weighted average score: [0.8067]\n",
      "EPOCH 39 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 54.29%\n",
      "[5]: 82.86%\n",
      "    39     0.271694   0.7588     0.790476  \n",
      "f1 weighted average score: [0.7907]\n",
      "EPOCH 40 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 58.57%\n",
      "[5]: 82.86%\n",
      "    40     0.257327   0.738468   0.803175  \n",
      "f1 weighted average score: [0.8033]\n",
      "EPOCH 41 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 58.57%\n",
      "[5]: 82.86%\n",
      "    41     0.256494   0.748036   0.796825  \n",
      "f1 weighted average score: [0.798]\n",
      "EPOCH 42 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 57.14%\n",
      "[5]: 80.0%\n",
      "    42     0.256467   0.73895    0.793651  \n",
      "f1 weighted average score: [0.7937]\n",
      "EPOCH 43 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 47.14%\n",
      "[5]: 85.71%\n",
      "    43     0.261867   0.76515    0.787302  \n",
      "f1 weighted average score: [0.7842]\n",
      "EPOCH 44 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 57.14%\n",
      "[5]: 85.71%\n",
      "    44     0.260763   0.723416   0.796825  \n",
      "f1 weighted average score: [0.7954]\n",
      "EPOCH 45 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 61.43%\n",
      "[5]: 85.71%\n",
      "    45     0.268117   0.71399    0.806349  \n",
      "f1 weighted average score: [0.8076]\n",
      "EPOCH 46 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 50.0%\n",
      "[5]: 80.0%\n",
      "    46     0.266188   0.726859   0.790476  \n",
      "f1 weighted average score: [0.7875]\n",
      "EPOCH 47 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 64.29%\n",
      "[5]: 85.71%\n",
      "    47     0.265499   0.69983    0.806349  \n",
      "f1 weighted average score: [0.8072]\n",
      "EPOCH 48 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 47.14%\n",
      "[5]: 82.86%\n",
      "    48     0.274505   0.733215   0.777778  \n",
      "f1 weighted average score: [0.7727]\n",
      "EPOCH 49 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 61.43%\n",
      "[5]: 85.71%\n",
      "    49     0.273241   0.707692   0.8       \n",
      "f1 weighted average score: [ 0.8]\n",
      "EPOCH 50 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 52.86%\n",
      "[5]: 85.71%\n",
      "    50     0.275718   0.697412   0.8       \n",
      "f1 weighted average score: [0.7975]\n",
      "EPOCH 51 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 58.57%\n",
      "[5]: 85.71%\n",
      "    51     0.269244   0.69024    0.806349  \n",
      "f1 weighted average score: [0.8059]\n",
      "EPOCH 52 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 60.0%\n",
      "[5]: 85.71%\n",
      "    52     0.265851   0.688954   0.806349  \n",
      "f1 weighted average score: [0.8063]\n",
      "EPOCH 53 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 57.14%\n",
      "[5]: 85.71%\n",
      "    53     0.259181   0.708825   0.796825  \n",
      "f1 weighted average score: [0.7962]\n",
      "EPOCH 54 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 50.0%\n",
      "[5]: 85.71%\n",
      "    54     0.257056   0.713604   0.784127  \n",
      "f1 weighted average score: [0.7808]\n",
      "EPOCH 55 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 54.29%\n",
      "[5]: 85.71%\n",
      "    55     0.256019   0.694252   0.803175  \n",
      "f1 weighted average score: [0.8029]\n",
      "EPOCH 56 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 55.71%\n",
      "[5]: 85.71%\n",
      "    56     0.258316   0.687055   0.806349  \n",
      "f1 weighted average score: [0.8071]\n",
      "EPOCH 57 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 54.29%\n",
      "[5]: 85.71%\n",
      "    57     0.263409   0.709513   0.803175  \n",
      "f1 weighted average score: [0.8033]\n",
      "EPOCH 58 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 58.57%\n",
      "[5]: 82.86%\n",
      "    58     0.276686   0.707266   0.806349  \n",
      "f1 weighted average score: [0.8065]\n",
      "EPOCH 59 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 52.86%\n",
      "[5]: 82.86%\n",
      "    59     0.275215   0.731317   0.784127  \n",
      "f1 weighted average score: [0.7825]\n",
      "EPOCH 60 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 52.86%\n",
      "[5]: 80.0%\n",
      "    60     0.259869   0.743839   0.780952  \n",
      "f1 weighted average score: [0.7784]\n",
      "EPOCH 61 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 27.14%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 57.14%\n",
      "[5]: 82.86%\n",
      "    61     0.256921   0.736325   0.790476  \n",
      "f1 weighted average score: [0.7907]\n",
      "EPOCH 62 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 50.0%\n",
      "[5]: 82.86%\n",
      "    62     0.252599   0.722873   0.790476  \n",
      "f1 weighted average score: [0.788]\n",
      "EPOCH 63 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 48.57%\n",
      "[5]: 82.86%\n",
      "    63     0.250715   0.716143   0.787302  \n",
      "f1 weighted average score: [0.7848]\n",
      "EPOCH 64 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: 30.0%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 55.71%\n",
      "[5]: 85.71%\n",
      "    64     0.25172    0.718689   0.8       \n",
      "f1 weighted average score: [0.7979]\n",
      "EPOCH 65 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 52.86%\n",
      "[5]: 82.86%\n",
      "    65     0.261352   0.727001   0.780952  \n",
      "f1 weighted average score: [0.7776]\n",
      "EPOCH 66 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 52.86%\n",
      "[5]: 85.71%\n",
      "    66     0.258826   0.720258   0.780952  \n",
      "f1 weighted average score: [0.779]\n",
      "EPOCH 67 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 58.57%\n",
      "[5]: 85.71%\n",
      "    67     0.263055   0.682974   0.8       \n",
      "f1 weighted average score: [0.7996]\n",
      "EPOCH 68 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 58.57%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 47.14%\n",
      "[5]: 85.71%\n",
      "    68     0.278159   0.727064   0.787302  \n",
      "f1 weighted average score: [0.7839]\n",
      "EPOCH 69 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 58.57%\n",
      "[5]: 85.71%\n",
      "    69     0.269463   0.667477   0.815873  \n",
      "f1 weighted average score: [0.8157]\n",
      "EPOCH 70 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 58.57%\n",
      "[5]: 85.71%\n",
      "    70     0.277929   0.671832   0.815873  \n",
      "f1 weighted average score: [0.8158]\n",
      "EPOCH 71 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 60.0%\n",
      "[5]: 85.71%\n",
      "    71     0.269179   0.657329   0.812698  \n",
      "f1 weighted average score: [0.8137]\n",
      "EPOCH 72 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 58.57%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 52.86%\n",
      "[5]: 85.71%\n",
      "    72     0.261263   0.713195   0.780952  \n",
      "f1 weighted average score: [0.7788]\n",
      "EPOCH 73 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 62.86%\n",
      "[5]: 80.0%\n",
      "    73     0.260308   0.674731   0.809524  \n",
      "f1 weighted average score: [0.8101]\n",
      "EPOCH 74 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 60.0%\n",
      "[5]: 80.0%\n",
      "    74     0.275527   0.685223   0.803175  \n",
      "f1 weighted average score: [0.8024]\n",
      "EPOCH 75 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 37.14%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 48.57%\n",
      "[5]: 80.0%\n",
      "    75     0.280561   0.720304   0.774603  \n",
      "f1 weighted average score: [0.7693]\n",
      "EPOCH 76 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 50.0%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 58.57%\n",
      "[5]: 80.0%\n",
      "    76     0.271464   0.674975   0.803175  \n",
      "f1 weighted average score: [0.8032]\n",
      "EPOCH 77 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 58.57%\n",
      "[5]: 80.0%\n",
      "    77     0.262003   0.674305   0.809524  \n",
      "f1 weighted average score: [0.8103]\n",
      "EPOCH 78 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 52.86%\n",
      "[5]: 80.0%\n",
      "    78     0.259041   0.693884   0.793651  \n",
      "f1 weighted average score: [0.7933]\n",
      "EPOCH 79 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 52.86%\n",
      "[5]: 80.0%\n",
      "    79     0.260809   0.691573   0.796825  \n",
      "f1 weighted average score: [0.7967]\n",
      "EPOCH 80 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 61.43%\n",
      "[5]: 80.0%\n",
      "    80     0.257799   0.679114   0.806349  \n",
      "f1 weighted average score: [0.8062]\n",
      "EPOCH 81 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 48.57%\n",
      "[5]: 80.0%\n",
      "    81     0.251795   0.691131   0.790476  \n",
      "f1 weighted average score: [0.7887]\n",
      "EPOCH 82 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 58.57%\n",
      "[5]: 80.0%\n",
      "    82     0.259235   0.683526   0.803175  \n",
      "f1 weighted average score: [0.8034]\n",
      "EPOCH 83 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 52.86%\n",
      "[5]: 80.0%\n",
      "    83     0.262317   0.701901   0.8       \n",
      "f1 weighted average score: [0.7994]\n",
      "EPOCH 84 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 55.71%\n",
      "[5]: 80.0%\n",
      "    84     0.256655   0.69299    0.8       \n",
      "f1 weighted average score: [0.8016]\n",
      "EPOCH 85 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 40.0%\n",
      "[1]: 58.57%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 47.14%\n",
      "[5]: 82.86%\n",
      "    85     0.26026    0.718115   0.777778  \n",
      "f1 weighted average score: [0.7739]\n",
      "EPOCH 86 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 37.14%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 60.0%\n",
      "[5]: 80.0%\n",
      "    86     0.25452    0.690892   0.803175  \n",
      "f1 weighted average score: [0.8035]\n",
      "EPOCH 87 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 38.57%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 60.0%\n",
      "[5]: 80.0%\n",
      "    87     0.259661   0.684115   0.806349  \n",
      "f1 weighted average score: [0.8064]\n",
      "EPOCH 88 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 60.0%\n",
      "[5]: 85.71%\n",
      "    88     0.264867   0.684923   0.812698  \n",
      "f1 weighted average score: [0.8129]\n",
      "EPOCH 89 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 61.43%\n",
      "[5]: 82.86%\n",
      "    89     0.274614   0.680443   0.812698  \n",
      "f1 weighted average score: [0.814]\n",
      "EPOCH 90 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 51.43%\n",
      "[5]: 82.86%\n",
      "    90     0.271047   0.690663   0.803175  \n",
      "f1 weighted average score: [0.8018]\n",
      "EPOCH 91 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 62.86%\n",
      "[5]: 82.86%\n",
      "    91     0.267791   0.682684   0.819048  \n",
      "f1 weighted average score: [0.8202]\n",
      "EPOCH 92 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 58.57%\n",
      "[5]: 82.86%\n",
      "    92     0.265734   0.694912   0.8       \n",
      "f1 weighted average score: [0.7997]\n",
      "EPOCH 93 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 37.14%\n",
      "[1]: 58.57%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 47.14%\n",
      "[5]: 82.86%\n",
      "    93     0.263219   0.702921   0.793651  \n",
      "f1 weighted average score: [0.7911]\n",
      "EPOCH 94 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 51.43%\n",
      "[4]: 61.43%\n",
      "[5]: 82.86%\n",
      "    94     0.256966   0.661544   0.822222  \n",
      "f1 weighted average score: [0.8233]\n",
      "EPOCH 95 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 61.43%\n",
      "[5]: 82.86%\n",
      "    95     0.262149   0.690352   0.806349  \n",
      "f1 weighted average score: [0.8068]\n",
      "EPOCH 96 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 58.57%\n",
      "[5]: 80.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    96     0.268528   0.702797   0.806349  \n",
      "f1 weighted average score: [0.8059]\n",
      "EPOCH 97 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 37.14%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 54.29%\n",
      "[5]: 82.86%\n",
      "    97     0.260868   0.699999   0.806349  \n",
      "f1 weighted average score: [0.8056]\n",
      "EPOCH 98 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 37.14%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 57.14%\n",
      "[5]: 82.86%\n",
      "    98     0.262228   0.696031   0.803175  \n",
      "f1 weighted average score: [0.8029]\n",
      "EPOCH 99 ---------------                                   \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 58.57%\n",
      "[5]: 80.0%\n",
      "    99     0.247419   0.686093   0.815873  \n",
      "f1 weighted average score: [0.8154]\n",
      "EPOCH 100 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 58.57%\n",
      "[5]: 80.0%\n",
      "   100     0.256165   0.68996    0.809524  \n",
      "f1 weighted average score: [0.8105]\n",
      "EPOCH 101 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 38.57%\n",
      "[1]: 58.57%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 52.86%\n",
      "[5]: 82.86%\n",
      "   101     0.25598    0.694298   0.809524  \n",
      "f1 weighted average score: [0.8081]\n",
      "EPOCH 102 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 38.57%\n",
      "[1]: 51.43%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 55.71%\n",
      "[5]: 82.86%\n",
      "   102     0.259556   0.657123   0.812698  \n",
      "f1 weighted average score: [0.8135]\n",
      "EPOCH 103 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 37.14%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 57.14%\n",
      "[5]: 82.86%\n",
      "   103     0.280149   0.642187   0.819048  \n",
      "f1 weighted average score: [0.8189]\n",
      "EPOCH 104 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 62.86%\n",
      "[5]: 80.0%\n",
      "   104     0.280714   0.65199    0.815873  \n",
      "f1 weighted average score: [0.8166]\n",
      "EPOCH 105 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 57.14%\n",
      "[5]: 82.86%\n",
      "   105     0.264968   0.673223   0.8       \n",
      "f1 weighted average score: [0.7994]\n",
      "EPOCH 106 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 57.14%\n",
      "[5]: 82.86%\n",
      "   106     0.277135   0.657055   0.822222  \n",
      "f1 weighted average score: [0.8227]\n",
      "EPOCH 107 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 61.43%\n",
      "[5]: 82.86%\n",
      "   107     0.274652   0.637489   0.822222  \n",
      "f1 weighted average score: [0.823]\n",
      "EPOCH 108 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 60.0%\n",
      "[5]: 82.86%\n",
      "   108     0.26961    0.641644   0.819048  \n",
      "f1 weighted average score: [0.8197]\n",
      "EPOCH 109 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 28.57%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 60.0%\n",
      "[5]: 80.0%\n",
      "   109     0.259801   0.653097   0.809524  \n",
      "f1 weighted average score: [0.8096]\n",
      "EPOCH 110 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 58.57%\n",
      "[5]: 82.86%\n",
      "   110     0.250712   0.643514   0.819048  \n",
      "f1 weighted average score: [0.8189]\n",
      "EPOCH 111 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 54.29%\n",
      "[5]: 82.86%\n",
      "   111     0.247157   0.656304   0.803175  \n",
      "f1 weighted average score: [0.8024]\n",
      "EPOCH 112 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 60.0%\n",
      "[5]: 82.86%\n",
      "   112     0.246444   0.654616   0.815873  \n",
      "f1 weighted average score: [0.8162]\n",
      "EPOCH 113 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 37.14%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 47.14%\n",
      "[5]: 82.86%\n",
      "   113     0.245823   0.691194   0.796825  \n",
      "f1 weighted average score: [0.7954]\n",
      "EPOCH 114 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 55.71%\n",
      "[5]: 82.86%\n",
      "   114     0.250272   0.666601   0.809524  \n",
      "f1 weighted average score: [0.8094]\n",
      "EPOCH 115 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 55.71%\n",
      "[5]: 82.86%\n",
      "   115     0.242588   0.676589   0.812698  \n",
      "f1 weighted average score: [0.8131]\n",
      "EPOCH 116 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 51.43%\n",
      "[5]: 82.86%\n",
      "   116     0.232843   0.699911   0.803175  \n",
      "f1 weighted average score: [0.8009]\n",
      "EPOCH 117 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 55.71%\n",
      "[5]: 80.0%\n",
      "   117     0.235853   0.698142   0.793651  \n",
      "f1 weighted average score: [0.7922]\n",
      "EPOCH 118 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 61.43%\n",
      "[5]: 80.0%\n",
      "   118     0.244269   0.669329   0.806349  \n",
      "f1 weighted average score: [0.8072]\n",
      "EPOCH 119 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 61.43%\n",
      "[5]: 82.86%\n",
      "   119     0.243105   0.66986    0.815873  \n",
      "f1 weighted average score: [0.8161]\n",
      "EPOCH 120 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 54.29%\n",
      "[5]: 82.86%\n",
      "   120     0.242049   0.681411   0.803175  \n",
      "f1 weighted average score: [0.8023]\n",
      "EPOCH 121 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 67.14%\n",
      "[5]: 82.86%\n",
      "   121     0.250849   0.640595   0.822222  \n",
      "f1 weighted average score: [0.823]\n",
      "EPOCH 122 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 58.57%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 48.57%\n",
      "[5]: 82.86%\n",
      "   122     0.255925   0.710347   0.790476  \n",
      "f1 weighted average score: [0.7877]\n",
      "EPOCH 123 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 48.57%\n",
      "[5]: 82.86%\n",
      "   123     0.252097   0.713415   0.793651  \n",
      "f1 weighted average score: [0.7926]\n",
      "EPOCH 124 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 38.57%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 55.71%\n",
      "[5]: 82.86%\n",
      "   124     0.247473   0.706716   0.790476  \n",
      "f1 weighted average score: [0.7885]\n",
      "EPOCH 125 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 58.57%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 50.0%\n",
      "[5]: 82.86%\n",
      "   125     0.246784   0.752934   0.774603  \n",
      "f1 weighted average score: [0.7745]\n",
      "EPOCH 126 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 61.43%\n",
      "[5]: 82.86%\n",
      "   126     0.249921   0.661591   0.812698  \n",
      "f1 weighted average score: [0.8128]\n",
      "EPOCH 127 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 30.0%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 61.43%\n",
      "[5]: 82.86%\n",
      "   127     0.254728   0.651578   0.825397  \n",
      "f1 weighted average score: [0.8263]\n",
      "EPOCH 128 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 61.43%\n",
      "[5]: 80.0%\n",
      "   128     0.249493   0.652267   0.815873  \n",
      "f1 weighted average score: [0.8167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 129 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 54.29%\n",
      "[5]: 82.86%\n",
      "   129     0.244801   0.66884    0.8       \n",
      "f1 weighted average score: [0.7991]\n",
      "EPOCH 130 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 57.14%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 55.71%\n",
      "[5]: 80.0%\n",
      "   130     0.239734   0.674355   0.806349  \n",
      "f1 weighted average score: [0.8062]\n",
      "EPOCH 131 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 61.43%\n",
      "[5]: 80.0%\n",
      "   131     0.243996   0.651457   0.819048  \n",
      "f1 weighted average score: [0.8203]\n",
      "EPOCH 132 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 60.0%\n",
      "[5]: 80.0%\n",
      "   132     0.23613    0.647949   0.819048  \n",
      "f1 weighted average score: [0.8203]\n",
      "EPOCH 133 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 37.14%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 54.29%\n",
      "[5]: 82.86%\n",
      "   133     0.231776   0.644501   0.812698  \n",
      "f1 weighted average score: [0.8123]\n",
      "EPOCH 134 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 60.0%\n",
      "[5]: 82.86%\n",
      "   134     0.235373   0.648465   0.819048  \n",
      "f1 weighted average score: [0.8199]\n",
      "EPOCH 135 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 38.57%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 57.14%\n",
      "[5]: 82.86%\n",
      "   135     0.239778   0.663885   0.803175  \n",
      "f1 weighted average score: [0.8032]\n",
      "EPOCH 136 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 60.0%\n",
      "[5]: 82.86%\n",
      "   136     0.247014   0.641414   0.822222  \n",
      "f1 weighted average score: [0.8231]\n",
      "EPOCH 137 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 38.57%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 55.71%\n",
      "[5]: 82.86%\n",
      "   137     0.235741   0.657128   0.806349  \n",
      "f1 weighted average score: [0.8063]\n",
      "EPOCH 138 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 60.0%\n",
      "[5]: 82.86%\n",
      "   138     0.240659   0.645131   0.822222  \n",
      "f1 weighted average score: [0.8233]\n",
      "EPOCH 139 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 60.0%\n",
      "[5]: 82.86%\n",
      "   139     0.235686   0.64129    0.825397  \n",
      "f1 weighted average score: [0.8266]\n",
      "EPOCH 140 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 40.0%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 60.0%\n",
      "[5]: 82.86%\n",
      "   140     0.245014   0.656114   0.812698  \n",
      "f1 weighted average score: [0.8131]\n",
      "EPOCH 141 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 60.0%\n",
      "[5]: 82.86%\n",
      "   141     0.239516   0.636684   0.822222  \n",
      "f1 weighted average score: [0.8236]\n",
      "EPOCH 142 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 38.57%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 48.57%\n",
      "[4]: 57.14%\n",
      "[5]: 82.86%\n",
      "   142     0.240741   0.633473   0.819048  \n",
      "f1 weighted average score: [0.8186]\n",
      "EPOCH 143 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 54.29%\n",
      "[5]: 80.0%\n",
      "   143     0.23788    0.677448   0.806349  \n",
      "f1 weighted average score: [0.8043]\n",
      "EPOCH 144 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 38.57%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 62.86%\n",
      "[5]: 80.0%\n",
      "   144     0.251625   0.680065   0.806349  \n",
      "f1 weighted average score: [0.8057]\n",
      "EPOCH 145 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 60.0%\n",
      "[5]: 82.86%\n",
      "   145     0.252894   0.664266   0.822222  \n",
      "f1 weighted average score: [0.8225]\n",
      "EPOCH 146 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 37.14%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 61.43%\n",
      "[5]: 82.86%\n",
      "   146     0.239514   0.653006   0.812698  \n",
      "f1 weighted average score: [0.8131]\n",
      "EPOCH 147 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 38.57%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 52.86%\n",
      "[5]: 82.86%\n",
      "   147     0.24597    0.661037   0.812698  \n",
      "f1 weighted average score: [0.8128]\n",
      "EPOCH 148 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 64.29%\n",
      "[5]: 82.86%\n",
      "   148     0.246598   0.655826   0.815873  \n",
      "f1 weighted average score: [0.8161]\n",
      "EPOCH 149 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 58.57%\n",
      "[5]: 82.86%\n",
      "   149     0.255905   0.667557   0.815873  \n",
      "f1 weighted average score: [0.816]\n",
      "EPOCH 150 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 62.86%\n",
      "[5]: 82.86%\n",
      "   150     0.255154   0.669086   0.806349  \n",
      "f1 weighted average score: [0.8057]\n",
      "EPOCH 151 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 31.43%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 60.0%\n",
      "[5]: 80.0%\n",
      "   151     0.246977   0.672781   0.815873  \n",
      "f1 weighted average score: [0.8163]\n",
      "EPOCH 152 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 35.71%\n",
      "[1]: 55.71%\n",
      "[2]:  0.0%\n",
      "[3]: 42.86%\n",
      "[4]: 61.43%\n",
      "[5]: 80.0%\n",
      "   152     0.247988   0.682614   0.812698  \n",
      "f1 weighted average score: [0.8123]\n",
      "EPOCH 153 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 37.14%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 51.43%\n",
      "[5]: 82.86%\n",
      "   153     0.294782   0.662746   0.812698  \n",
      "f1 weighted average score: [0.8109]\n",
      "EPOCH 154 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 57.14%\n",
      "[5]: 82.86%\n",
      "   154     0.271289   0.619176   0.828571  \n",
      "f1 weighted average score: [0.8285]\n",
      "EPOCH 155 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 58.57%\n",
      "[5]: 82.86%\n",
      "   155     0.264018   0.627316   0.819048  \n",
      "f1 weighted average score: [0.8199]\n",
      "EPOCH 156 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 37.14%\n",
      "[1]: 52.86%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 58.57%\n",
      "[5]: 82.86%\n",
      "   156     0.257353   0.644774   0.812698  \n",
      "f1 weighted average score: [0.8128]\n",
      "EPOCH 157 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 58.57%\n",
      "[5]: 82.86%\n",
      "   157     0.241963   0.637972   0.815873  \n",
      "f1 weighted average score: [0.815]\n",
      "EPOCH 158 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 32.86%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 57.14%\n",
      "[5]: 82.86%\n",
      "   158     0.239124   0.637547   0.809524  \n",
      "f1 weighted average score: [0.8094]\n",
      "EPOCH 159 ---------------                                  \n",
      "batch distribution:  [22, 21, 5, 14, 30, 5]\n",
      "[0]: 34.29%\n",
      "[1]: 54.29%\n",
      "[2]:  0.0%\n",
      "[3]: 45.71%\n",
      "[4]: 61.43%\n",
      "[5]: 82.86%\n",
      "   159     0.2395     0.627283   0.831746  \n",
      "f1 weighted average score: [0.8317]\n",
      "\n",
      "CPU times: user 40min 54s, sys: 16min 39s, total: 57min 33s\n",
      "Wall time: 38min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.62728]), 0.8317460372334435]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-3, 8, wds=wd, cycle_len=20, use_clr=(20,8, 0.95, 0.85), best_save_name=learn.model.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('Objective_C_Resnet_per_class_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(1e-3, 8, wds=wd, cycle_len=10, use_clr=(20,8, 0.95, 0.85), best_save_name=learn.model.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(1e-3, 1, wds=wd, cycle_len=1, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze results \n",
    "log_preds, y = learn.TTA(n_aug=1)\n",
    "log_preds_mean = np.mean(log_preds, axis=0)\n",
    "preds = np.argmax(log_preds_mean, axis=1)\n",
    "# cm = confusion_matrix(preds,y)\n",
    "cm = confusion_matrix(y, preds)\n",
    "plot_confusion_matrix(cm, data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
