{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import skimage.external.tifffile as tiff\n",
    "\n",
    "from common import Statistics, dataset_source\n",
    "from resources.conv_learner import *\n",
    "from resources.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../datasets/yeast_v5\"\n",
    "data_path = Path(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ('WT', 'mfb1KO', 'mfb1KO_mmr1KO', 'mmr1KO', 'mmm1KO_230', 'num1_110')\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "BATCH_SIZE = 64\n",
    "SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on: mfb1KO\n",
      "working on: mfb1KO_mmr1KO\n",
      "working on: mmr1KO\n",
      "working on: WT\n",
      "working on: mmm1KO_230\n",
      "working on: num1_110\n"
     ]
    }
   ],
   "source": [
    "stats_name = \"yeast_v5_per_class.dict\"\n",
    "test_dirs, train_dirs = dataset_source(data_path)\n",
    "stats_dict = Statistics.per_class(test_dirs, train_dirs,save_name=stats_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path: str, sz, bs, stats):\n",
    "    create, lbl2index = ImageClassifierData.prepare_from_path(path, val_name='test', bs=bs, balance=True)\n",
    "    stats_dict = {lbl2index[key]: val for key, val in stats.items()}\n",
    "    tfms = tfms_from_stats(stats_dict, sz, aug_tfms=[RandomDihedral()], pad=sz//8) #even without transformations and padding -> failure\n",
    "    print('\\n class to index mapping:\\n',lbl2index)\n",
    "    return create(tfms)\n",
    "\n",
    "### the eventual sub-function of ImageClassifierData (read_dirs) expects subdirectories for each class: \n",
    "### e.g. all \"test/cat.png\" images should be in a \"cat\" folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.018555202366876015\n",
      "-0.017172535478982644\n",
      "0.15949723926705456\n",
      "0.01022554069958134\n",
      "-0.03429450382046319\n",
      "0.14697767745171808\n",
      "\n",
      " class to index mapping:\n",
      " {'WT': 0, 'mfb1KO': 1, 'mfb1KO_mmr1KO': 2, 'mmm1KO_230': 3, 'mmr1KO': 4, 'num1_110': 5}\n"
     ]
    }
   ],
   "source": [
    "data = get_data(PATH,SIZE, BATCH_SIZE,stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(data.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 30\n",
    "tiff.imshow(data.trn_ds.denorm(x[idx], y[idx].item()).squeeze()[:,:,0]); #denorm function called has a rollaxis() hence indexing changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(layers[i], layers[i + 1]) for i in range(len(layers) - 1)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        for l in self.layers:\n",
    "            l_x = l(x)\n",
    "            x = F.relu(l_x)\n",
    "        return F.log_softmax(l_x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(SimpleNet([200*200*2, 40, NUM_CLASSES]), data) #(!) change channel-number & classes accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn, [o.numel() for o in learn.model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(lr, 200, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Conv2d(layers[i], layers[i + 1], kernel_size=5, stride=1, padding=(2,2))\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for l in self.layers: x = F.relu(l(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(ConvNet([2, 20, 40, 80], 6), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.summary() ### learner.summary is hardcording the number of channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(lr, 10, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet_with_Batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BnLayer(nn.Module):\n",
    "    def __init__(self, ni, nf, stride=2, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(ni, nf, kernel_size=kernel_size, stride=stride,\n",
    "                              bias=False, padding=1)\n",
    "        self.a = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.m = nn.Parameter(torch.ones(nf,1,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x_chan = x.transpose(0,1).contiguous().view(x.size(1), -1)\n",
    "        if self.training:\n",
    "            self.means = x_chan.mean(1)[:,None,None]\n",
    "            self.stds  = x_chan.std (1)[:,None,None]\n",
    "        return (x-self.means) / self.stds *self.m + self.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetLayer(BnLayer):\n",
    "    def forward(self, x): return x + super().forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(nn.Module):\n",
    "    def __init__(self, layers, c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 10, kernel_size=5, stride=1, padding=2)\n",
    "        self.layers = nn.ModuleList([BnLayer(layers[i], layers[i+1])\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.layers2 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i + 1], 1)\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.layers3 = nn.ModuleList([ResnetLayer(layers[i+1], layers[i + 1], 1)\n",
    "            for i in range(len(layers) - 1)])\n",
    "        self.out = nn.Linear(layers[-1], c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        for l,l2,l3 in zip(self.layers, self.layers2, self.layers3):\n",
    "            x = l3(l2(l(x)))\n",
    "        x = F.adaptive_max_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.log_softmax(self.out(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(Resnet([10, 20, 40, 80, 160], 6), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d-1',\n",
       "              OrderedDict([('input_shape', [-1, 2, 200, 200]),\n",
       "                           ('output_shape', [-1, 10, 200, 200]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 510)])),\n",
       "             ('Conv2d-2',\n",
       "              OrderedDict([('input_shape', [-1, 10, 200, 200]),\n",
       "                           ('output_shape', [-1, 20, 100, 100]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 1800)])),\n",
       "             ('BnLayer-3',\n",
       "              OrderedDict([('input_shape', [-1, 10, 200, 200]),\n",
       "                           ('output_shape', [-1, 20, 100, 100]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-4',\n",
       "              OrderedDict([('input_shape', [-1, 20, 100, 100]),\n",
       "                           ('output_shape', [-1, 20, 100, 100]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 3600)])),\n",
       "             ('ResnetLayer-5',\n",
       "              OrderedDict([('input_shape', [-1, 20, 100, 100]),\n",
       "                           ('output_shape', [-1, 20, 100, 100]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-6',\n",
       "              OrderedDict([('input_shape', [-1, 20, 100, 100]),\n",
       "                           ('output_shape', [-1, 20, 100, 100]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 3600)])),\n",
       "             ('ResnetLayer-7',\n",
       "              OrderedDict([('input_shape', [-1, 20, 100, 100]),\n",
       "                           ('output_shape', [-1, 20, 100, 100]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-8',\n",
       "              OrderedDict([('input_shape', [-1, 20, 100, 100]),\n",
       "                           ('output_shape', [-1, 40, 50, 50]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 7200)])),\n",
       "             ('BnLayer-9',\n",
       "              OrderedDict([('input_shape', [-1, 20, 100, 100]),\n",
       "                           ('output_shape', [-1, 40, 50, 50]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-10',\n",
       "              OrderedDict([('input_shape', [-1, 40, 50, 50]),\n",
       "                           ('output_shape', [-1, 40, 50, 50]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 14400)])),\n",
       "             ('ResnetLayer-11',\n",
       "              OrderedDict([('input_shape', [-1, 40, 50, 50]),\n",
       "                           ('output_shape', [-1, 40, 50, 50]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-12',\n",
       "              OrderedDict([('input_shape', [-1, 40, 50, 50]),\n",
       "                           ('output_shape', [-1, 40, 50, 50]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 14400)])),\n",
       "             ('ResnetLayer-13',\n",
       "              OrderedDict([('input_shape', [-1, 40, 50, 50]),\n",
       "                           ('output_shape', [-1, 40, 50, 50]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-14',\n",
       "              OrderedDict([('input_shape', [-1, 40, 50, 50]),\n",
       "                           ('output_shape', [-1, 80, 25, 25]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 28800)])),\n",
       "             ('BnLayer-15',\n",
       "              OrderedDict([('input_shape', [-1, 40, 50, 50]),\n",
       "                           ('output_shape', [-1, 80, 25, 25]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-16',\n",
       "              OrderedDict([('input_shape', [-1, 80, 25, 25]),\n",
       "                           ('output_shape', [-1, 80, 25, 25]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 57600)])),\n",
       "             ('ResnetLayer-17',\n",
       "              OrderedDict([('input_shape', [-1, 80, 25, 25]),\n",
       "                           ('output_shape', [-1, 80, 25, 25]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-18',\n",
       "              OrderedDict([('input_shape', [-1, 80, 25, 25]),\n",
       "                           ('output_shape', [-1, 80, 25, 25]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 57600)])),\n",
       "             ('ResnetLayer-19',\n",
       "              OrderedDict([('input_shape', [-1, 80, 25, 25]),\n",
       "                           ('output_shape', [-1, 80, 25, 25]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-20',\n",
       "              OrderedDict([('input_shape', [-1, 80, 25, 25]),\n",
       "                           ('output_shape', [-1, 160, 13, 13]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 115200)])),\n",
       "             ('BnLayer-21',\n",
       "              OrderedDict([('input_shape', [-1, 80, 25, 25]),\n",
       "                           ('output_shape', [-1, 160, 13, 13]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-22',\n",
       "              OrderedDict([('input_shape', [-1, 160, 13, 13]),\n",
       "                           ('output_shape', [-1, 160, 13, 13]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 230400)])),\n",
       "             ('ResnetLayer-23',\n",
       "              OrderedDict([('input_shape', [-1, 160, 13, 13]),\n",
       "                           ('output_shape', [-1, 160, 13, 13]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-24',\n",
       "              OrderedDict([('input_shape', [-1, 160, 13, 13]),\n",
       "                           ('output_shape', [-1, 160, 13, 13]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 230400)])),\n",
       "             ('ResnetLayer-25',\n",
       "              OrderedDict([('input_shape', [-1, 160, 13, 13]),\n",
       "                           ('output_shape', [-1, 160, 13, 13]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Linear-26',\n",
       "              OrderedDict([('input_shape', [-1, 160]),\n",
       "                           ('output_shape', [-1, 6]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 966)]))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2f42e0ca314414bbc1db36e0c6c2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1518244421288/work/torch/lib/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/YNet/YNet_dev/resources/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/YNet/YNet_dev/resources/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m                    \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                    \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                    swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/YNet/YNet_dev/resources/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mper_class_accuracies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (!) added per class accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/YNet/YNet_dev/resources/model.py\u001b[0m in \u001b[0;36mper_class_accuracies\u001b[0;34m(data_loader, model, epoch)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mIS_TORCH_04\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this is a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-58a4a0328ca6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml3\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_max_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-babf3ddde244>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mResnetLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBnLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-3dce9ef1bc51>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_chan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstds\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mx_chan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstds\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1518244421288/work/torch/lib/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "%time learn.fit(1e-2, 8, cycle_len=4, wds=wd, best_save_name='Objective_A_Resnet_per_class_balanced_fromstart_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a969cf7994041a695f11d2389d0dcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=80), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]:  0.0%                                                 \n",
      "[1]:  0.2%\n",
      "[2]: 0.5143%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.3857%\n",
      "[5]:  0.4%\n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.762936   0.921598   0.596825  \n",
      "[0]: 0.02857%                                              \n",
      "[1]:  0.0%\n",
      "[2]: 0.4857%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.4429%\n",
      "[5]:  0.4%\n",
      "    1      0.79728    1.020787   0.565079  \n",
      "[0]: 0.02857%                                              \n",
      "[1]: 0.04286%\n",
      "[2]: 0.6571%\n",
      "[3]: 0.8571%\n",
      "[4]: 0.3857%\n",
      "[5]: 0.6286%\n",
      "    2      0.868843   0.784458   0.644444  \n",
      "[0]:  0.0%                                                 \n",
      "[1]:  0.0%\n",
      "[2]: 0.6857%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.5714%\n",
      "[5]: 0.1714%\n",
      "    3      0.852408   1.046649   0.596825  \n",
      "[0]: 0.01429%                                              \n",
      "[1]:  0.0%\n",
      "[2]: 0.5143%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]:  0.4%\n",
      "    4      0.842904   0.929993   0.574603  \n",
      "[0]: 0.01429%                                              \n",
      "[1]:  0.0%\n",
      "[2]: 0.7429%\n",
      "[3]: 0.8857%\n",
      "[4]:  0.8%\n",
      "[5]:  0.8%\n",
      "    5      0.84534    0.773865   0.622222  \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.05714%\n",
      "[2]: 0.6571%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.5429%\n",
      "[5]: 0.4857%\n",
      "    6      0.802721   0.818247   0.663492  \n",
      "[0]: 0.01429%                                              \n",
      "[1]:  0.0%\n",
      "[2]:  0.8%\n",
      "[3]: 0.8571%\n",
      "[4]: 0.6714%\n",
      "[5]: 0.5143%\n",
      "    7      0.747906   0.775948   0.647619  \n",
      "[0]: 0.02857%                                              \n",
      "[1]: 0.02857%\n",
      "[2]: 0.7714%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.5286%\n",
      "[5]:  0.4%\n",
      "    8      0.726562   0.822228   0.692063  \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.02857%\n",
      "[2]: 0.7714%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.6286%\n",
      "[5]: 0.5714%\n",
      "    9      0.707895   0.763209   0.644444  \n",
      "[0]: 0.01429%                                              \n",
      "[1]: 0.08571%\n",
      "[2]: 0.7429%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.6286%\n",
      "[5]: 0.3143%\n",
      "    10     0.697695   1.111976   0.593651  \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.1714%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.8857%\n",
      "[4]:  0.6%\n",
      "[5]:  0.6%\n",
      "    11     0.686888   0.768724   0.609524  \n",
      "[0]: 0.04286%                                              \n",
      "[1]: 0.1286%\n",
      "[2]: 0.8286%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.4714%\n",
      "[5]: 0.4286%\n",
      "    12     0.684399   0.917711   0.55873   \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.1571%\n",
      "[2]: 0.8571%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.3714%\n",
      "[5]: 0.4571%\n",
      "    13     0.714021   0.804542   0.666667  \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.1714%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.3714%\n",
      "[5]: 0.6857%\n",
      "    14     0.714259   0.730154   0.650794  \n",
      "[0]: 0.04286%                                              \n",
      "[1]: 0.1286%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.4143%\n",
      "[5]: 0.4571%\n",
      "    15     0.682892   0.786856   0.688889  \n",
      "[0]: 0.01429%                                              \n",
      "[1]: 0.04286%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.7857%\n",
      "[5]: 0.5143%\n",
      "    16     0.64367    0.791939   0.669841  \n",
      "[0]: 0.04286%                                              \n",
      "[1]: 0.02857%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.6857%\n",
      "[5]: 0.6286%\n",
      "    17     0.617229   0.674144   0.746032  \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.1429%\n",
      "[2]: 0.6857%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.5143%\n",
      "[5]: 0.4857%\n",
      "    18     0.593869   0.699927   0.704762  \n",
      "[0]: 0.05714%                                              \n",
      "[1]:  0.1%\n",
      "[2]: 0.6857%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.5857%\n",
      "[5]: 0.4857%\n",
      "    19     0.568613   0.715681   0.707937  \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.1429%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.3286%\n",
      "[5]: 0.5714%\n",
      "    20     0.570643   0.812492   0.622222  \n",
      "[0]: 0.07143%                                              \n",
      "[1]: 0.05714%\n",
      "[2]: 0.6857%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.5429%\n",
      "[5]: 0.3143%\n",
      "    21     0.580482   0.799701   0.692063  \n",
      "[0]: 0.02857%                                              \n",
      "[1]: 0.1429%\n",
      "[2]:  0.8%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.4429%\n",
      "[5]: 0.5714%\n",
      "    22     0.594815   0.705997   0.711111  \n",
      "[0]: 0.01429%                                              \n",
      "[1]: 0.01429%\n",
      "[2]: 0.7429%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.5857%\n",
      "[5]: 0.4857%\n",
      "    23     0.581482   0.804057   0.609524  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.07143%\n",
      "[2]: 0.6857%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.4143%\n",
      "[5]: 0.5429%\n",
      "    24     0.569717   0.78076    0.663492  \n",
      "[0]: 0.02857%                                              \n",
      "[1]:  0.0%\n",
      "[2]: 0.7429%\n",
      "[3]: 0.9429%\n",
      "[4]:  0.6%\n",
      "[5]: 0.2857%\n",
      "    25     0.565671   0.84164    0.64127   \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.08571%\n",
      "[2]:  0.8%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.4429%\n",
      "[5]: 0.6857%\n",
      "    26     0.571987   0.645759   0.736508  \n",
      "[0]: 0.01429%                                              \n",
      "[1]:  0.0%\n",
      "[2]: 0.7714%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.6571%\n",
      "    27     0.576862   0.700967   0.704762  \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.1571%\n",
      "[2]: 0.6857%\n",
      "[3]: 0.9143%\n",
      "[4]:  0.5%\n",
      "[5]: 0.5429%\n",
      "    28     0.5497     0.732969   0.688889  \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.2143%\n",
      "[2]: 0.8571%\n",
      "[3]: 0.8571%\n",
      "[4]: 0.3714%\n",
      "[5]: 0.5143%\n",
      "    29     0.537552   0.716176   0.669841  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.2857%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.5286%\n",
      "[5]: 0.6571%\n",
      "    30     0.52889    0.735633   0.695238  \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.2571%\n",
      "[2]: 0.8571%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.2143%\n",
      "[5]:  0.4%\n",
      "    31     0.545586   0.901931   0.596825  \n",
      "[0]: 0.1286%                                               \n",
      "[1]: 0.1571%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.8571%\n",
      "[4]: 0.3857%\n",
      "[5]: 0.8286%\n",
      "    32     0.537811   0.683702   0.67619   \n",
      "[0]: 0.1143%                                               \n",
      "[1]: 0.02857%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.9429%\n",
      "[4]:  0.7%\n",
      "[5]: 0.4286%\n",
      "    33     0.546066   0.854876   0.67619   \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.01429%\n",
      "[2]: 0.7429%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.6286%\n",
      "[5]: 0.4857%\n",
      "    34     0.526851   0.78336    0.64127   \n",
      "[0]: 0.1286%                                               \n",
      "[1]:  0.1%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.8571%\n",
      "[4]: 0.5714%\n",
      "[5]: 0.6857%\n",
      "    35     0.500098   0.680882   0.685714  \n",
      "[0]:  0.1%                                                 \n",
      "[1]: 0.07143%\n",
      "[2]: 0.7429%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.4857%\n",
      "[5]: 0.3429%\n",
      "    36     0.478462   0.799931   0.631746  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.1429%\n",
      "[2]: 0.8286%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.4143%\n",
      "[5]: 0.4857%\n",
      "    37     0.468836   0.668861   0.692063  \n",
      "[0]: 0.07143%                                              \n",
      "[1]:  0.1%\n",
      "[2]: 0.7429%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.5286%\n",
      "[5]:  0.6%\n",
      "    38     0.450967   0.6438     0.714286  \n",
      "[0]: 0.1143%                                               \n",
      "[1]: 0.08571%\n",
      "[2]:  0.8%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.6286%\n",
      "[5]: 0.4571%\n",
      "    39     0.429762   0.724898   0.695238  \n",
      "[0]: 0.1143%                                               \n",
      "[1]: 0.1429%\n",
      "[2]: 0.6857%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.3714%\n",
      "[5]: 0.7714%\n",
      "    40     0.429178   0.674501   0.692063  \n",
      "[0]: 0.08571%                                              \n",
      "[1]:  0.0%\n",
      "[2]: 0.7429%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.6714%\n",
      "[5]: 0.7429%\n",
      "    41     0.448258   0.628035   0.704762  \n",
      "[0]:  0.1%                                                 \n",
      "[1]: 0.1286%\n",
      "[2]: 0.6857%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.4429%\n",
      "[5]: 0.4857%\n",
      "    42     0.448302   0.706436   0.704762  \n",
      "[0]: 0.1857%                                               \n",
      "[1]:  0.1%\n",
      "[2]: 0.7714%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.5143%\n",
      "[5]: 0.4571%\n",
      "    43     0.474187   0.672859   0.733333  \n",
      "[0]:  0.2%                                                 \n",
      "[1]: 0.1143%\n",
      "[2]: 0.6571%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.6429%\n",
      "[5]: 0.2571%\n",
      "    44     0.461869   0.915445   0.619048  \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.05714%\n",
      "[2]: 0.6286%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.5857%\n",
      "[5]: 0.2857%\n",
      "    45     0.458568   0.770434   0.609524  \n",
      "[0]: 0.08571%                                              \n",
      "[1]: 0.08571%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.6571%\n",
      "[5]: 0.4571%\n",
      "    46     0.442084   0.730008   0.666667  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.1286%\n",
      "[2]: 0.7714%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.5714%\n",
      "[5]: 0.5143%\n",
      "    47     0.425938   0.63045    0.714286  \n",
      "[0]: 0.1714%                                               \n",
      "[1]:  0.2%\n",
      "[2]: 0.6286%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.4714%\n",
      "[5]: 0.6571%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    48     0.412731   0.604163   0.726984  \n",
      "[0]: 0.1571%                                               \n",
      "[1]:  0.1%\n",
      "[2]: 0.7714%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.4857%\n",
      "[5]: 0.4857%\n",
      "    49     0.423176   0.695306   0.707937  \n",
      "[0]: 0.2286%                                               \n",
      "[1]:  0.2%\n",
      "[2]: 0.7429%\n",
      "[3]: 0.9143%\n",
      "[4]:  0.3%\n",
      "[5]: 0.6571%\n",
      "    50     0.441346   0.817056   0.64127   \n",
      "[0]: 0.08571%                                              \n",
      "[1]:  0.1%\n",
      "[2]:  0.8%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.5571%\n",
      "[5]:  0.4%\n",
      "    51     0.447607   0.840534   0.615873  \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.1571%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.6429%\n",
      "[5]: 0.4571%\n",
      "    52     0.456322   0.686182   0.698413  \n",
      "[0]: 0.08571%                                              \n",
      "[1]: 0.1429%\n",
      "[2]: 0.6286%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.6143%\n",
      "[5]: 0.6857%\n",
      "    53     0.445973   0.68793    0.68254   \n",
      "[0]: 0.01429%                                              \n",
      "[1]: 0.1429%\n",
      "[2]:  0.8%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.5857%\n",
      "[5]: 0.4571%\n",
      "    54     0.429751   0.703978   0.67619   \n",
      "[0]:  0.1%                                                 \n",
      "[1]: 0.1429%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.4429%\n",
      "[5]: 0.7714%\n",
      "    55     0.410505   0.680631   0.704762  \n",
      "[0]: 0.07143%                                              \n",
      "[1]:  0.2%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.7429%\n",
      "[4]: 0.4143%\n",
      "[5]: 0.7143%\n",
      "    56     0.394875   0.612339   0.71746   \n",
      "[0]: 0.04286%                                              \n",
      "[1]:  0.1%\n",
      "[2]: 0.6571%\n",
      "[3]: 0.9429%\n",
      "[4]:  0.6%\n",
      "[5]: 0.4571%\n",
      "    57     0.387308   0.653715   0.714286  \n",
      "[0]: 0.07143%                                              \n",
      "[1]: 0.1429%\n",
      "[2]: 0.7429%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.5286%\n",
      "[5]: 0.4857%\n",
      "    58     0.389379   0.619803   0.720635  \n",
      "[0]: 0.04286%                                              \n",
      "[1]: 0.1714%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.5143%\n",
      "[5]: 0.6857%\n",
      "    59     0.377262   0.616758   0.733333  \n",
      "[0]: 0.1286%                                               \n",
      "[1]: 0.2143%\n",
      "[2]: 0.7714%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.2714%\n",
      "[5]: 0.5429%\n",
      "    60     0.383322   0.751019   0.679365  \n",
      "[0]: 0.1429%                                               \n",
      "[1]: 0.1857%\n",
      "[2]:  0.6%\n",
      "[3]: 0.9714%\n",
      "[4]:  0.5%\n",
      "[5]: 0.5429%\n",
      "    61     0.385654   0.679515   0.688889  \n",
      "[0]: 0.08571%                                              \n",
      "[1]: 0.1714%\n",
      "[2]: 0.6857%\n",
      "[3]: 0.9429%\n",
      "[4]:  0.5%\n",
      "[5]:  0.6%\n",
      "    62     0.375822   0.550871   0.774603  \n",
      "[0]: 0.08571%                                              \n",
      "[1]: 0.1714%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.4571%\n",
      "[5]: 0.5143%\n",
      "    63     0.376821   0.600078   0.768254  \n",
      "[0]:  0.1%                                                 \n",
      "[1]: 0.1571%\n",
      "[2]: 0.7429%\n",
      "[3]: 0.8571%\n",
      "[4]: 0.4571%\n",
      "[5]: 0.6286%\n",
      "    64     0.38056    0.61045    0.720635  \n",
      "[0]: 0.05714%                                              \n",
      "[1]: 0.1286%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.7714%\n",
      "[4]: 0.5571%\n",
      "[5]: 0.6857%\n",
      "    65     0.37519    0.603063   0.698413  \n",
      "[0]: 0.08571%                                              \n",
      "[1]: 0.1571%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.4143%\n",
      "[5]: 0.4857%\n",
      "    66     0.377059   0.644134   0.746032  \n",
      "[0]: 0.1429%                                               \n",
      "[1]: 0.1143%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.5857%\n",
      "[5]: 0.5143%\n",
      "    67     0.396625   0.695831   0.695238  \n",
      "[0]: 0.1429%                                               \n",
      "[1]: 0.1143%\n",
      "[2]: 0.7429%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.5286%\n",
      "[5]:  0.6%\n",
      "    68     0.384319   0.672081   0.704762  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.1429%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.9429%\n",
      "[4]: 0.5286%\n",
      "[5]: 0.5143%\n",
      "    69     0.365835   0.620938   0.736508  \n",
      "[0]: 0.04286%                                              \n",
      "[1]: 0.08571%\n",
      "[2]:  0.8%\n",
      "[3]: 0.8571%\n",
      "[4]: 0.6286%\n",
      "[5]: 0.5429%\n",
      "    70     0.352125   0.607814   0.742857  \n",
      "[0]:  0.2%                                                 \n",
      "[1]: 0.1571%\n",
      "[2]: 0.7143%\n",
      "[3]: 0.7143%\n",
      "[4]: 0.4857%\n",
      "[5]: 0.8286%\n",
      "    71     0.351974   0.558372   0.71746   \n",
      "[0]:  0.1%                                                 \n",
      "[1]: 0.07143%\n",
      "[2]: 0.6286%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.6571%\n",
      "[5]: 0.3143%\n",
      "    72     0.369121   0.769903   0.726984  \n",
      "[0]: 0.1429%                                               \n",
      "[1]: 0.02857%\n",
      "[2]: 0.6571%\n",
      "[3]: 0.8571%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.4286%\n",
      "    73     0.373667   0.775924   0.698413  \n",
      "[0]: 0.08571%                                              \n",
      "[1]: 0.04286%\n",
      "[2]: 0.6857%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.7571%\n",
      "[5]: 0.4571%\n",
      "    74     0.37986    0.65886    0.726984  \n",
      "[0]: 0.1857%                                               \n",
      "[1]: 0.1286%\n",
      "[2]: 0.6286%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.5857%\n",
      "[5]: 0.4286%\n",
      "    75     0.363262   0.77863    0.660317  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.1286%\n",
      "[2]:  0.6%\n",
      "[3]: 0.8286%\n",
      "[4]: 0.5286%\n",
      "[5]: 0.4857%\n",
      "    76     0.346684   0.697479   0.695238  \n",
      "[0]:  0.2%                                                 \n",
      "[1]: 0.1143%\n",
      "[2]: 0.6857%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.6571%\n",
      "[5]: 0.6286%\n",
      "    77     0.339273   0.591685   0.720635  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.1857%\n",
      "[2]: 0.7143%\n",
      "[3]:  0.8%\n",
      "[4]: 0.5429%\n",
      "[5]: 0.4857%\n",
      "    78     0.349274   0.60106    0.739683  \n",
      "[0]: 0.1286%                                               \n",
      "[1]: 0.1429%\n",
      "[2]: 0.6571%\n",
      "[3]: 0.8857%\n",
      "[4]: 0.6143%\n",
      "[5]: 0.4857%\n",
      "    79     0.343936   0.651143   0.711111  \n",
      "\n",
      "CPU times: user 19min 25s, sys: 7min 39s, total: 27min 5s\n",
      "Wall time: 18min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.65114]), 0.711111108840458]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# at very little overfitting we have 43% accuracy\n",
    "%time learn.fit(1e-2, 8, wds=wd, cycle_len=10, use_clr=(20,8, 0.95, 0.85), best_save_name='Objective_A_Resnet_per_class_balanced_fromstart_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a861486e9b24d4da9cb2079c82d94b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=160), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: 0.1857%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]:  0.7%\n",
      "[5]: 0.7714%\n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.1267     0.421499   0.844444  \n",
      "[0]: 0.1857%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.6714%\n",
      "[5]: 0.7714%\n",
      "    1      0.125395   0.395248   0.853968  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3714%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.7714%\n",
      "    2      0.12648    0.346227   0.866667  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8571%\n",
      "    3      0.127998   0.342675   0.879365  \n",
      "[0]: 0.1571%                                               \n",
      "[1]:  0.3%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8571%\n",
      "    4      0.126569   0.341496   0.869841  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8857%\n",
      "    5      0.123608   0.361523   0.869841  \n",
      "[0]: 0.1857%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.6857%\n",
      "[5]:  0.8%\n",
      "    6      0.123444   0.338185   0.873016  \n",
      "[0]: 0.1429%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7571%\n",
      "[5]: 0.8286%\n",
      "    7      0.127369   0.329577   0.87619   \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3143%\n",
      "[3]:  1.0%\n",
      "[4]: 0.6857%\n",
      "[5]: 0.8857%\n",
      "    8      0.135883   0.334261   0.88254   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    9      0.127856   0.320487   0.88254   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.6857%\n",
      "[5]: 0.8571%\n",
      "    10     0.127057   0.335888   0.873016  \n",
      "[0]: 0.1714%                                               \n",
      "[1]:  0.3%\n",
      "[2]: 0.3429%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "    11     0.12791    0.302191   0.88254   \n",
      "[0]: 0.1714%                                               \n",
      "[1]:  0.3%\n",
      "[2]:  0.4%\n",
      "[3]: 0.9714%\n",
      "[4]:  0.7%\n",
      "[5]:  0.8%\n",
      "    12     0.130778   0.323      0.873016  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]:  0.8%\n",
      "    13     0.125107   0.314303   0.879365  \n",
      "[0]: 0.1429%                                               \n",
      "[1]:  0.3%\n",
      "[2]:  0.4%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]:  0.8%\n",
      "    14     0.121021   0.318992   0.88254   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3143%\n",
      "[2]:  0.4%\n",
      "[3]:  1.0%\n",
      "[4]:  0.7%\n",
      "[5]:  0.8%\n",
      "    15     0.115848   0.311741   0.88254   \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]:  0.7%\n",
      "[5]:  0.8%\n",
      "    16     0.11744    0.323778   0.87619   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8571%\n",
      "    17     0.120855   0.323186   0.87619   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "    18     0.116543   0.328578   0.873016  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "    19     0.113188   0.327212   0.873016  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8571%\n",
      "    20     0.109118   0.323845   0.879365  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]:  0.8%\n",
      "    21     0.107554   0.329247   0.873016  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3143%\n",
      "[2]:  0.2%\n",
      "[3]:  1.0%\n",
      "[4]:  0.7%\n",
      "[5]: 0.9429%\n",
      "    22     0.115575   0.348457   0.866667  \n",
      "[0]: 0.1571%                                               \n",
      "[1]:  0.3%\n",
      "[2]: 0.2857%\n",
      "[3]: 0.9714%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8857%\n",
      "    23     0.114151   0.316247   0.885714  \n",
      "[0]: 0.1429%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8571%\n",
      "    24     0.114171   0.312235   0.873016  \n",
      "[0]: 0.1429%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2571%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.9143%\n",
      "    25     0.110588   0.326267   0.88254   \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2857%\n",
      "[3]:  1.0%\n",
      "[4]: 0.6857%\n",
      "[5]: 0.8857%\n",
      "    26     0.113057   0.340501   0.885714  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3571%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]:  0.7%\n",
      "[5]:  0.8%\n",
      "    27     0.115692   0.352072   0.866667  \n",
      "[0]: 0.1429%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3143%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7714%\n",
      "[5]: 0.8571%\n",
      "    28     0.114117   0.315796   0.885714  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2857%\n",
      "[3]:  1.0%\n",
      "[4]: 0.6857%\n",
      "[5]: 0.9143%\n",
      "    29     0.115605   0.318623   0.888889  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8286%\n",
      "    30     0.115378   0.333728   0.87619   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "    31     0.110201   0.34084    0.87619   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]:  0.8%\n",
      "    32     0.11582    0.357031   0.853968  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8571%\n",
      "    33     0.113922   0.355638   0.866667  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8571%\n",
      "    34     0.116172   0.339793   0.88254   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2857%\n",
      "[3]:  1.0%\n",
      "[4]: 0.6857%\n",
      "[5]: 0.9143%\n",
      "    35     0.109856   0.351511   0.879365  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8857%\n",
      "    36     0.109779   0.347819   0.873016  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2857%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.9143%\n",
      "    37     0.108669   0.341489   0.87619   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8857%\n",
      "    38     0.11428    0.335397   0.873016  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2857%\n",
      "[3]:  1.0%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8857%\n",
      "    39     0.110775   0.343522   0.873016  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3429%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8571%\n",
      "    40     0.109967   0.343586   0.866667  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]:  0.7%\n",
      "[5]:  0.8%\n",
      "    41     0.109176   0.350638   0.860317  \n",
      "[0]: 0.1857%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.6857%\n",
      "[5]: 0.8571%\n",
      "    42     0.112185   0.353585   0.863492  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]:  0.8%\n",
      "    43     0.109627   0.327724   0.879365  \n",
      "[0]: 0.1429%                                               \n",
      "[1]: 0.3571%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7571%\n",
      "[5]: 0.9143%\n",
      "    44     0.113927   0.33954    0.885714  \n",
      "[0]: 0.1429%                                               \n",
      "[1]: 0.3714%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "    45     0.111264   0.341233   0.869841  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2857%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8857%\n",
      "    46     0.109738   0.32618    0.866667  \n",
      "[0]: 0.1429%                                               \n",
      "[1]: 0.3857%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    47     0.112259   0.316618   0.873016  \n",
      "[0]:  0.2%                                                 \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8286%\n",
      "    48     0.115348   0.356505   0.857143  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8286%\n",
      "    49     0.10684    0.352463   0.863492  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3429%\n",
      "[3]: 0.9714%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8571%\n",
      "    50     0.105028   0.343095   0.863492  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3714%\n",
      "[3]:  1.0%\n",
      "[4]: 0.6857%\n",
      "[5]: 0.8286%\n",
      "    51     0.104453   0.370951   0.857143  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    52     0.107864   0.352275   0.857143  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.9143%\n",
      "    53     0.10291    0.328985   0.885714  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3143%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8571%\n",
      "    54     0.103975   0.303352   0.892063  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8571%\n",
      "    55     0.10407    0.314067   0.88254   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    56     0.103268   0.328229   0.869841  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "    57     0.102879   0.337635   0.87619   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3143%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "    58     0.106276   0.328222   0.87619   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2857%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    59     0.110503   0.331769   0.879365  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3429%\n",
      "[3]: 0.9714%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8286%\n",
      "    60     0.108805   0.336662   0.87619   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "    61     0.109418   0.355195   0.860317  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3429%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    62     0.10721    0.322911   0.88254   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]:  0.2%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8857%\n",
      "    63     0.10827    0.358154   0.87619   \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2286%\n",
      "[3]:  1.0%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8286%\n",
      "    64     0.104855   0.350422   0.873016  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3857%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.6857%\n",
      "[5]: 0.8286%\n",
      "    65     0.105267   0.362842   0.860317  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.1714%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8286%\n",
      "    66     0.107028   0.344207   0.866667  \n",
      "[0]: 0.1857%                                               \n",
      "[1]: 0.3571%\n",
      "[2]: 0.1143%\n",
      "[3]:  1.0%\n",
      "[4]:  0.7%\n",
      "[5]: 0.9429%\n",
      "    67     0.105987   0.363164   0.869841  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "    68     0.106737   0.334458   0.879365  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3571%\n",
      "[2]: 0.2857%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8286%\n",
      "    69     0.103355   0.341011   0.860317  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3571%\n",
      "[2]: 0.3143%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    70     0.101234   0.351601   0.866667  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3143%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    71     0.10167    0.337145   0.869841  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2857%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8571%\n",
      "    72     0.10596    0.333192   0.879365  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3571%\n",
      "[2]: 0.3143%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    73     0.105916   0.323893   0.87619   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3571%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    74     0.105592   0.318319   0.88254   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3143%\n",
      "[2]: 0.2571%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8571%\n",
      "    75     0.100885   0.312507   0.885714  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2571%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "    76     0.099803   0.345015   0.866667  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3286%\n",
      "[2]:  0.2%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    77     0.100628   0.354571   0.853968  \n",
      "[0]: 0.1571%                                                \n",
      "[1]: 0.3429%\n",
      "[2]:  0.2%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    78     0.099635   0.342925   0.863492  \n",
      "[0]: 0.1571%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2571%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8286%\n",
      "    79     0.096933   0.337457   0.869841  \n",
      "[0]: 0.1571%                                                \n",
      "[1]: 0.3429%\n",
      "[2]:  0.2%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    80     0.097132   0.332828   0.873016  \n",
      "[0]: 0.1571%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2286%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8286%\n",
      "    81     0.094531   0.320486   0.879365  \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3143%\n",
      "[2]: 0.1429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8857%\n",
      "    82     0.100995   0.360093   0.853968  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2286%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "    83     0.103777   0.359042   0.838095  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3571%\n",
      "[2]: 0.1429%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.9429%\n",
      "    84     0.106929   0.320556   0.892063  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3571%\n",
      "[2]: 0.2857%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8286%\n",
      "    85     0.10834    0.323398   0.873016  \n",
      "[0]: 0.1429%                                               \n",
      "[1]: 0.3714%\n",
      "[2]:  0.2%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.6714%\n",
      "[5]: 0.8857%\n",
      "    86     0.109314   0.336093   0.866667  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2286%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    87     0.100809   0.331726   0.869841  \n",
      "[0]: 0.1571%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2286%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7571%\n",
      "[5]: 0.8286%\n",
      "    88     0.098186   0.340884   0.866667  \n",
      "[0]: 0.1571%                                                \n",
      "[1]: 0.3429%\n",
      "[2]:  0.2%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7571%\n",
      "[5]: 0.9429%\n",
      "    89     0.10113    0.327861   0.888889  \n",
      "[0]: 0.1571%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2857%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8571%\n",
      "    90     0.103006   0.327536   0.88254   \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3714%\n",
      "[2]: 0.2286%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7714%\n",
      "[5]: 0.8286%\n",
      "    91     0.104023   0.317797   0.88254   \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "    92     0.104873   0.337792   0.866667  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3571%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    93     0.098069   0.337873   0.873016  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3571%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "    94     0.103965   0.345014   0.869841  \n",
      "[0]: 0.1571%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7571%\n",
      "[5]: 0.8571%\n",
      "    95     0.104336   0.350574   0.860317  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3571%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8286%\n",
      "    96     0.110053   0.330939   0.873016  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3571%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    97     0.107702   0.32853    0.87619   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "    98     0.102074   0.323798   0.873016  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2286%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8571%\n",
      "    99     0.099644   0.320497   0.873016  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8286%\n",
      "   100     0.098191   0.31051    0.88254   \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3286%\n",
      "[2]:  0.2%\n",
      "[3]:  1.0%\n",
      "[4]: 0.6857%\n",
      "[5]: 0.9143%\n",
      "   101     0.103095   0.364226   0.873016  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3143%\n",
      "[2]: 0.2857%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "   102     0.097602   0.341312   0.863492  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3714%\n",
      "[3]:  1.0%\n",
      "[4]: 0.6857%\n",
      "[5]: 0.8286%\n",
      "   103     0.095864   0.374177   0.860317  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3143%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "   104     0.097038   0.356509   0.869841  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3571%\n",
      "[2]: 0.2571%\n",
      "[3]: 0.9714%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8286%\n",
      "   105     0.10056    0.356781   0.860317  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3143%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8571%\n",
      "   106     0.101866   0.34151    0.857143  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3714%\n",
      "[2]:  0.4%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8571%\n",
      "   107     0.098923   0.312496   0.885714  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]:  1.0%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8286%\n",
      "   108     0.098562   0.351428   0.869841  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2286%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8571%\n",
      "   109     0.105756   0.33152    0.87619   \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3571%\n",
      "[2]: 0.2571%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7571%\n",
      "[5]: 0.8571%\n",
      "   110     0.098913   0.300819   0.895238  \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8571%\n",
      "   111     0.099199   0.32526    0.87619   \n",
      "[0]:  0.2%                                                  \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2571%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8571%\n",
      "   112     0.097311   0.338837   0.873016  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2571%\n",
      "[3]: 0.9714%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8571%\n",
      "   113     0.098991   0.34651    0.873016  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3143%\n",
      "[2]: 0.3429%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8571%\n",
      "   114     0.0975     0.355847   0.84127   \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3429%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8571%\n",
      "   115     0.097303   0.342667   0.866667  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3429%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8571%\n",
      "   116     0.101662   0.332413   0.879365  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3429%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8571%\n",
      "   117     0.104265   0.331976   0.87619   \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3143%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8571%\n",
      "   118     0.102325   0.342318   0.87619   \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2857%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8571%\n",
      "   119     0.097563   0.34302    0.873016  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.3714%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7571%\n",
      "[5]: 0.8571%\n",
      "   120     0.099732   0.334793   0.873016  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8286%\n",
      "   121     0.099551   0.336594   0.873016  \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2857%\n",
      "[3]: 0.9714%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8571%\n",
      "   122     0.097892   0.331474   0.869841  \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2286%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.6857%\n",
      "[5]: 0.9143%\n",
      "   123     0.096395   0.331126   0.879365  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.3143%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8571%\n",
      "   124     0.094934   0.313589   0.885714  \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3143%\n",
      "[2]:  0.2%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7571%\n",
      "[5]: 0.9429%\n",
      "   125     0.101811   0.334271   0.87619   \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3143%\n",
      "[2]: 0.2286%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8571%\n",
      "   126     0.099813   0.329762   0.87619   \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3143%\n",
      "[2]:  0.2%\n",
      "[3]:  1.0%\n",
      "[4]:  0.8%\n",
      "[5]: 0.8857%\n",
      "   127     0.096956   0.329291   0.873016  \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.1714%\n",
      "[3]:  1.0%\n",
      "[4]:  0.7%\n",
      "[5]: 0.9429%\n",
      "   128     0.099141   0.36494    0.866667  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3143%\n",
      "[2]: 0.2286%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8571%\n",
      "   129     0.09738    0.345091   0.860317  \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2286%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "   130     0.097671   0.346443   0.863492  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2286%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "   131     0.105662   0.333623   0.869841  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3571%\n",
      "[2]: 0.2857%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8571%\n",
      "   132     0.098808   0.346944   0.879365  \n",
      "[0]:  0.2%                                                 \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8571%\n",
      "   133     0.103542   0.33127    0.87619   \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3143%\n",
      "[2]: 0.2571%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "   134     0.11189    0.327425   0.873016  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3286%\n",
      "[2]:  0.2%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8857%\n",
      "   135     0.109602   0.329189   0.879365  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "   136     0.108014   0.340958   0.869841  \n",
      "[0]: 0.1714%                                               \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "   137     0.10332    0.34791    0.869841  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "   138     0.101845   0.340488   0.87619   \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8286%\n",
      "   139     0.09962    0.339254   0.873016  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2286%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8571%\n",
      "   140     0.098388   0.348859   0.866667  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2286%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8286%\n",
      "   141     0.097353   0.357896   0.860317  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3143%\n",
      "[2]:  0.2%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.9143%\n",
      "   142     0.091954   0.377063   0.857143  \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2286%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8286%\n",
      "   143     0.095731   0.333639   0.87619   \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3143%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8286%\n",
      "   144     0.095096   0.345276   0.873016  \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8286%\n",
      "   145     0.096001   0.330592   0.87619   \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8286%\n",
      "   146     0.101511   0.333254   0.87619   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3143%\n",
      "[2]: 0.2571%\n",
      "[3]:  1.0%\n",
      "[4]: 0.6857%\n",
      "[5]: 0.8286%\n",
      "   147     0.096628   0.368414   0.853968  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2571%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7143%\n",
      "[5]: 0.8571%\n",
      "   148     0.091768   0.32927    0.879365  \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3143%\n",
      "[2]: 0.2286%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7571%\n",
      "[5]: 0.8571%\n",
      "   149     0.088262   0.336212   0.860317  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.1429%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.9143%\n",
      "   150     0.090358   0.357641   0.860317  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3143%\n",
      "[2]: 0.2286%\n",
      "[3]:  1.0%\n",
      "[4]: 0.7857%\n",
      "[5]: 0.8286%\n",
      "   151     0.090551   0.338561   0.857143  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3286%\n",
      "[2]:  0.2%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8571%\n",
      "   152     0.089507   0.329528   0.873016  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3286%\n",
      "[2]: 0.2286%\n",
      "[3]: 0.9714%\n",
      "[4]:  0.7%\n",
      "[5]: 0.8571%\n",
      "   153     0.094313   0.328857   0.869841  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2286%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7714%\n",
      "[5]: 0.8571%\n",
      "   154     0.091311   0.302682   0.885714  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3286%\n",
      "[2]:  0.2%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8571%\n",
      "   155     0.097419   0.32919    0.863492  \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3286%\n",
      "[2]:  0.2%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7286%\n",
      "[5]: 0.8571%\n",
      "   156     0.098201   0.33768    0.863492  \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3429%\n",
      "[2]: 0.2571%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7429%\n",
      "[5]: 0.8571%\n",
      "   157     0.100136   0.321367   0.88254   \n",
      "[0]: 0.1857%                                                \n",
      "[1]: 0.3143%\n",
      "[2]: 0.2571%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7714%\n",
      "[5]: 0.8571%\n",
      "   158     0.095019   0.306278   0.888889  \n",
      "[0]: 0.1714%                                                \n",
      "[1]: 0.3143%\n",
      "[2]: 0.2286%\n",
      "[3]: 0.9714%\n",
      "[4]: 0.7714%\n",
      "[5]: 0.8571%\n",
      "   159     0.090951   0.308671   0.87619   \n",
      "\n",
      "CPU times: user 36min 20s, sys: 14min 45s, total: 51min 5s\n",
      "Wall time: 34min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.30867]), 0.8761904799748981]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-3, 8, wds=wd, cycle_len=20, use_clr=(20,8, 0.95, 0.85), best_save_name='Objective_A_Resnet_per_class_balanced_fromstart_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('Objective_A_Resnet_per_class_balanced_fromstart_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4a0cdf71884e838b34959157c2d235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: 0.08571%                                              \n",
      "[1]: 0.1286%\n",
      "[2]: 0.6857%\n",
      "[3]: 0.9143%\n",
      "[4]: 0.5714%\n",
      "[5]: 0.6857%\n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.359634   0.552267   0.75873   \n",
      "\n",
      "CPU times: user 13.8 s, sys: 5.61 s, total: 19.4 s\n",
      "Wall time: 12.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.55227]), 0.7587301547565157]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-3, 1, wds=wd, cycle_len=1, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62  3  0  0  5  0]                         \n",
      " [13 43  0  0 14  0]\n",
      " [ 0  0 35  0  0  0]\n",
      " [ 0  0  0 35  0  0]\n",
      " [ 6 20  0  0 44  0]\n",
      " [ 0  0  4  7  0 24]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# analyze results \n",
    "log_preds, y = learn.TTA(n_aug=1)\n",
    "log_preds_mean = np.mean(log_preds, axis=0)\n",
    "preds = np.argmax(log_preds_mean, axis=1)\n",
    "# cm = confusion_matrix(preds,y)\n",
    "cm = confusion_matrix(y, preds)\n",
    "plot_confusion_matrix(cm, data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
