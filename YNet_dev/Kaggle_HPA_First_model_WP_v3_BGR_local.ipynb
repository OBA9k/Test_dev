{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import skimage.external.tifffile as tiff\n",
    "\n",
    "from common import Statistics, dataset_source\n",
    "from resources.conv_learner import *\n",
    "from resources.plots import *\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"datasets/Kaggle_HPA_2018/\"\n",
    "data_path = Path(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 28\n",
    "bs = 64\n",
    "sz = [3,224,224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up a list of a random 20% of images in train as the validation set\n",
    "\n",
    "lbl_csv = PATH + 'HPA_labels.csv'\n",
    "n = len(list(open(lbl_csv))) -1\n",
    "val_idxs = get_cv_idxs(n, val_pct=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, lbl_csv, val_idxs, sz, bs, aug_tfms):\n",
    "\n",
    "    tfms = tfms_with_IntNorm(sz, aug_tfms=aug_tfms, crop_type=CropType.CENTER)\n",
    "    data = ImageClassifierData.from_csv(PATH, 'full_train_BGR', lbl_csv, val_idxs = val_idxs, test_name='full_test_BGR', tfms=tfms, bs=bs, suffix = '.tiff', \n",
    "                                        balance=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define augmentations\n",
    "augs = [RandomDihedral()]\n",
    "\n",
    "# initialize data object\n",
    "data = get_data(PATH, lbl_csv, val_idxs, sz, bs, aug_tfms = augs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inpsect data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(data.test_dl))\n",
    "# x_test, y_test = next(iter(data.test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       "[torch.cuda.LongTensor of size 10 (GPU 0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading epochs to inspect class-balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_epoch(dl = data.trn_dl):\n",
    "    \n",
    "    batch = iter(dl)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "#     for b in range(0,len(dl)):\n",
    "    for b in range(0,10):\n",
    "\n",
    "        x_, y_ = next(batch)\n",
    "        x_np, y_np = to_np(x_), to_np(y_)\n",
    "        xs.append(x_np)\n",
    "        ys.append(y_np)\n",
    "\n",
    "    return np.vstack(xs), np.concatenate(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = load_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# analyze results\n",
    "lbl_dist = ys.sum(axis=0)\n",
    "print(lbl_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights calculation WIP\n",
    "\n",
    "ys = data.trn_ds.y\n",
    "\n",
    "cut = 1/len(data.classes)\n",
    "perc = (ys.sum(axis=0) / ys.sum())\n",
    "\n",
    "weights_per_label = [cut / perc[i] for i in range(len(data.classes))]\n",
    "w_matrix = [ys[i] * weights_per_label for i in range(len(ys))]\n",
    "\n",
    "min_weights_per_im = [np.min(w_matrix[i][np.nonzero(w_matrix[i])]) for i in range(len(ys))]\n",
    "weights_per_im = [np.max(w_matrix[i]) for i in range(len(ys))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_weights_per_im[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inpsecting loaded images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_label(y):\n",
    "    ind = [i for i, p in enumerate(y) if y[i]==1]\n",
    "    return(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspect train images\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "idx = 2\n",
    "\n",
    "im = to_np(x)[idx]\n",
    "\n",
    "lbl = to_label(to_np(y)[idx])\n",
    "print(lbl)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(16,10))\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    ax.imshow(im[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspect test images\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "idx = 3\n",
    "\n",
    "im = to_np(x_test)[idx]\n",
    "\n",
    "# lbl = to_label(to_np(y)[idx])\n",
    "# print(lbl)\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize=(16,10))\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    ax.imshow(im[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base-model\n",
    "\n",
    "arch = resnet18\n",
    "# arch = resnet50\n",
    "learn = ConvLearner.pretrained(arch, data, ps=0, opt_fn=optim.Adam, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional parameters\n",
    "\n",
    "wd=1e-5 # weight-decay/L2 regularization \n",
    "learn.metrics = [accuracy_thresh(0.5),f1_macro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time learn.fit(5e-3, 1, cycle_len=1, wds=wd, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = (5e-4, 1e-3, 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time learn.fit(lr, 2, cycle_len=8, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(lr, 1, cycle_len=8, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('ResNet18_pre_64_10perVal_v1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('ResNet18_pre_64_10perVal_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.predict_with_targs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test-predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y =  learn.TTA(is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_th(preds, targs, start=0.2, end=0.6, step=0.05):\n",
    "    ths = np.arange(start,end,step)\n",
    "    res = [f1_macro(preds, targs, thresh=th, kind='macro') for th in ths]\n",
    "    idx = np.argmax(res)\n",
    "    return ths[idx], res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train predictions\n",
    "\n",
    "preds_trn, targs_trn =  learn.predict_with_targs('trn')\n",
    "\n",
    "preds_trn_torch = torch.from_numpy(preds_trn)\n",
    "targs_trn_torch = torch.from_numpy(targs_trn)\n",
    "\n",
    "opt_th(preds_trn_torch, targs_trn_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds_val_torch[0])\n",
    "print(preds_trn_torch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get val predictions\n",
    "\n",
    "preds_val, targs_val =  learn.predict_with_targs('val')\n",
    "\n",
    "preds_val_torch = torch.from_numpy(preds_val)\n",
    "targs_val_torch = torch.from_numpy(targs_val)\n",
    "\n",
    "opt_th(preds_val_torch, targs_val_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test predictions\n",
    "\n",
    "preds_test, targs_test =  learn.predict_with_targs('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
       "       25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targs_test[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_epoch(dl = data.trn_dl):\n",
    "    \n",
    "    batch = iter(dl)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "#     for b in range(0,len(dl)):\n",
    "    for b in range(0,10):\n",
    "\n",
    "        x_, y_ = next(batch)\n",
    "        x_np, y_np = to_np(x_), to_np(y_)\n",
    "        xs.append(x_np)\n",
    "        ys.append(y_np)\n",
    "\n",
    "    return np.vstack(xs), np.concatenate(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_dl.sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = data.test_ds.fnames\n",
    "test_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(preds_file, output_name, th = 0.3, TTA=False):\n",
    "    \n",
    "    # creating submission file\n",
    "    \n",
    "    if TTA:\n",
    "        preds = preds_file.mean(axis=0)\n",
    "        print('TTA:',preds.shape)\n",
    "    else: preds = preds_file\n",
    "    \n",
    "    clss = np.arange(0, len(data.classes)) # get class indeces\n",
    "    res = np.array([' '.join(np.char.mod('%d', clss[np.where(p > th)])) for p in preds]) # generating output\n",
    "\n",
    "    # ensure that there are no empty cells: in case no value > thresh, fill in with argmax()\n",
    "    for i in range(res.shape[0]):\n",
    "        if res[i] == '':\n",
    "            res[i] = preds[i].argmax()\n",
    "\n",
    "    # getting image Ids\n",
    "    fnames = np.array([os.path.basename(im).split('.')[0] for im in data.test_ds.fnames])\n",
    "\n",
    "    # creating submission file\n",
    "    sub_df = pd.DataFrame(res, index=fnames, columns=['Predicted'])\n",
    "    sub_df.to_csv(output_name, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = PATH + 'submissions/Res18_pre_0.42_t-03.csv'\n",
    "\n",
    "create_submission(log_preds, submission_name, th=0.3, TTA=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of label identities:\n",
    "\n",
    "cell_location_label = {\n",
    "0:  'Nucleoplasm',\n",
    "1:  'Nuclear membrane',\n",
    "2:  'Nucleoli',   \n",
    "3:  'Nucleoli fibrillar center',\n",
    "4:  'Nuclear speckles',\n",
    "5:  'Nuclear bodies',\n",
    "6:  'Endoplasmic reticulum',   \n",
    "7:  'Golgi apparatus',\n",
    "8:  'Peroxisomes',\n",
    "9:  'Endosomes',\n",
    "10:  'Lysosomes',\n",
    "11:  'Intermediate filaments',\n",
    "12:  'Actin filaments',\n",
    "13:  'Focal adhesion sites',   \n",
    "14:  'Microtubules',\n",
    "15:  'Microtubule ends',  \n",
    "16:  'Cytokinetic bridge',   \n",
    "17:  'Mitotic spindle',\n",
    "18:  'Microtubule organizing center',  \n",
    "19:  'Centrosome',\n",
    "20:  'Lipid droplets',\n",
    "21:  'Plasma membrane',   \n",
    "22:  'Cell junctions', \n",
    "23:  'Mitochondria',\n",
    "24:  'Aggresome',\n",
    "25:  'Cytosol',\n",
    "26:  'Cytoplasmic bodies',   \n",
    "27:  'Rods & rings' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# thresholds = np.linspace(0, 1, 1000)\n",
    "# score = 0.0\n",
    "# test_threshold=0.5*np.ones(28)\n",
    "# best_threshold=np.zeros(28)\n",
    "# best_val = np.zeros(28)\n",
    "# for i in range(28):\n",
    "#     for threshold in thresholds:\n",
    "#         test_threshold[i] = threshold\n",
    "#         max_val = np.max(preds_y)\n",
    "#         val_predict = (preds_y > test_threshold)\n",
    "#         score = f1_score(valid_y > 0.5, val_predict, average='macro')\n",
    "#         if score > best_val[i]:\n",
    "#             best_threshold[i] = threshold\n",
    "#             best_val[i] = score\n",
    "#     print(\"Threshold[%d] %0.6f, F1: %0.6f\" % (i,best_threshold[i],best_val[i]))\n",
    "#     test_threshold[i] = best_threshold[i]\n",
    "# print(\"Best threshold: \")\n",
    "# print(best_threshold)\n",
    "# print(\"Best f1:\")\n",
    "# print(best_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
