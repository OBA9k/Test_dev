{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import skimage.external.tifffile as tiff\n",
    "\n",
    "from common import Statistics, dataset_source\n",
    "from resources.conv_learner import *\n",
    "from resources.plots import *\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"datasets/Kaggle_HPA_2018/\"\n",
    "data_path = Path(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 28\n",
    "bs = 64\n",
    "sz = [3,224,224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up a list of a random 20% of images in train as the validation set\n",
    "\n",
    "lbl_csv = PATH + 'HPA_labels.csv'\n",
    "n = len(list(open(lbl_csv))) -1\n",
    "val_idxs = get_cv_idxs(n, val_pct=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, lbl_csv, val_idxs, sz, bs, aug_tfms):\n",
    "\n",
    "    tfms = tfms_with_IntNorm(sz, aug_tfms=aug_tfms, crop_type=CropType.CENTER)\n",
    "    data = ImageClassifierData.from_csv(PATH, 'full_train_BGR', lbl_csv, val_idxs = val_idxs, test_name='full_test_BGR', tfms=tfms, bs=bs, suffix = '.tiff', \n",
    "                                        balance=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted\n"
     ]
    }
   ],
   "source": [
    "# define augmentations\n",
    "augs = [RandomDihedral()]\n",
    "\n",
    "# initialize data object\n",
    "data = get_data(PATH, lbl_csv, val_idxs, sz, bs, aug_tfms = augs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inpsect data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(data.trn_dl))\n",
    "# x_test, y_test = next(iter(data.test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading epochs to inspect class-balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_epoch(dl = data.trn_dl):\n",
    "    \n",
    "    batch = iter(dl)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "#     for b in range(0,len(dl)):\n",
    "    for b in range(0,10):\n",
    "\n",
    "        x_, y_ = next(batch)\n",
    "        x_np, y_np = to_np(x_), to_np(y_)\n",
    "        xs.append(x_np)\n",
    "        ys.append(y_np)\n",
    "\n",
    "    return np.vstack(xs), np.concatenate(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = load_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# analyze results\n",
    "lbl_dist = ys.sum(axis=0)\n",
    "print(lbl_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights calculation WIP\n",
    "\n",
    "ys = data.trn_ds.y\n",
    "\n",
    "cut = 1/len(data.classes)\n",
    "perc = (ys.sum(axis=0) / ys.sum())\n",
    "\n",
    "weights_per_label = [cut / perc[i] for i in range(len(data.classes))]\n",
    "w_matrix = [ys[i] * weights_per_label for i in range(len(ys))]\n",
    "\n",
    "min_weights_per_im = [np.min(w_matrix[i][np.nonzero(w_matrix[i])]) for i in range(len(ys))]\n",
    "weights_per_im = [np.max(w_matrix[i]) for i in range(len(ys))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_weights_per_im[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inpsecting loaded images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_label(y):\n",
    "    ind = [i for i, p in enumerate(y) if y[i]==1]\n",
    "    return(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspect train images\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "idx = 2\n",
    "\n",
    "im = to_np(x)[idx]\n",
    "\n",
    "lbl = to_label(to_np(y)[idx])\n",
    "print(lbl)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(16,10))\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    ax.imshow(im[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspect test images\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "idx = 3\n",
    "\n",
    "im = to_np(x_test)[idx]\n",
    "\n",
    "# lbl = to_label(to_np(y)[idx])\n",
    "# print(lbl)\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize=(16,10))\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    ax.imshow(im[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base-model\n",
    "\n",
    "arch = resnet18\n",
    "# arch = resnet50\n",
    "learn = ConvLearner.pretrained(arch, data, ps=0, opt_fn=optim.Adam, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional parameters\n",
    "\n",
    "wd=1e-5 # weight-decay/L2 regularization \n",
    "learn.metrics = [accuracy_thresh(0.5),f1_macro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time learn.fit(5e-3, 1, cycle_len=1, wds=wd, use_wd_sched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = (5e-4, 1e-3, 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4bb3de11bc454f89d2337a7d5a5d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 0                                                                                                                                                                                      \n",
      "epoch      trn_loss   val_loss   <lambda>   f1_macro   \n",
      "    0      0.137455   0.1615     0.946871   0.127783  \n",
      "EPOCH 1 ---------------------------------------- STEP 1                                                                                                                                                                                      \n",
      "    1      0.10834    0.157976   0.949055   0.22694   \n",
      "EPOCH 2 ---------------------------------------- STEP 2                                                                                                                                                                                      \n",
      "    2      0.092836   0.134314   0.952389   0.255329  \n",
      "EPOCH 3 ---------------------------------------- STEP 3                                                                                                                                                                                      \n",
      "    3      0.082321   0.141466   0.951481   0.258425  \n",
      "EPOCH 4 ---------------------------------------- STEP 4                                                                                                                                                                                      \n",
      "    4      0.072746   0.125641   0.954814   0.334492  \n",
      "EPOCH 5 ---------------------------------------- STEP 5                                                                                                                                                                                      \n",
      "    5      0.062246   0.112804   0.960343   0.376379  \n",
      "EPOCH 6 ---------------------------------------- STEP 6                                                                                                                                                                                      \n",
      "    6      0.05181    0.10799    0.961584   0.39562   \n",
      "EPOCH 7 ---------------------------------------- STEP 7                                                                                                                                                                                      \n",
      "    7      0.046948   0.098681   0.96524    0.419082  \n",
      "EPOCH 8 ---------------------------------------- STEP 8                                                                                                                                                                                      \n",
      "    8      0.084267   0.214268   0.931411   0.199958  \n",
      "EPOCH 9 ---------------------------------------- STEP 9                                                                                                                                                                                      \n",
      "    9      0.072383   0.126632   0.955826   0.32678   \n",
      "EPOCH 10 ---------------------------------------- STEP 10                                                                                                                                                                                    \n",
      "    10     0.064389   0.121733   0.95663    0.353032  \n",
      "EPOCH 11 ---------------------------------------- STEP 11                                                                                                                                                                                    \n",
      "    11     0.055021   0.118892   0.959814   0.364588  \n",
      "EPOCH 12 ---------------------------------------- STEP 12                                                                                                                                                                                    \n",
      "    12     0.047669   0.111297   0.961458   0.406757  \n",
      "EPOCH 13 ---------------------------------------- STEP 13                                                                                                                                                                                    \n",
      "    13     0.041229   0.102956   0.965217   0.420061  \n",
      "EPOCH 14 ---------------------------------------- STEP 14                                                                                                                                                                                    \n",
      "    14     0.034804   0.099648   0.965929   0.425329  \n",
      "EPOCH 15 ---------------------------------------- STEP 15                                                                                                                                                                                    \n",
      "    15     0.030369   0.097729   0.967504   0.437129  \n",
      "\n",
      "Wall time: 1h 50min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.09773]), 0.9675042538501689, 0.4371290804418025]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lr, 2, cycle_len=8, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time learn.fit(lr, 1, cycle_len=8, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('ResNet18_pre_64_10perVal_v1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('ResNet18_pre_64_10perVal_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.predict_with_targs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test-predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                             \r"
     ]
    }
   ],
   "source": [
    "log_preds, y =  learn.TTA(is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_th(preds, targs, start=0.2, end=0.6, step=0.05):\n",
    "    ths = np.arange(start,end,step)\n",
    "    res = [f1_macro(preds, targs, thresh=th, kind='macro') for th in ths]\n",
    "    idx = np.argmax(res)\n",
    "    return ths[idx], res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.39999999999999997,\n",
       " [0.92619235324298,\n",
       "  0.9328112334721564,\n",
       "  0.9371767136037829,\n",
       "  0.939984370193041,\n",
       "  0.9413976617363594,\n",
       "  0.9413670204891537,\n",
       "  0.9408816526273823,\n",
       "  0.9393772059857021])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get train predictions\n",
    "\n",
    "preds_trn, targs_trn =  learn.predict_with_targs('trn')\n",
    "\n",
    "preds_trn_torch = torch.from_numpy(preds_trn)\n",
    "targs_trn_torch = torch.from_numpy(targs_trn)\n",
    "\n",
    "opt_th(preds_trn_torch, targs_trn_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds_val_torch[0])\n",
    "print(preds_trn_torch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3,\n",
       " [0.5891571227741271,\n",
       "  0.5968790636677838,\n",
       "  0.6024754308320616,\n",
       "  0.6010317740546677,\n",
       "  0.5988708536620362,\n",
       "  0.5940680327869428,\n",
       "  0.5936215038296789,\n",
       "  0.591517903171673])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get val predictions\n",
    "\n",
    "preds_val, targs_val =  learn.predict_with_targs('val')\n",
    "\n",
    "preds_val_torch = torch.from_numpy(preds_val)\n",
    "targs_val_torch = torch.from_numpy(targs_val)\n",
    "\n",
    "opt_th(preds_val_torch, targs_val_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test predictions\n",
    "\n",
    "preds_test, targs_test =  learn.predict_with_targs('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_epoch(dl = data.trn_dl):\n",
    "    \n",
    "    batch = iter(dl)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "#     for b in range(0,len(dl)):\n",
    "    for b in range(0,10):\n",
    "\n",
    "        x_, y_ = next(batch)\n",
    "        x_np, y_np = to_np(x_), to_np(y_)\n",
    "        xs.append(x_np)\n",
    "        ys.append(y_np)\n",
    "\n",
    "    return np.vstack(xs), np.concatenate(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.SequentialSampler at 0x227ceb6cb70>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.test_dl.sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['full_test_BGR\\\\00008af0-bad0-11e8-b2b8-ac1f6b6435d0.tiff',\n",
       "       'full_test_BGR\\\\0000a892-bacf-11e8-b2b8-ac1f6b6435d0.tiff',\n",
       "       'full_test_BGR\\\\0006faa6-bac7-11e8-b2b7-ac1f6b6435d0.tiff',\n",
       "       'full_test_BGR\\\\0008baca-bad7-11e8-b2b9-ac1f6b6435d0.tiff',\n",
       "       'full_test_BGR\\\\000cce7e-bad4-11e8-b2b8-ac1f6b6435d0.tiff',\n",
       "       'full_test_BGR\\\\00109f6a-bac8-11e8-b2b7-ac1f6b6435d0.tiff',\n",
       "       'full_test_BGR\\\\001765de-bacd-11e8-b2b8-ac1f6b6435d0.tiff',\n",
       "       'full_test_BGR\\\\0018641a-bac9-11e8-b2b8-ac1f6b6435d0.tiff',\n",
       "       'full_test_BGR\\\\00200f22-bad7-11e8-b2b9-ac1f6b6435d0.tiff',\n",
       "       'full_test_BGR\\\\0026f154-bac6-11e8-b2b7-ac1f6b6435d0.tiff'], dtype='<U55')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_names = data.test_ds.fnames\n",
    "np.array(test_names)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_im_ids = {fname: idx for idx, fname in enumerate(test_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11702, 1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(test_im_ids.values()))[:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(preds_file, output_name, th = 0.3, TTA=False):\n",
    "    \n",
    "    # creating submission file\n",
    "    \n",
    "    if TTA:\n",
    "        preds = preds_file.mean(axis=0)\n",
    "        print('TTA:',preds.shape)\n",
    "    else: preds = preds_file\n",
    "    \n",
    "    clss = np.arange(0, len(data.classes)) # get class indeces\n",
    "    res = np.array([' '.join(np.char.mod('%d', clss[np.where(p > th)])) for p in preds]) # generating output\n",
    "\n",
    "    # ensure that there are no empty cells: in case no value > thresh, fill in with argmax()\n",
    "    for i in range(res.shape[0]):\n",
    "        if res[i] == '':\n",
    "            res[i] = preds[i].argmax()\n",
    "\n",
    "    # getting image Ids\n",
    "    fnames = np.array([os.path.basename(im).split('.')[0] for im in data.test_ds.fnames])\n",
    "\n",
    "    # creating submission file\n",
    "    sub_df = pd.DataFrame(res, index=fnames, columns=['Predicted'])\n",
    "    sub_df.to_csv(output_name, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA: (11702, 28)\n"
     ]
    }
   ],
   "source": [
    "submission_name = PATH + 'submissions/Res18_pre_0.42_t-03.csv'\n",
    "\n",
    "create_submission(log_preds, submission_name, th=0.3, TTA=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of label identities:\n",
    "\n",
    "cell_location_label = {\n",
    "0:  'Nucleoplasm',\n",
    "1:  'Nuclear membrane',\n",
    "2:  'Nucleoli',   \n",
    "3:  'Nucleoli fibrillar center',\n",
    "4:  'Nuclear speckles',\n",
    "5:  'Nuclear bodies',\n",
    "6:  'Endoplasmic reticulum',   \n",
    "7:  'Golgi apparatus',\n",
    "8:  'Peroxisomes',\n",
    "9:  'Endosomes',\n",
    "10:  'Lysosomes',\n",
    "11:  'Intermediate filaments',\n",
    "12:  'Actin filaments',\n",
    "13:  'Focal adhesion sites',   \n",
    "14:  'Microtubules',\n",
    "15:  'Microtubule ends',  \n",
    "16:  'Cytokinetic bridge',   \n",
    "17:  'Mitotic spindle',\n",
    "18:  'Microtubule organizing center',  \n",
    "19:  'Centrosome',\n",
    "20:  'Lipid droplets',\n",
    "21:  'Plasma membrane',   \n",
    "22:  'Cell junctions', \n",
    "23:  'Mitochondria',\n",
    "24:  'Aggresome',\n",
    "25:  'Cytosol',\n",
    "26:  'Cytoplasmic bodies',   \n",
    "27:  'Rods & rings' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# thresholds = np.linspace(0, 1, 1000)\n",
    "# score = 0.0\n",
    "# test_threshold=0.5*np.ones(28)\n",
    "# best_threshold=np.zeros(28)\n",
    "# best_val = np.zeros(28)\n",
    "# for i in range(28):\n",
    "#     for threshold in thresholds:\n",
    "#         test_threshold[i] = threshold\n",
    "#         max_val = np.max(preds_y)\n",
    "#         val_predict = (preds_y > test_threshold)\n",
    "#         score = f1_score(valid_y > 0.5, val_predict, average='macro')\n",
    "#         if score > best_val[i]:\n",
    "#             best_threshold[i] = threshold\n",
    "#             best_val[i] = score\n",
    "#     print(\"Threshold[%d] %0.6f, F1: %0.6f\" % (i,best_threshold[i],best_val[i]))\n",
    "#     test_threshold[i] = best_threshold[i]\n",
    "# print(\"Best threshold: \")\n",
    "# print(best_threshold)\n",
    "# print(\"Best f1:\")\n",
    "# print(best_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
