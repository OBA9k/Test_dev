{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import skimage.external.tifffile as tiff\n",
    "\n",
    "from common import Statistics, dataset_source\n",
    "from resources.conv_learner import *\n",
    "from resources.plots import *\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"datasets/HPA_challenge_2018/Hirano3D/\"\n",
    "# data_path = Path(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV generation via sklearn, Multilabel implementation by trent-b, or FastAi\n",
    "\n",
    "Both libraries seem to be completely useless... can just use native fastai function: get_cv_idxs().<br>\n",
    "However, get_cv_idxs() does NOT shuffle...!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def get_label_stratified_CV_idxs(csv_path):\n",
    "    \n",
    "    _all_labels = pd.read_csv(csv_path)\n",
    "    arr = _all_labels.values\n",
    "\n",
    "    X = arr[:,0]\n",
    "    y = arr[:,1:]\n",
    "    \n",
    "    ### sklearn.model_selection.StratifiedKFold\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "    \n",
    "    for train_index, val_index in sss.split(X, y):\n",
    "        trn_idxs = train_index\n",
    "        val_idxs = val_index\n",
    "    \n",
    "    print(f\"\"\"Train label-distribution:\\n\"\"\"\n",
    "          f\"\"\"{pd.Series(arr[:,1][trn_idxs]).value_counts()}\"\"\")\n",
    "    print(f\"\"\"Val label-distribution:\\n\"\"\"\n",
    "          f\"\"\"{pd.Series(arr[:,1][val_idxs]).value_counts()}\"\"\")\n",
    "    \n",
    "    return trn_idxs, val_idxs\n",
    "\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "def get_label_stratified_CV_idxs_multi(csv_path):\n",
    "    \n",
    "    # FastAi csv_source expects a folder-name string to be passed as first arg... -> 'dummy'\n",
    "    X, y, all_lbls = csv_source('dummy', csv_path)\n",
    "    \n",
    "    ### Iterative stratification library: https://github.com/trent-b/iterative-stratification\n",
    "    msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "    \n",
    "    for train_index, val_index in msss.split(X, y):\n",
    "        trn_idxs = train_index\n",
    "        val_idxs = val_index\n",
    "    \n",
    "    trn_count = np.sum(y[trn_idxs], axis=0)\n",
    "    val_count = np.sum(y[val_idxs], axis=0)\n",
    "    \n",
    "    print(f\"\"\"Train label-distribution:\\n\"\"\"\n",
    "          f\"\"\"{trn_count}\"\"\")\n",
    "    print(f\"\"\"Val label-distribution:\\n\"\"\"\n",
    "          f\"\"\"{val_count}\"\"\")\n",
    "    \n",
    "    return trn_idxs, val_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# idxs_dict = {'trn_idxs': trn_idxs, 'val_idxs': val_idxs}\n",
    "\n",
    "# with open('datasets/HPA_challenge_2018/tmp/dn121_AWS_1_cont_idxs.pkl', 'wb') as handle:\n",
    "#     pickle.dump(idxs_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('datasets/HPA_challenge_2018/Hirano3D/Hirano3D_AWS_idxs.pkl', 'rb') as handle:\n",
    "    idxs_dict_load = pickle.load(handle)\n",
    "    \n",
    "val_idxs_loaded = idxs_dict_load['val_idxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setting up a list of a random 20% of images in train as the validation set\n",
    "\n",
    "# lbl_csv = path + 'Kaggle_AND_HPAv18_60x_NoDefDupes_labels.csv'\n",
    "# n = len(list(open(lbl_csv))) -1\n",
    "# val_idxs = get_cv_idxs(n, val_pct=0.2)\n",
    "\n",
    "\n",
    "# Count labels\n",
    "# _all_labels = pd.read_csv(PATH + 'multi_folder_Hirano3D_02.csv')\n",
    "# print(_all_labels.Targets.value_counts())\n",
    "\n",
    "# _arr = _all_labels.values\n",
    "# _val_labels = pd.DataFrame(_arr[val_idxs], columns=['Id','Targets'])\n",
    "# print(_val_labels.Targets.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = os.listdir('datasets/HPA_challenge_2018/HPAv18_GBRY_60x_def_dupes_removed_all')\n",
    "# l[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, lbl_csv, val_idxs, sz, bs, aug_tfms):\n",
    "\n",
    "    tfms = tfms_with_IntNorm(sz, aug_tfms=aug_tfms, crop_type=CropType.CENTER)\n",
    "    data = ImageClassifierData.from_csv(path, 'data', lbl_csv, \n",
    "                                        val_idxs = val_idxs,\n",
    "                                        test_name='data/8bit_Hirano3D_MaxP_GRFB_test_512', \n",
    "                                        tfms=tfms, bs=bs, suffix = '.tif', \n",
    "                                        balance=True, num_workers=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Normalization\n",
      "val_crop is: 2\n",
      "Calculating weights...\n",
      "one-hot encoding single-labels...\n",
      "Weights calculated successfully!\n",
      "Using WeightedRandomSampler\n"
     ]
    }
   ],
   "source": [
    "# define augmentations\n",
    "augs = [RandomDihedral(),RandomRotate(90)]\n",
    "NUM_CLASSES = 4\n",
    "bs = 16\n",
    "sz = [4,512,512]\n",
    "lbl_csv = path + '8bit_multi_folder_Hirano3D_v1.csv'\n",
    "# initialize data object\n",
    "data = get_data(path, lbl_csv, val_idxs_loaded, sz, bs, aug_tfms = augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 512, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(data.trn_dl))\n",
    "im = to_np(x)[0]\n",
    "im.shape\n",
    "# x_test, y_test = next(iter(data.test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print transformations\n",
    "# plt.style.use('seaborn-white')\n",
    "\n",
    "c = 0\n",
    "idx = 0\n",
    "fig, ax = plt.subplots(1,4, figsize=(16,10))\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    x, y = next(iter(data.aug_dl))\n",
    "    im = to_np(x)[idx]\n",
    "#     ax.imshow(np.sum(im, axis = 0))\n",
    "    ax.imshow(im[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading epoch for manual inspection..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_epoch(dl = data.trn_dl):\n",
    "    \n",
    "    batch = iter(dl)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "#     for b in range(0,len(dl)):\n",
    "    for b in range(0,10):\n",
    "\n",
    "        x_, y_ = next(batch)\n",
    "        x_np, y_np = to_np(x_), to_np(y_)\n",
    "        xs.append(x_np)\n",
    "        ys.append(y_np)\n",
    "\n",
    "    return np.vstack(xs), np.concatenate(ys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inpsecting loaded images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_label(y):\n",
    "    ind = [i for i, p in enumerate(y) if y[i]==1]\n",
    "    return(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspect train images\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "idx = 2\n",
    "\n",
    "im = to_np(x)[idx]\n",
    "\n",
    "# lbl = to_np(y)[idx]\n",
    "lbl = to_label(to_np(y)[idx])\n",
    "print(lbl)\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize=(16,10))\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    ax.imshow(im[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspect test images\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "idx = 3\n",
    "\n",
    "im = to_np(x_test)[idx]\n",
    "\n",
    "# lbl = to_label(to_np(y)[idx])\n",
    "# print(lbl)\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize=(16,10))\n",
    "for i, ax in enumerate(ax.flat):\n",
    "    ax.imshow(im[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def check_model_loading(learn_obj, loaded_state_dict):\n",
    "    learn_weight0 = list(copy.deepcopy(learn_obj.models.model.state_dict()).items())[0] # need deepcopy here\n",
    "    learn_weight10 = list(copy.deepcopy(learn_obj.models.model.state_dict()).items())[604] # need deepcopy here\n",
    "\n",
    "    learn_obj.models.model.load_state_dict(loaded_state_dict, strict=False)\n",
    "    learn_weight0_loaded = list(learn_obj.models.model.state_dict().items())[0]\n",
    "    learn_weight10_loaded = list(learn_obj.models.model.state_dict().items())[604]\n",
    "\n",
    "#     print('weights_0:')\n",
    "#     print(learn_weight0[1][0] - learn_weight0_loaded[1][0])\n",
    "#     print('weights_10:')\n",
    "#     print(learn_weight10[1][0] - learn_weight10_loaded[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_state_dict_path = 'datasets/HPA_challenge_2018/models/HPAv18_bs64_sz256_rCrp_dn121_v2_2_val_009.h5'\n",
    "loaded_state_dict = torch.load(saved_state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded_state_dict # keys:  616\n",
      "loaded_state_dict_trunc # keys:  604\n"
     ]
    }
   ],
   "source": [
    "# truncating saved model_state_dict()\n",
    "\n",
    "loaded_state_dict_trunc = copy.deepcopy(loaded_state_dict)\n",
    "del_keys = list(loaded_state_dict_trunc.keys())[604:]\n",
    "for key in del_keys: del loaded_state_dict_trunc[key]\n",
    "\n",
    "print('loaded_state_dict # keys: ', len(loaded_state_dict.keys()))    \n",
    "print('loaded_state_dict_trunc # keys: ', len(loaded_state_dict_trunc.keys()))    \n",
    "\n",
    "# Print model's state_dict\n",
    "# print(\"Model's state_dict:\")\n",
    "# for param_tensor in learn.models.model.state_dict():\n",
    "#     print(param_tensor, \"\\t\", learn.models.model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = dn121_c\n",
    "\n",
    "learn = ConvLearner.pretrained(arch, data, opt_fn=optim.Adam, ps=0.5, pretrained=False)\n",
    "check_model_loading(learn, loaded_state_dict_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional parameters\n",
    "\n",
    "wd=1e-4 # weight-decay/L2 regularization \n",
    "# learn.metrics = [accuracy, f1_micro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([1e-6,1e-4,1e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a13e6d2e3034997b7a968663952301b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 0   \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      1.533484   1.259084   0.506024  \n",
      "EPOCH 1 ---------------------------------------- STEP 1   \n",
      "    1      1.306975   1.105823   0.53012   \n",
      "\n",
      "creating log-files...\n",
      "log-files saved to: datasets/HPA_challenge_2018/Hirano3D/\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/HPA_challenge_2018/Hirano3D/\n",
      "CPU times: user 4min 15s, sys: 25.9 s, total: 4min 41s\n",
      "Wall time: 4min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.10582]), 0.530120482286775]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs, 2, wds=wd, use_wd_sched=True, best_save_name='Hirano3D_dn121_512_transferHPA_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34a60a9edd1439ca48480f6f032b0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 2   \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      1.119408   1.249912   0.518072  \n",
      "EPOCH 1 ---------------------------------------- STEP 3   \n",
      "    1      1.043418   1.140043   0.53012   \n",
      "EPOCH 2 ---------------------------------------- STEP 4   \n",
      "    2      1.031245   1.063561   0.560241  \n",
      "\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/HPA_challenge_2018/Hirano3D/\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/HPA_challenge_2018/Hirano3D/\n",
      "CPU times: user 6min 23s, sys: 34.1 s, total: 6min 57s\n",
      "Wall time: 6min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.06356]), 0.5602409638554217]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs, 3, wds=wd, use_wd_sched=True, best_save_name='Hirano3D_dn121_512_transferHPA_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([1e-4,5e-4,1e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7decf2460e8d4fea807a823a84db2ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 5   \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      1.08316    1.152153   0.53012   \n",
      "EPOCH 1 ---------------------------------------- STEP 6    \n",
      "    1      0.944399   1.225646   0.566265  \n",
      "EPOCH 2 ---------------------------------------- STEP 7    \n",
      "    2      0.909283   1.10834    0.590361  \n",
      "EPOCH 3 ---------------------------------------- STEP 8    \n",
      "    3      0.804855   1.007621   0.596386  \n",
      "\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/HPA_challenge_2018/Hirano3D/\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/HPA_challenge_2018/Hirano3D/\n",
      "CPU times: user 8min 31s, sys: 45.1 s, total: 9min 16s\n",
      "Wall time: 9min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.00762]), 0.5963855421686747]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs, 4, wds=wd, use_wd_sched=True, best_save_name='Hirano3D_dn121_512_transferHPA_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5be4b5c6224d06aaeaa6401f9b50e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 9    \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.902267   1.205712   0.566265  \n",
      "EPOCH 1 ---------------------------------------- STEP 10   \n",
      "    1      0.745801   1.151965   0.572289  \n",
      "EPOCH 2 ---------------------------------------- STEP 11   \n",
      "    2      0.697623   1.05382    0.60241   \n",
      "EPOCH 3 ---------------------------------------- STEP 12   \n",
      "    3      0.692708   0.974555   0.60241   \n",
      "\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/HPA_challenge_2018/Hirano3D/\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/HPA_challenge_2018/Hirano3D/\n",
      "CPU times: user 8min 31s, sys: 45.1 s, total: 9min 16s\n",
      "Wall time: 9min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.97455]), 0.6024096385542169]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs, 4, wds=wd, use_wd_sched=True, best_save_name='Hirano3D_dn121_512_transferHPA_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c1ff47810046139e02fc7a0219ba78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 13   \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.554884   0.95452    0.614458  \n",
      "EPOCH 1 ---------------------------------------- STEP 14   \n",
      "    1      0.520966   0.893683   0.626506  \n",
      "EPOCH 2 ---------------------------------------- STEP 15   \n",
      "    2      0.467085   0.926303   0.60241   \n",
      "EPOCH 3 ---------------------------------------- STEP 16   \n",
      "    3      0.457922   0.983832   0.620482  \n",
      "\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/HPA_challenge_2018/Hirano3D/\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/HPA_challenge_2018/Hirano3D/\n",
      "CPU times: user 8min 30s, sys: 46.7 s, total: 9min 17s\n",
      "Wall time: 9min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.98383]), 0.6204819284289717]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-4, 4, wds=wd, use_wd_sched=True, best_save_name='Hirano3D_dn121_512_transferHPA_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971f61d9216546a59b2b2f462b56c454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=16, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 17   \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.524163   1.478992   0.53012   \n",
      "EPOCH 1 ---------------------------------------- STEP 18   \n",
      "    1      0.706804   1.323869   0.506024  \n",
      "EPOCH 2 ---------------------------------------- STEP 19   \n",
      "    2      0.685119   1.187399   0.572289  \n",
      "EPOCH 3 ---------------------------------------- STEP 20   \n",
      "    3      0.620629   0.984921   0.674699  \n",
      "EPOCH 4 ---------------------------------------- STEP 21   \n",
      "    4      0.607244   1.069384   0.614458  \n",
      "EPOCH 5 ---------------------------------------- STEP 22   \n",
      "    5      0.505628   0.975346   0.644578  \n",
      "EPOCH 6 ---------------------------------------- STEP 23   \n",
      "    6      0.450526   1.02132    0.644578  \n",
      "EPOCH 7 ---------------------------------------- STEP 24   \n",
      "    7      0.396202   0.959084   0.698795  \n",
      "EPOCH 8 ---------------------------------------- STEP 25   \n",
      "    8      0.382718   1.245899   0.596386  \n",
      "EPOCH 9 ---------------------------------------- STEP 26   \n",
      "    9      0.432777   1.232746   0.548193  \n",
      "EPOCH 10 ---------------------------------------- STEP 27  \n",
      "    10     0.490083   1.376855   0.542169  \n",
      "EPOCH 11 ---------------------------------------- STEP 28  \n",
      "    11     0.544019   1.257495   0.584337  \n",
      "EPOCH 12 ---------------------------------------- STEP 29  \n",
      "    12     0.516657   1.036921   0.644578  \n",
      "EPOCH 13 ---------------------------------------- STEP 30  \n",
      "    13     0.426623   1.053054   0.644578  \n",
      "EPOCH 14 ---------------------------------------- STEP 31  \n",
      "    14     0.354759   0.948568   0.662651  \n",
      "EPOCH 15 ---------------------------------------- STEP 32  \n",
      "    15     0.312516   0.929199   0.704819  \n",
      "\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/HPA_challenge_2018/Hirano3D/\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/HPA_challenge_2018/Hirano3D/\n",
      "CPU times: user 34min 6s, sys: 3min, total: 37min 6s\n",
      "Wall time: 36min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.9292]), 0.7048192763903055]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-3, 2, cycle_len=8, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85), best_save_name='Hirano3D_dn121_512_transferHPA_v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = dn121_c\n",
    "wd = 1e-3\n",
    "learn = ConvLearner.pretrained(arch, data, opt_fn=optim.Adam, ps=0.5, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('Hirano3D_dn121_512_transferHPA_v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951d8c88bd644c51b7619891430fda25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=16, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 ---------------------------------------- STEP 0    \n",
      "epoch      trn_loss   val_loss   accuracy   \n",
      "    0      0.228102   0.937856   0.704819  \n",
      "EPOCH 1 ---------------------------------------- STEP 1    \n",
      "    1      0.215028   1.016051   0.728916  \n",
      "EPOCH 2 ---------------------------------------- STEP 2    \n",
      "    2      0.216698   1.036658   0.716867  \n",
      "EPOCH 3 ---------------------------------------- STEP 3    \n",
      "    3      0.185915   1.012291   0.692771  \n",
      "EPOCH 4 ---------------------------------------- STEP 4    \n",
      "    4      0.216514   1.057943   0.686747  \n",
      "EPOCH 5 ---------------------------------------- STEP 5    \n",
      "    5      0.196268   1.042959   0.680723  \n",
      "EPOCH 6 ---------------------------------------- STEP 6    \n",
      "    6      0.164228   1.071928   0.680723  \n",
      "EPOCH 7 ---------------------------------------- STEP 7    \n",
      "    7      0.176888   1.093766   0.680723  \n",
      "EPOCH 8 ---------------------------------------- STEP 8    \n",
      "    8      0.152491   1.044826   0.686747  \n",
      "EPOCH 9 ---------------------------------------- STEP 9    \n",
      "    9      0.172533   1.117226   0.692771  \n",
      "EPOCH 10 ---------------------------------------- STEP 10  \n",
      "    10     0.184849   1.120334   0.716867  \n",
      "EPOCH 11 ---------------------------------------- STEP 11  \n",
      "    11     0.145022   1.113595   0.680723  \n",
      "EPOCH 12 ---------------------------------------- STEP 12  \n",
      "    12     0.145323   1.127346   0.686747  \n",
      "EPOCH 13 ---------------------------------------- STEP 13  \n",
      "    13     0.152867   1.174564   0.710843  \n",
      "EPOCH 14 ---------------------------------------- STEP 14  \n",
      "    14     0.139164   1.186761   0.668675  \n",
      "EPOCH 15 ---------------------------------------- STEP 15  \n",
      "    15     0.132624   1.122238   0.698795  \n",
      "\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/HPA_challenge_2018/Hirano3D/\n",
      "appending existing log-files...\n",
      "log-files saved to: datasets/HPA_challenge_2018/Hirano3D/\n",
      "CPU times: user 15min 17s, sys: 3min 52s, total: 19min 10s\n",
      "Wall time: 18min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.12224]), 0.6987951800047633]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(1e-3, 2, cycle_len=8, wds=wd, use_wd_sched=True, use_clr=(20,8, 0.95, 0.85), best_save_name='Hirano3D_dn121_512_transferHPA_v5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = learn.sched\n",
    "\n",
    "_iter_log = [[p.iterations[i], p.losses[i], p.lrs[i]] for i in range(len(p.iterations))]\n",
    "_epoch_log = [[p.glob_step[i], p.val_losses[i], *p.rec_metrics[i]] for i in range(len(p.glob_step))]\n",
    "\n",
    "_iter_log = pd.DataFrame(_iter_log, columns=[\"Iterations\", 'trn_oss', 'Lr'])\n",
    "_epoch_log = pd.DataFrame(_epoch_log, columns=['Global_step','val_loss','metric_1', 'f1_macro'])\n",
    "\n",
    "_iter_log.to_csv('datasets/HPA_challenge_2018/logs/iter_log_HPAv18_bs128_sz128_rCrp_dn121_v1_.csv', index=False) \n",
    "_epoch_log.to_csv('datasets/HPA_challenge_2018/logs/epoch_log_HPAv18_bs128_sz128_rCrp_dn121_v1_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = learn.sched\n",
    "\n",
    "_iter_log = [[p.iterations[i], p.losses[i], p.lrs[i]] for i in range(len(p.iterations))]\n",
    "_epoch_log = [[p.glob_step[i], p.val_losses[i], *p.rec_metrics[i]] for i in range(len(p.glob_step))]\n",
    "\n",
    "_iter_log = pd.DataFrame(_iter_log, columns=[\"Iterations\", 'trn_oss', 'Lr'])\n",
    "_epoch_log = pd.DataFrame(_epoch_log, columns=['Global_step','val_loss','metric_1', 'f1_macro'])\n",
    "\n",
    "_iter_log.to_csv('datasets/HPA_challenge_2018/logs/iter_log_HPAv18_bs128_sz128_rCrp_dn121_v1_.csv', header=False, index=False, mode='a') \n",
    "_epoch_log.to_csv('datasets/HPA_challenge_2018/logs/epoch_log_HPAv18_bs128_sz128_rCrp_dn121_v1_.csv', header=False, index=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('Hirano3D_dn121_512_transferHPA_v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test-predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.predict_with_targs()\n",
    "preds = np.argmax(log_preds, axis=1)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    }
   ],
   "source": [
    "log_preds, y =  learn.TTA(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  3 13  7]\n",
      " [ 1 25  2  5]\n",
      " [ 4  3 28  2]\n",
      " [ 5  3  3 20]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix \n",
    "plt.style.use('seaborn-white')\n",
    "log_preds_mean = np.mean(log_preds, axis=0)\n",
    "preds = np.argmax(log_preds_mean, axis=1)\n",
    "cm = confusion_matrix(preds,y)\n",
    "plot_confusion_matrix(cm, data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6927710843373494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.65      0.72        65\n",
      "           1       0.74      0.76      0.75        33\n",
      "           2       0.61      0.76      0.67        37\n",
      "           3       0.59      0.65      0.62        31\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       166\n",
      "   macro avg       0.68      0.70      0.69       166\n",
      "weighted avg       0.71      0.69      0.69       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(preds, y))\n",
    "print(classification_report(preds, y, target_names=data.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y =  learn.TTA(is_test=True)\n",
    "log_preds_mean = np.mean(log_preds, axis=0)\n",
    "preds = np.argmax(log_preds_mean, axis=1)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to be called by register_forward_hook\n",
    "\n",
    "def get_embeddings(layer_name):\n",
    "    def register_hook(layer_name):\n",
    "        def get_embedding(layer, inp, outp):\n",
    "            tmp = inp[0]\n",
    "            embedding.append(tmp)\n",
    "\n",
    "        hook = layer.register_forward_hook(get_embedding) \n",
    "        \n",
    "        for i in ['trn', 'val', 'test']:\n",
    "            embedding = []\n",
    "            preds, y = learn.predict_with_targs(i)\n",
    "            \n",
    "            # populating dict, consiting of [0]: preds, [1]: y, [2]: activations[layer]\n",
    "            embeddings[i] = [preds, y, np.vstack(to_np(embedding))]\n",
    "            \n",
    "        hook.remove()\n",
    "        \n",
    "    embeddings = {}    \n",
    "    layer = learn.models.model._modules.get(layer_name)\n",
    "    register_hook(layer)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embeddings('7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# with open('datasets/HPA_challenge_2018/Hirano3D/tmp/Embeddings_Hirano3D_dn121_512_transferHPA_v4.pkl', 'wb') as handle:\n",
    "#     pickle.dump(embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('datasets/HPA_challenge_2018/Hirano3D/tmp/Embeddings_Hirano3D_dn121_512_transferHPA_v4.pkl', 'rb') as handle:\n",
    "    embeddings_loaded = pickle.load(handle)\n",
    "    \n",
    "# embeddings = embeddings_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(664, 512)\n",
      "(166, 512)\n",
      "(60, 512)\n",
      "(664,)\n",
      "(166,)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "# unpacking embeddings\n",
    "\n",
    "embs_trn = embeddings['trn'][2]\n",
    "y_trn = embeddings['trn'][1]\n",
    "\n",
    "embs_val = embeddings['val'][2]\n",
    "y_val = embeddings['val'][1]\n",
    "\n",
    "embs_test = embeddings['test'][2]\n",
    "y_test = embeddings['test'][1]\n",
    "\n",
    "print(embs_trn.shape)\n",
    "print(embs_val.shape)\n",
    "print(embs_test.shape)\n",
    "\n",
    "print(y_trn.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'umap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-623e299b05c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'umap'"
     ]
    }
   ],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'umap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b0f5d20442dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m UMAP_trn_embedding = umap.UMAP(n_neighbors=10,\n\u001b[0m\u001b[1;32m      2\u001b[0m                       \u001b[0mmin_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       metric='correlation').fit(embs_trn)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mUMAP_trn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUMAP_trn_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'umap' is not defined"
     ]
    }
   ],
   "source": [
    "UMAP_trn_embedding = umap.UMAP(n_neighbors=10,\n",
    "                      min_dist=0.3,\n",
    "                      metric='correlation').fit(embs_trn)\n",
    "\n",
    "UMAP_trn = UMAP_trn_embedding.embedding_\n",
    "UMAP_val = UMAP_trn_embedding.transform(embs_val)\n",
    "UMAP_test = UMAP_trn_embedding.transform(embs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.test_ds.fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.zeros(60)\n",
    "y_test[:30] = y_test[:30] +1 \n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting PCA vs TSNE results\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "compA = 0\n",
    "compB = 1\n",
    "\n",
    "for i in range(4):\n",
    "    trn_UMAP_cls = UMAP_trn[y_trn == i]\n",
    "\n",
    "    axarr[0].scatter(trn_UMAP_cls[:,compA], trn_UMAP_cls[:,compB], label = data.classes[i], s = 5)\n",
    "    axarr[0].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    if i == 0:\n",
    "        axarr[1].scatter(trn_UMAP_cls[:,compA], trn_UMAP_cls[:,compB], label = data.classes[i], s = 5)\n",
    "\n",
    "    axarr[0].set_xlim(-10,5)\n",
    "    axarr[0].set_ylim(-5,8)\n",
    "    \n",
    "for i in [0,1]:\n",
    "    test_UMAP_cls = UMAP_test[y_test == i]\n",
    "    \n",
    "    axarr[1].scatter(test_UMAP_cls[:,compA], test_UMAP_cls[:,compB], s = 5)\n",
    "    axarr[1].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    axarr[1].set_xlim(-10,5)\n",
    "    axarr[1].set_ylim(-5,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_th(preds, targs, start=0.2, end=0.6, step=0.05):\n",
    "    ths = np.arange(start,end,step)\n",
    "    res = [f1_macro(preds, targs, thresh=th, kind='macro') for th in ths]\n",
    "    idx = np.argmax(res)\n",
    "    return ths[idx], res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train predictions\n",
    "\n",
    "preds_trn, targs_trn =  learn.predict_with_targs('trn')\n",
    "\n",
    "preds_trn_torch = torch.from_numpy(preds_trn)\n",
    "targs_trn_torch = torch.from_numpy(targs_trn)\n",
    "\n",
    "opt_th(preds_trn_torch, targs_trn_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds_val_torch[0])\n",
    "print(preds_trn_torch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds_mean = np.mean(log_preds, axis=0)\n",
    "preds = np.argmax(log_preds_mean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get val predictions\n",
    "\n",
    "preds_val, targs_val =  learn.predict_with_targs('val')\n",
    "\n",
    "preds_val_torch = torch.from_numpy(preds_val)\n",
    "targs_val_torch = torch.from_numpy(targs_val)\n",
    "\n",
    "opt_th(preds_val_torch, targs_val_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get val predictions\n",
    "\n",
    "preds_val, targs_val =  learn.TTA(n=8)\n",
    "preds_val= np.mean(preds_val, axis=0)\n",
    "preds_val_torch = torch.from_numpy(preds_val)\n",
    "targs_val_torch = torch.from_numpy(targs_val)\n",
    "\n",
    "opt_th(preds_val_torch, targs_val_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get val predictions\n",
    "\n",
    "preds_val, targs_val =  learn.TTA(8)\n",
    "preds_val= np.mean(preds_val, axis=0)\n",
    "preds_val_torch = torch.from_numpy(preds_val)\n",
    "targs_val_torch = torch.from_numpy(targs_val)\n",
    "\n",
    "opt_th(preds_val_torch, targs_val_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test predictions\n",
    "\n",
    "preds_test, targs_test =  learn.predict_with_targs('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targs_test[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_epoch(dl = data.trn_dl):\n",
    "    \n",
    "    batch = iter(dl)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "#     for b in range(0,len(dl)):\n",
    "    for b in range(0,10):\n",
    "\n",
    "        x_, y_ = next(batch)\n",
    "        x_np, y_np = to_np(x_), to_np(y_)\n",
    "        xs.append(x_np)\n",
    "        ys.append(y_np)\n",
    "\n",
    "    return np.vstack(xs), np.concatenate(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test_dl.sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = data.test_ds.fnames\n",
    "test_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(preds_file, output_name, th = 0.3, TTA=False):\n",
    "    \n",
    "    # creating submission file\n",
    "    \n",
    "    if TTA:\n",
    "        preds = preds_file.mean(axis=0)\n",
    "        print('TTA:',preds.shape)\n",
    "    else: preds = preds_file\n",
    "    \n",
    "    clss = np.arange(0, len(data.classes)) # get class indeces\n",
    "    res = np.array([' '.join(np.char.mod('%d', clss[np.where(p > th)])) for p in preds]) # generating output\n",
    "\n",
    "    # ensure that there are no empty cells: in case no value > thresh, fill in with argmax()\n",
    "    for i in range(res.shape[0]):\n",
    "        if res[i] == '':\n",
    "            res[i] = preds[i].argmax()\n",
    "\n",
    "    # getting image Ids\n",
    "    fnames = np.array([os.path.basename(im).split('.')[0] for im in data.test_ds.fnames])\n",
    "\n",
    "    # creating submission file\n",
    "    sub_df = pd.DataFrame(res, index=fnames, columns=['Predicted'])\n",
    "    sub_df.to_csv(output_name, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = PATH + 'submissions/Res18_pre_0.42_t-03.csv'\n",
    "\n",
    "create_submission(log_preds, submission_name, th=0.3, TTA=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of label identities:\n",
    "\n",
    "cell_location_label = {\n",
    "0:  'Nucleoplasm',\n",
    "1:  'Nuclear membrane',\n",
    "2:  'Nucleoli',   \n",
    "3:  'Nucleoli fibrillar center',\n",
    "4:  'Nuclear speckles',\n",
    "5:  'Nuclear bodies',\n",
    "6:  'Endoplasmic reticulum',   \n",
    "7:  'Golgi apparatus',\n",
    "8:  'Peroxisomes',\n",
    "9:  'Endosomes',\n",
    "10:  'Lysosomes',\n",
    "11:  'Intermediate filaments',\n",
    "12:  'Actin filaments',\n",
    "13:  'Focal adhesion sites',   \n",
    "14:  'Microtubules',\n",
    "15:  'Microtubule ends',  \n",
    "16:  'Cytokinetic bridge',   \n",
    "17:  'Mitotic spindle',\n",
    "18:  'Microtubule organizing center',  \n",
    "19:  'Centrosome',\n",
    "20:  'Lipid droplets',\n",
    "21:  'Plasma membrane',   \n",
    "22:  'Cell junctions', \n",
    "23:  'Mitochondria',\n",
    "24:  'Aggresome',\n",
    "25:  'Cytosol',\n",
    "26:  'Cytoplasmic bodies',   \n",
    "27:  'Rods & rings' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# thresholds = np.linspace(0, 1, 1000)\n",
    "# score = 0.0\n",
    "# test_threshold=0.5*np.ones(28)\n",
    "# best_threshold=np.zeros(28)\n",
    "# best_val = np.zeros(28)\n",
    "# for i in range(28):\n",
    "#     for threshold in thresholds:\n",
    "#         test_threshold[i] = threshold\n",
    "#         max_val = np.max(preds_y)\n",
    "#         val_predict = (preds_y > test_threshold)\n",
    "#         score = f1_score(valid_y > 0.5, val_predict, average='macro')\n",
    "#         if score > best_val[i]:\n",
    "#             best_threshold[i] = threshold\n",
    "#             best_val[i] = score\n",
    "#     print(\"Threshold[%d] %0.6f, F1: %0.6f\" % (i,best_threshold[i],best_val[i]))\n",
    "#     test_threshold[i] = best_threshold[i]\n",
    "# print(\"Best threshold: \")\n",
    "# print(best_threshold)\n",
    "# print(\"Best f1:\")\n",
    "# print(best_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
